<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://ysjhhhhhhh.github.io</id>
    <title>Gridea</title>
    <updated>2019-12-12T11:42:04.250Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://ysjhhhhhhh.github.io"/>
    <link rel="self" href="https://ysjhhhhhhh.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://ysjhhhhhhh.github.io/images/avatar.png</logo>
    <icon>https://ysjhhhhhhh.github.io/favicon.ico</icon>
    <rights>All rights reserved 2019, Gridea</rights>
    <entry>
        <title type="html"><![CDATA[Netflix系列]]></title>
        <id>https://ysjhhhhhhh.github.io/post/netflix-xi-lie</id>
        <link href="https://ysjhhhhhhh.github.io/post/netflix-xi-lie">
        </link>
        <updated>2018-06-19T07:39:20.000Z</updated>
        <content type="html"><![CDATA[<p>[TOC]</p>
<h1 id="netflix体系简介">Netflix体系简介</h1>
<p>Netflix这可是个大boss，地位仅次于老大，老大各项服务依赖与它，与各种Netflix OSS组件集成，组成微服务的核心，它的小弟主要有Eureka, Hystrix, Zuul, Archaius… 太多了</p>
<h2 id="核心成员">核心成员</h2>
<h3 id="netflix-eureka">Netflix Eureka</h3>
<p>服务中心，云端服务发现，一个基于 REST 的服务，用于定位服务，以实现云端中间层服务发现和故障转移。这个可是springcloud最牛鼻的小弟，服务中心，任何小弟需要其它小弟支持什么都需要从这里来拿，同样的你有什么独门武功的都赶紧过报道，方便以后其它小弟来调用；它的好处是你不需要直接找各种什么小弟支持，只需要到服务中心来领取，也不需要知道提供支持的其它小弟在哪里，还是几个小弟来支持的，反正拿来用就行，服务中心来保证稳定性和质量。</p>
<h3 id="netflix-ribbon">Netflix Ribbon</h3>
<p>Ribbon是一个客户端负载均衡组件，帮我们实现后端服务节点动态扩容，而不影响调用方。</p>
<h3 id="netflix-hystrix">Netflix Hystrix</h3>
<p>熔断器，容错管理工具，旨在通过熔断机制控制服务和第三方库的节点,从而对延迟和故障提供更强大的容错能力。比如突然某个小弟生病了，但是你还需要它的支持，然后调用之后它半天没有响应，你却不知道，一直在等等这个响应；有可能别的小弟也正在调用你的武功绝技，那么当请求多之后，就会发生严重的阻塞影响老大的整体计划。这个时候Hystrix就派上用场了，当Hystrix发现某个小弟不在状态不稳定立马马上让它下线，让其它小弟来顶上来，或者给你说不用等了这个小弟今天肯定不行，该干嘛赶紧干嘛去别在这排队了。</p>
<h3 id="netflix-zuul">Netflix Zuul</h3>
<p>Zuul 是在云平台上提供动态路由,监控,弹性,安全等边缘服务的框架。Zuul 相当于是设备和 Netflix 流应用的 Web 网站后端所有请求的前门。当其它门派来找大哥办事的时候一定要先经过zuul,看下有没有带刀子什么的给拦截回去，或者是需要找那个小弟的直接给带过去。</p>
<h3 id="netflix-archaius">Netflix Archaius</h3>
<p>配置管理API，包含一系列配置管理API，提供动态类型化属性、线程安全配置操作、轮询框架、回调机制等功能。可以实现动态获取配置， 原理是每隔60s（默认，可配置）从配置源读取一次内容，这样修改了配置文件后不需要重启服务就可以使修改后的内容生效，前提使用archaius的API来读取。</p>
<h1 id="eurekanetflix-服务发现与注册">Eureka(Netflix) - 服务发现与注册</h1>
<h2 id="eureka介绍">Eureka介绍</h2>
<blockquote>
<p>Eureka是xxx</p>
</blockquote>
<h2 id="eureka的使用方法">Eureka的使用方法</h2>
<p>Eureka分为服务端和客户端，Eureka Server负责集中管理所有注册上来的微服务,维护一个完整的服务列表，同时监控每个服务的状态（通过客户端定时renew），及时下线down掉的服务<br>
Eureka Client端负责上报服务、服务下线、拉取服务端的服务列表等功能。</p>
<h3 id="eureka-server端配置">Eureka Server端配置</h3>
<ol>
<li>添加依赖</li>
</ol>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<ol start="2">
<li>properties配置</li>
</ol>
<pre><code class="language-yml">spring:
  application:
    name: eureka-server
  profiles:
    active: dev

security:
  basic:
    enabled: true
  user:
    name: lisi
    password: 123

eureka:
  instance:
    prefer-ip-address: true #在某些情况下，Eureka优先使用IP地址而不是主机名。设置为true，当应用程序向eureka注册时，它将使用其IP地址而不是其主机名
    #instance-id: ${spring.application.name}:${spring.application.instance_id:${server.port}}
  client:
    registerWithEureka: true
    fetchRegistry: true

---
spring:
  profiles: dev
server:
  port: 8781
eureka:
  instance:
    hostname: peer1
    lease-renewal-interval-in-seconds: 30   #eureka client续租的超时时长
  client:
    service-url:
      defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/
    register-with-eureka: false  #单机模式：禁止向别的eureka server注册自己
    fetch-registry: false #单机模式：禁止从别的eureka server获取服务列表

security:
  basic:
    enabled: false
---
spring:
  profiles: peer1
server:
  port: 8781
eureka:
  instance:
    hostname: peer1
  client:
    service-url:
      defaultZone: http://${security.user.name}:${security.user.password}@peer2:8782/eureka/,http://${security.user.name}:${security.user.password}@peer3:8783/eureka/
security:
  basic:
    enabled: true


---
spring:
  profiles: peer2
server:
  port: 8782
eureka:
  instance:
    hostname: peer2
  client:
    service-url:
      defaultZone: http://${security.user.name}:${security.user.password}@peer1:8781/eureka/,http://${security.user.name}:${security.user.password}@peer3:8783/eureka/

---
spring:
  profiles: peer3
server:
  port: 8783
eureka:
  instance:
    hostname: peer3
  client:
    service-url:
      defaultZone: http://${security.user.name}:${security.user.password}@peer1:8781/eureka/,http://${security.user.name}:${security.user.password}@peer2:8782/eureka/
</code></pre>
<ol start="3">
<li>开启应用的Eureka Server功能<br>
在应用启动类上加 @EnableEurekaServer注解</li>
</ol>
<pre><code class="language-java">@SpringBootApplication
@EnableEurekaServer
public class EurekaApplication
{
    public static void main( String[] args )
    {
        SpringApplication.run(EurekaApplication.class, args);
    }
}
</code></pre>
<h3 id="eureka-client端">Eureka Client端</h3>
<ol>
<li>添加依赖</li>
</ol>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<ol start="2">
<li>客户端配置</li>
</ol>
<pre><code class="language-yml">eureka:
  client:
    serviceUrl:
#      defaultZone: http://lisi:123@peer1:8781/eureka/
      defaultZone: http://peer1:8781/eureka/
  instance:
    prefer-ip-address: true #在某些情况下，Eureka优先使用IP地址而不是主机名。设置为true，当应用程序向eureka注册时，它将使用其IP地址而不是其主机名
    instance-id: ${spring.application.name}:${spring.application.instance_id:${server.port}}
</code></pre>
<ol start="3">
<li>开启应用的Eureka Client功能<br>
在应用启动类上加 @EnableEurekaClient或者@EnableDiscoveryClient注解</li>
</ol>
<pre><code class="language-java">@SpringBootApplication
@EnableEurekaClient
// @EnableDiscoveryClient  //与EnableEurekaClient二选一
public class ClientApplicationStart {
    public static void main(String[] args) {
        new SpringApplicationBuilder(ClientApplicationStart.class).web(true).run(args);
    }
}
</code></pre>
<h2 id="eureka的保护模式">Eureka的保护模式</h2>
<p>在使用Eureka作为服务注册中心时，有时控制台的网页上会出现红色的警告：<br>
EMERGENCY! EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY'RE NOT. RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEING EXPIRED JUST TO BE SAFE.</p>
<p>出现此问题的原因是要从Eureka服务注册中心的原理说起， 所有注册到Eureka中的微服务与Eureka Server之间一直保持着一个心跳连接， 当Eureka Server这边收不到某个微服务（其实就是Eureka Client）的心跳连接时，有可能有两种情况： 1. 微服务真的挂了； 2. Eureka Server与微服务(Eureka Client)之间的网络中断，但微服务本身并没有挂。</p>
<p>默认情况下，如果Eureka Server在一定时间内没有接收到某个微服务实例的心跳，Eureka Server将会注销该实例（默认90秒）。但是当网络分区故障发生时，微服务与Eureka Server之间无法正常通信，这就可能变得非常危险了----因为微服务本身是健康的，此时本不应该注销这个微服务。</p>
<p>Eureka Server通过“自我保护模式”来解决这个问题----当Eureka Server节点在短时间内丢失过多客户端时（可能发生了网络分区故障），那么这个节点就会进入自我保护模式。一旦进入该模式，Eureka Server就会保护服务注册表中的信息，不再删除服务注册表中的数据（也就是不会注销任何微服务）。当网络故障恢复后，该Eureka Server节点会自动退出自我保护模式。</p>
<p>自我保护模式是一种对网络异常的安全保护措施。使用自我保护模式，而已让Eureka集群更加的健壮、稳定。</p>
<p>如果不想看到这个警告，我们也可以通过下面的配置显式关闭保护模式（生产环境不建议关掉）：</p>
<pre><code class="language-properties"># 关闭Eureka Server保护模式
eureka.server.enable-self-preservation=false
</code></pre>
<h1 id="ribbionnetflix-客户端负载均衡">Ribbion(Netflix) - 客户端负载均衡</h1>
<h2 id="ribbon介绍">Ribbon介绍</h2>
<p>Ribbon是一个客户端负载均衡组件，帮我们实现后端服务节点动态扩容，而不影响调用方。</p>
<h2 id="ribbon的使用方法">Ribbon的使用方法</h2>
<p>Eureka和Feign中已经默认集成了Ribbon，如果项目中引入了Eureka，通过在RestTemplate上添加@LoadBalanced；如果用的是Feign声明式REST客户端，feign默认就已经帮我们开启了ribbon负载均衡能力。</p>
<h2 id="ribbon的配置">Ribbon的配置</h2>
<h3 id="通过代码修改ribbon全局配置">通过代码修改ribbon全局配置</h3>
<ol>
<li>创建Ribbon配置类</li>
</ol>
<pre><code class="language-java">/**
 * 通过注解的方式自定义ribbon策略
 * 可自定义的属性参见：https://cloud.spring.io/spring-cloud-static/spring-cloud-netflix/2.0.2.RELEASE/single/spring-cloud-netflix.html#_customizing_the_ribbon_client
 * 注意：此配置不可放置到ComponentScan可以扫描到的位置（一般来说可以放到Application启动类的上层包中），否则就会全局生效
 */
@Configuration  //官方文档说配置类必须加上此注解，但本人测试不加也可以，建议最好还是按官方要求加上
public class RibbonConfiguration {
    @Bean
    public IRule ribbonRule() {
        return new RoundRobinRule();
    }
}
</code></pre>
<ol start="2">
<li>在Spring @Configuration类中引用配置，并加上@RibbonClients注解引用上面定义的配置</li>
</ol>
<pre><code class="language-java">/**
 * 用用全局配置
 * @author: john
 * @create: 2018-12-14 20:37:14
 */
@Configuration
@RibbonClients(defaultConfiguration = RibbonConfiguration.class)    //配置ribbon全局策略
public class ApplicationConfiguration {
}
</code></pre>
<h3 id="通过代码修改指定微服务的ribbon配置">通过代码修改指定微服务的ribbon配置</h3>
<ol>
<li>创建Robbon配置类</li>
</ol>
<blockquote>
<p>见1.1中创建的Ribbon配置类</p>
</blockquote>
<ol start="2">
<li>在Spring @Configuration类中引用配置，并且加上@RibbonClient注解</li>
</ol>
<pre><code class="language-java">/**
 * @className: PrintServiceConfiguration
 * @description: 通过注解的方式自定义指定service的ribbon配置
 * @author: john
 * @create: 2018-12-14 20:29:19
 */
@Configuration
@RibbonClient(name = &quot;MICROSERVER-PRINT&quot;, configuration = RibbonConfiguration.class) //name对应微服务名称
public class PrintServiceConfiguration {
}

</code></pre>
<h3 id="属性文件全局配置">属性文件全局配置</h3>
<pre><code>官方文档中没有找到，应该是不支持
</code></pre>
<h3 id="属性文件特定配置">属性文件特定配置</h3>
<pre><code>&lt;clientName&gt;.ribbon.xxx，支持的属性如下：
- NFLoadBalancerClassName: should implement ILoadBalancer
- NFLoadBalancerRuleClassName: should implement IRule
- NFLoadBalancerPingClassName: should implement IPing
- NIWSServerListClassName: should implement ServerList
- NIWSServerListFilterClassName should implement ServerListFilter

例如：
```yml
microserver-print:
    ribbon:
        NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule #设置ribbon访问microserver-print这个微服务的负载均衡Rule
```
</code></pre>
<h2 id="ribbon与eureka配合使用">Ribbon与Eureka配合使用</h2>
<p>Eureka中已经默认集成了Ribbon，所以当我们引入Eureka后，不需要额外做什么操作只要在ResultTemplate的Bean配置上加上@LoadBalanced（或者和Feign一起使用，feign也集成了ribbon）。</p>
<pre><code class="language-java">@Configuration
public class ApplicationConfiguration {
    @Bean
    @LoadBalanced
    public RestTemplate setRestTemplate() {
        return new RestTemplate();
    }
}

// 使用RestTemplate通过服务ID调用服务，http://{serviceId}/path
@RequestMapping(&quot;/name/{name}&quot;)
public String nameHello(@PathVariable String name, Model model) {
    String result = restTemplate.getForObject(&quot;http://hello-server/name/&quot;+name, String.class);
    model.addAttribute(&quot;msg&quot;, result);
    return &quot;index&quot;;
}

</code></pre>
<blockquote>
<p>当Ribbon与Eureka一起使用时，Eureka会修改Ribbon以下几个全局配置：</p>
<ul>
<li>ribbonServerList被设置为：DiscoveryEnabledNIWSServerList的扩展DomainExtractingServerList</li>
<li>IPing被设置为：NIWSDiscoveryPing</li>
</ul>
</blockquote>
<h2 id="ribbon脱离eureka单独使用">Ribbon脱离Eureka单独使用</h2>
<p>Ribbon本身并不依赖Eureka，完全可以单独作为客户端负载均衡使用。用法如下：<br>
在yml文件中做如下配置：</p>
<pre><code class="language-yml"># 测试use ribbon without eureka, must set ribbon.eureka.enabled=false
print:
  ribbon:
    NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule
    listOfServers: localhost:8001,localhost:8002

ribbon:
  eureka:
    enabled: false  #如果项目引入了Eureka，必须设置关闭在eureka中使用ribbon

</code></pre>
<p>然后通过以下两种方式使用ribbon：</p>
<ol>
<li>在RestTemplate配置Bean上添加@LoadBalanced注解。访问http://print/rest/print/ 就会开启ribbon的负载均衡能力</li>
<li>直接通过ribbon提供的API使用</li>
</ol>
<pre><code class="language-java">public class MyClass {
    @Autowired
    private LoadBalancerClient loadBalancer;

    public void doStuff() {
        ServiceInstance instance = loadBalancer.choose(&quot;print&quot;);
        URI storesUri = URI.create(String.format(&quot;http://%s:%s&quot;, instance.getHost(), instance.getPort()));
        // ... do something with the URI
    }
}
</code></pre>
<h1 id="hystrixnetflix-服务熔断-降级-限流-隔离">Hystrix(Netflix) - 服务熔断、降级、限流、隔离</h1>
<h2 id="hystrix介绍">Hystrix介绍</h2>
<blockquote>
<p>在分布式环境中，许多服务依赖项中的一些不可避免地会失败。<br>
Hystrix是一个库，可通过添加延迟容错和容错逻辑来帮助您控制这些分布式服务之间的交互。<br>
Hystrix通过隔离服务之间的访问点，阻止它们之间的级联故障以及提供后备选项来实现这一目标，这些都可以提高系统的整体恢复能力</p>
</blockquote>
<blockquote>
<p>通俗的说Hystrix是Netflix公司开源的一个用于服务调用的断路器组件，给我们提供了包括服务熔断、降级、超时、资源隔离在内的完整解决方案。</p>
</blockquote>
<h2 id="hystrix的用法">Hystrix的用法</h2>
<p>Hystrix已经集成到了Feign中，可以和feign无缝对接。 如果没有引入Feign，我们也可以通过引入Hystrix相关依赖，通过HystrixCommand对指定的请求包裹Hystrix熔断功能。</p>
<h3 id="hystrix和feign一起使用">Hystrix和Feign一起使用</h3>
<blockquote>
<p>参见Feign章节中的《Feign与Hystrix集成》部分</p>
</blockquote>
<h3 id="hystrix与resttemplate一起使用">Hystrix与RestTemplate一起使用</h3>
<ol>
<li>引入Hystrix依赖包</li>
</ol>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<ol start="2">
<li>在Application启动类中开启Hystrix熔断</li>
<li>在SpringMVC Controller的请求方法上添加 @HystrixCommand注解</li>
</ol>
<pre><code class="language-java">/**
 * commandKey用于在Properties文件中配置此Command的参数，也可以直接用注解在这里配置参数
 * fallbackMethod指定服务降级时调用的方法
 */
@HystrixCommand(fallbackMethod = &quot;addFallback&quot;,commandKey = &quot;addFallbackCommandKey&quot;)    
@GetMapping(&quot;/add/{num1}_{num2}&quot;)
public Map&lt;String, Object&gt; add(@PathVariable int num1, @PathVariable int num2) {
    Map&lt;String, Object&gt; result = restTemplate.getForObject(calcServerUrl+&quot;add/&quot;+num1+&quot;_&quot;+num2, Map.class);
    return result;
}
</code></pre>
<h2 id="hystrix的配置">Hystrix的配置</h2>
<p>和Netflix Ribbon组件类似，Hystrix的所有配置参数也分四个级别：</p>
<ol>
<li>Global default from code（代码中全局默认）</li>
<li>Dynamic global default property （properties文件全局配置）</li>
<li>Instance default from code（代码中修改指定实例的参数）</li>
<li>Dynamic instance property (通过properteis文件修改指定实例的参数)</li>
</ol>
<p>以上四种方式的配置优先级依次升高，下面我们来依次介绍这四种方式的配置方法</p>
<h3 id="hystrix代码全局默认参数">Hystrix代码全局默认参数</h3>
<p>指的是Hystrix源码中设置的默认参数，我们可以在Properties文件中通过将CommandKey指向&quot;default&quot;，修改大部分全局默认参数。</p>
<h3 id="通过代码修改指定hystrixcommand参数">通过代码修改指定HystrixCommand参数</h3>
<h4 id="通过javanica的方式修改单个方法的hystrix参数推荐">通过javanica的方式修改单个方法的Hystrix参数（推荐）</h4>
<p>直接配置方法上的@HystrixCommand注解参数即可，如</p>
<pre><code class="language-java">@HystrixCommand(
        fallbackMethod = &quot;addFallback&quot;, commandKey = &quot;calc-add-command&quot;,
        groupKey = &quot;calc-command-group&quot;, threadPoolKey = &quot;calc-add-command-pool&quot;,
        commandProperties = {
                @HystrixProperty(name = &quot;execution.isolation.thread.timeoutInMilliseconds&quot;, value = &quot;1500&quot;),
                @HystrixProperty(name = &quot;circuitBreaker.requestVolumeThreshold&quot;, value = &quot;3&quot;),
                @HystrixProperty(name = &quot;metrics.rollingStats.timeInMilliseconds&quot;, value = &quot;10000&quot;),
                @HystrixProperty(name = &quot;metrics.rollingPercentile.enabled&quot;, value = &quot;false&quot;)
        },
        threadPoolProperties = {
                @HystrixProperty(name = &quot;coreSize&quot;, value = &quot;10&quot;),
                @HystrixProperty(name = &quot;queueSizeRejectionThreshold&quot;, value = &quot;9&quot;)
        }
)
@GetMapping(&quot;/add/{num1}_{num2}&quot;)
public Map&lt;String, Object&gt; add(@ApiParam @PathVariable int num1, @ApiParam @PathVariable int num2) {
    log.info(&quot;request calc.add, params: &quot; + num1 + &quot;,&quot; + num2);
    Map&lt;String, Object&gt; result = restTemplate.getForObject(calcServerUrl + &quot;add/&quot; + num1 + &quot;_&quot; + num2, Map.class);
    return result;
}

</code></pre>
<p>注：如果不配threadPoolKey的话，默认会取groupKey得值。相同threadPoolKey会共享同一个线程池的资源</p>
<h4 id="通过javanica的方式修改多个方法的hystrix参数">通过javanica的方式修改多个方法的Hystrix参数</h4>
<p>通过在类上面添加 @DefaultProperteis注解，可以修改此类中所有用@HystrixCommand注解的方法的默认Hystrix参数</p>
<pre><code class="language-java">@DefaultProperties(groupKey = &quot;DefaultGroupKey&quot;)
class Service {
    @HystrixCommand // hystrix command group key is 'DefaultGroupKey'
    public Object commandInheritsDefaultProperties() {
        return null;
    }
    @HystrixCommand(groupKey = &quot;SpecificGroupKey&quot;) // command overrides default group key
    public Object commandOverridesGroupKey() {
        return null;
    }
}
</code></pre>
<h4 id="通过自定义command类的方式包裹请求方法不推荐实际写起来太复杂">通过自定义Command类的方式包裹请求方法（不推荐，实际写起来太复杂）</h4>
<pre><code class="language-java">public class CommandHelloWorld extends HystrixCommand&lt;String&gt; {

    private final String name;

    static HystrixCommand.Setter commandSetter;

    static {
        HystrixCommandProperties.Setter commandPropertiesSetter = HystrixCommandProperties.Setter()
                .withExecutionIsolationSemaphoreMaxConcurrentRequests(20)   //最大并发请求数
                .withExecutionTimeoutInMilliseconds(1500)   //请求超过1.5秒执行降级逻辑
                .withCircuitBreakerRequestVolumeThreshold(3)    //在一个统计窗口期内，请求失败3次熔断
                .withCircuitBreakerSleepWindowInMilliseconds(2000)  //开启熔断后多久进入半熔断状态，断路器根据下一次的执行结果决定是否继续开启熔断
                .withMetricsRollingStatisticalWindowInMilliseconds(10000)   //10秒内如果大于等于3个错误请求就开启熔断
                .withMetricsRollingPercentileEnabled(false);    //关闭以错误请求百分比为度量指标的逻辑，仅按一个统计时间窗口内错误请求次数计算(主要是方便演示)

        HystrixThreadPoolProperties.Setter threadPoolPropertiesSetter = HystrixThreadPoolProperties.Setter()
                .withCoreSize(10)
                .withMaxQueueSize(10);

        commandSetter = HystrixCommand.Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(&quot;defalt-hystrix-group&quot;))
                .andThreadPoolKey(HystrixThreadPoolKey.Factory.asKey(&quot;default-hystrix-threadpool&quot;))
                .andCommandKey(HystrixCommandKey.Factory.asKey(&quot;default&quot;))
                .andCommandPropertiesDefaults(commandPropertiesSetter)
                .andThreadPoolPropertiesDefaults(threadPoolPropertiesSetter)
                ;
    }

    public CommandHelloWorld(String name) {
        super(commandSetter);
        this.name = name;
    }

    @Override
    protected String run() {
        // a real example would do work like a network call here
        return &quot;Hello &quot; + this.name;
    }
}

//调用
String s = new CommandHelloWorld(&quot;World&quot;).execute();
</code></pre>
<p>这种方式一般一个请求就得写一个自定义HystrixCommand，太复杂。当然也可以封装一个通用的CommonHystrixCommand，将业务逻辑抽象后传进来调用。不过一般工作中不会这么写，因为通过Properties配置文件或者javanica的方式会方便很多</p>
<pre><code class="language-java">// 这是一个利用Callable把业务方法和降级方法都传进来的例子，只是提供思路，当然还有其他更好的方式也是可以的
public static class DefaultHystrixCommand&lt;E&gt; extends HystrixCommand&lt;E&gt; {

        static HystrixCommand.Setter commandSetter;

        private Callable&lt;E&gt; callable;
        private Callable&lt;E&gt; fallBackCallable;

        static {
            HystrixCommandProperties.Setter commandPropertiesSetter = HystrixCommandProperties.Setter()
                    .withExecutionIsolationSemaphoreMaxConcurrentRequests(20)   //最大并发请求数
                    .withExecutionTimeoutInMilliseconds(5000)   //请求超过1.5秒执行降级逻辑
                    .withCircuitBreakerRequestVolumeThreshold(20)    //在一个统计窗口期内，请求失败3次熔断
                    .withCircuitBreakerSleepWindowInMilliseconds(2000)  //开启熔断后多久进入半熔断状态，断路器根据下一次的执行结果决定是否继续开启熔断
                    .withMetricsRollingStatisticalWindowInMilliseconds(10000)   //10秒内如果大于等于3个错误请求就开启熔断
                    .withMetricsRollingPercentileEnabled(false);    //关闭以错误请求百分比为度量指标的逻辑，仅按一个统计时间窗口内错误请求次数计算(主要是方便演示)

            HystrixThreadPoolProperties.Setter threadPoolPropertiesSetter = HystrixThreadPoolProperties.Setter()
                    .withCoreSize(10)
                    .withMaxQueueSize(8)
                    .withQueueSizeRejectionThreshold(4);

            commandSetter = HystrixCommand.Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(&quot;defalt-hystrix-group&quot;))
                    .andThreadPoolKey(HystrixThreadPoolKey.Factory.asKey(&quot;default-hystrix-threadpool&quot;))
                    .andCommandKey(HystrixCommandKey.Factory.asKey(&quot;default&quot;))
                    .andCommandPropertiesDefaults(commandPropertiesSetter)
                    .andThreadPoolPropertiesDefaults(threadPoolPropertiesSetter)
            ;
        }
        public DefaultHystrixCommand(Callable callable, Callable fallbackCallable) {
            super(commandSetter);
            this.callable = callable;
            this.fallBackCallable = fallbackCallable;
        }

        @Override
        protected E run() throws Exception {
            return this.callable.call();
        }

        @Override
        protected E getFallback(){
            try {
                return this.fallBackCallable.call();
            } catch (Exception e) {
                throw new RuntimeException(&quot;执行降级方法失败&quot;, e);
            }
        }
    }
</code></pre>
<h3 id="通过代码修改feignclient的hystrix参数配置">通过代码修改FeignClient的Hystrix参数配置</h3>
<ol>
<li>定义配置类</li>
</ol>
<pre><code class="language-java">@Configuration
public class DefaultFeignWithHystrixConfiguration {
    //这个是修改feign的请求超时时间，和Hystrix参数无关
    @Bean
    public Request.Options requestOptions() {
        return new Request.Options(1500, 1500);
    }

    @Bean
    public HystrixFeign.Builder feignBuilder() {
        return HystrixFeign.builder().setterFactory((target, method) -&gt; {
            HystrixCommandProperties.Setter commandPropertiesSetter = HystrixCommandProperties.Setter()
//                    .withExecutionIsolationSemaphoreMaxConcurrentRequests(20)   //最大并发请求数
                    .withExecutionTimeoutInMilliseconds(7000)   //请求超过1.5秒执行降级逻辑
                    .withCircuitBreakerRequestVolumeThreshold(20)    //在一个统计窗口期内，请求失败3次熔断
                    .withCircuitBreakerSleepWindowInMilliseconds(2000)  //开启熔断后多久进入半熔断状态，断路器根据下一次的执行结果决定是否继续开启熔断
                    .withMetricsRollingStatisticalWindowInMilliseconds(10000)   //10秒内如果大于等于3个错误请求就开启熔断
                    .withMetricsRollingPercentileEnabled(false);    //关闭以错误请求百分比为度量指标的逻辑，仅按一个统计时间窗口内错误请求次数计算(主要是方便演示)

            HystrixThreadPoolProperties.Setter threadPoolPropertiesSetter = HystrixThreadPoolProperties.Setter()
                    .withCoreSize(10)
                    .withMaxQueueSize(8)
                    .withQueueSizeRejectionThreshold(4);

//            String groupKey = target.name();
//            String commandKey = Feign.configKey(target.type(), method);
            String groupKey = &quot;default&quot;;
            String commandKey = &quot;default&quot;;
            return HystrixCommand.Setter
                    .withGroupKey(HystrixCommandGroupKey.Factory.asKey(groupKey))
                    .andCommandKey(HystrixCommandKey.Factory.asKey(commandKey))
                    .andCommandPropertiesDefaults(commandPropertiesSetter)
                    .andThreadPoolPropertiesDefaults(threadPoolPropertiesSetter);
        });
    }
}
</code></pre>
<p><font color="red">上面的配置类也不能放到@ComponentScan能扫描到的路径下，否则就会覆盖所有FeignClient的默认配置。</font></p>
<ol start="2">
<li>在需要的FeignClient上通过注解引用此配置就可以了</li>
</ol>
<pre><code class="language-java">@FeignClient(value = &quot;MICROSERVER-CALC&quot;, fallback = CalcServiceFallback.class, configuration = DefaultFeignWithHystrixConfiguration.class)
public interface CalcService {
}
</code></pre>
<h3 id="通过properties修改指定hystrixcommand的参数">通过Properties修改指定HystrixCommand的参数</h3>
<pre><code class="language-yml">hystrix:
  command:
    hystrixCommandName (如：calc_add_command):  #对应@HystrixCommand注解的commandKey属性，指定特定熔断器的属性(一般建议在代码中通过注解配置)，此处换成default可修改全局属性。
      execution:
        isolation:
          thread:
            timeoutInMilliseconds: 5000 #设置熔断器判定超时的时间，超过此时间的请求会执行降级逻辑，默认1s
      circuitBreaker:
        requestVolumeThreshold: 2 #设置熔断阈值，在熔断统计窗口期内，错误请求（超时、异常）次数达到阈值就会触发熔断，执行降级逻辑，默认20
        sleepWindowInMilliseconds: 10000  #设置熔断器多久进入半开状态，然后再次尝试确定熔断器是否应再次关闭，默认5s
        errorThresholdPercentage: 50  #设置在熔断统计窗口期内，错误请求达到百分之多少触发熔断，默认50
      metrics:
        rollingStats:
          timeInMilliseconds: 5000 #熔断度量窗口期时间， 默认10s
</code></pre>
<h3 id="通过properties修改hystrix全局默认参数">通过Properties修改Hystrix全局默认参数</h3>
<p>修改指定HystrixCommand的参数，将上面参数中command的名称calc_add_command换成default即可</p>
<h3 id="在properties中修改feignclient的hystrix参数">在Properties中修改FeignClient的Hystrix参数</h3>
<p>如果是修改某个FeignClient的hystrix参数，将上面参数中command的名称修改为FeignClient接口的simpleName.methodName(参数表)，中间不能有空格，例如：CalcServer#add(int,int)</p>
<p>参见 <a href="https://blog.csdn.net/xiao_jun_0820/article/details/78174502">源码资料</a></p>
<h3 id="常用配置项">常用配置项</h3>
<p>更多配置项请参见：<a href="https://github.com/Netflix/Hystrix/wiki/Configuration">Hystrix官方wiki</a></p>
<h4 id="关于queuesizerejectionthreshold与maxqueuesize">关于queueSizeRejectionThreshold与maxQueueSize</h4>
<p>官方的说法是maxQueueSize设置的是BlockingQueue的size，由于此size不能动态调整，所以maxQueueSize只能启动时加载，加载后无法动态调整。为了解决这个问题，官方提供了queueSizeRejectionThreshold参数，相当于人为的制造了一个“maxQueueSize”，当队列中达到此值后，再进来的新请求会直接reject，即使还没达到Queue的maxSize。</p>
<h2 id="hystrix-metrics-stream">Hystrix Metrics Stream</h2>
<blockquote>
<p>Hystrix Metrics Stream用于通过流式数据的方式输出Hystrix使用过程中产生的各项指标，可通过Hystrix Dashboard查看。</p>
</blockquote>
<h3 id="配置方法">配置方法</h3>
<ol>
<li>引入Hystrix完整依赖</li>
</ol>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-actuator&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<ol start="2">
<li>在Application启动类上开启Hystrix功能</li>
</ol>
<pre><code class="language-java">@SpringBootApplication
@EnableCircuitBreaker   //注意，要用metrics stream功能必须通过此注解显示打开断路器功能
public class ClientApplicationStart {
    public static void main(String[] args) {
        new SpringApplicationBuilder(ClientApplicationStart.class).web(true).run(args);
    }
}
</code></pre>
<p>通过浏览器访问： http://host:port/hystrix.stream 就可以看到Hystrix实时输出的流式JSON数据，将此地址配置到Hystrix Dashboard中就可以查看</p>
<p>注：Hystrix Metrics Stream必须配合SpringBoot Actuator一起使用</p>
<h2 id="hystrix的监控-hystrix-dashboard">Hystrix的监控 - Hystrix Dashboard</h2>
<blockquote>
<p>参见 <a href="#hystrix-dashboard">Hystrix Dashboard章节</a></p>
</blockquote>
<h1 id="zuulnetflix-统一网关-地址路由">Zuul(Netflix) - 统一网关、地址路由</h1>
<h2 id="zuul介绍">Zuul介绍</h2>
<blockquote>
<p>Zuul是Netflx开源的微服务网关。可以和Eureka、Ribbon、Hystrix配合使用，一个主要的功能就是可以将后端众多的微服务屏蔽、整合，对前端提供一套统一的服务(有点像是后端的Facade)。</p>
</blockquote>
<p>Zuul提供了以下几项支持：</p>
<ul>
<li>认证安全: 识别每一个资源的验证要求，并拒绝那些不符的请求</li>
<li>监控</li>
<li>动态路由: 动态将请求路由到不同后端集群</li>
<li>压力测试: 逐渐增加指向集群的流量，以了解性能</li>
<li>金丝雀测试: 灰度发布</li>
<li>流量控制: 为每一种负载类型分配对应容量，并弃用超出限定值的请求</li>
<li>服务迁移</li>
<li>静态资源响应处理: 边缘位置进行响应，避免转发到内部集群</li>
</ul>
<h2 id="zuul的用法">Zuul的用法</h2>
<ol>
<li>引入依赖包</li>
</ol>
<pre><code class="language-xml">&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
        &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;
    &lt;/dependency&gt;
    &lt;!-- eureka依赖是可选的，取决于是否需要代理接入eureka注册中心的服务 --&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
        &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre>
<ol start="2">
<li>在Application启动类添加注解</li>
</ol>
<ul>
<li>Server模式</li>
</ul>
<pre><code class="language-java">@SpringBootApplication
@EnableZuulServer
public class GatewayApplication {
    public static void main(String[] args) {
        SpringApplication.run(GatewayApplication.class, args);
    }
}
</code></pre>
<p>Server模式会关闭所有的代理相关功能</p>
<ul>
<li>Reverse Proxy模式</li>
</ul>
<pre><code class="language-java">@SpringBootApplication
@EnableZuulProxy
public class GatewayApplication {
    public static void main(String[] args) {
        SpringApplication.run(GatewayApplication.class, args);
    }
}
</code></pre>
<h3 id="动态路由需要在reverse-proxy模式下">动态路由(需要在Reverse Proxy模式下)</h3>
<h4 id="通过服务名代理">通过服务名代理</h4>
<pre><code class="language-yml">zuul:
  routes:
    microserver-calc: /calcs-direct/**  #直接通过服务名配置代理（必须是有效的服务名），所有访问/mi
</code></pre>
<h4 id="serviceidpath的方式">ServiceId+Path的方式</h4>
<pre><code class="language-yml">zuul:
  routes:
    calc-service: #通过path+serviceId的方式，这种适合配置参数比较多的情况（route的名字可以任意）
      path: /calcs/**  #匹配访问地址，访问地址如果可以匹配，则自动代理到对应的微服务
      serviceId: microserver-calc   #必须是有效的微服务名称
</code></pre>
<h4 id="忽略代理指定服务">忽略代理指定服务</h4>
<pre><code class="language-yml">zuul:
  routes:
    microserver-calc: /calcs-direct/** 
  ignored-services: '*' #除了显示配置到路由规则里的服务外（如：microserver-calc），不代理其他任务服务(也可以配置多个服务名:service1,service2)
  ignoredPatterns: /**/admin/** #更细粒度的忽略配置
  
</code></pre>
<h4 id="代理未接入服务注册中心的服务">代理未接入服务注册中心的服务</h4>
<pre><code class="language-yml">zuul:
  routes:
    service-calc:
      path: /calcs/**
      serviceId: service-calc-ribbon  #通过ribbon配置一个静态服务列表的service，用于代理为接入Eureka的服务
      
#ribbon:
#  eureka:
#    enabled: false

service-calc-ribbon:
  ribbon:
    NIWSServerListClassName: com.netflix.loadbalancer.ConfigurationBasedServerList  #如果不配置ServerList类型为ConfigurationBasedServerList的话就需要禁用ribbon的eureka支持
    ConnectTimeout: 500
    ReadTimeout: 2000
    listOfServers: http://localhost:8101,http://localhost:8102
</code></pre>
<h4 id="测过正则配置代理规则">测过正则配置代理规则</h4>
<pre><code class="language-java">// 从符合servicePattern的服务名中抽取出符合条件的内容，注入到路由模式中。
// 下面的配置可以将服务&quot;myusers-v1&quot;映射成&quot;/myusers/v1/**&quot;
@Bean
public PatternServiceRouteMapper serviceRouteMapper() {
    return new PatternServiceRouteMapper(&quot;(?&lt;name&gt;^.+)-(?&lt;version&gt;v.+$)&quot;,
            &quot;${name}/${version}&quot;);
}
</code></pre>
<p><font color="red">注：这种只针对注册到服务中心的服务生效</font></p>
<h4 id="添加全局访问前缀">添加全局访问前缀</h4>
<pre><code class="language-yml">server:
  port: 8080

zuul:
  routes:
    microserver-calc: /calcs/**  
  prefix: /api
  strip-prefix: true  #默认就是true
</code></pre>
<ul>
<li>当strip-prefix设置为true时<br>
访问：http://localhost:8080/api/calcs/**<br>
会被映射到微服务：microserver-calc/**</li>
<li>当strip-prefix设置为false时<br>
访问：http://localhost:8080/api/calcs/**<br>
会被映射到微服务：microserver-calc/api/**</li>
</ul>
<h4 id="给指定服务添加前缀">给指定服务添加前缀</h4>
<pre><code class="language-yml">server:
  port: 8080

zuul:
  routes:
    microserver-calc: #给指定服务配置前缀(这里的服务名称必须是真实的服务名，eureka或者手动用ribbon配置的名称) 
      path: /calc/**  #指定访问microserver-calc服务的前缀是/calc
      strip-prefix: false
</code></pre>
<h4 id="本地转发forward">本地转发(forward)</h4>
<pre><code class="language-yml">zuul:
  routes:
    route-name:
      path: /path-a/**
      url: forward:/path-b
</code></pre>
<h4 id="路由规则先后顺序">路由规则先后顺序</h4>
<pre><code class="language-yml">zuul:
  routes:
    users:
      path: /myusers/**
    legacy:
      path: /**
</code></pre>
<p>上面的配置如果用的是yml格式配置文件，如果访问/myusers/**会优先命中users服务；但是如果用properties文件，则可能导致无法路由到users服务</p>
<h3 id="聚合多个后端微服务提供统一api给前端">聚合多个后端微服务提供统一API给前端</h3>
<p>其实很简单，就是在Zuul层封装后端的多个请求，组合结果后返回给终端</p>
<pre><code class="language-java">@RestController
public class AggregationController {
  public static final Logger LOGGER = LoggerFactory.getLogger(ZuulApplication.class);

  @Autowired
  private RestTemplate restTemplate;
	
  @GetMapping(&quot;/aggregate/{id}&quot;)
  public Map&lt;String, User&gt; findById(@PathVariable Long id) throws Exception {
	  Map&lt;String, User&gt; dataMap = new HashMap&lt;&gt;();
	  User user = restTemplate.getForObject(&quot;http://microservice-provider-user/&quot; + id, User.class);
	  User orderUser = restTemplate.getForObject(&quot;http://microservice-consumer-order/user/&quot; + id, User.class);
	  dataMap.put(&quot;user&quot;, user);
	  dataMap.put(&quot;orderUser&quot;, orderUser);
	  return dataMap;
  }
}
</code></pre>
<h3 id="zuul的访问超时控制">Zuul的访问超时控制</h3>
<h4 id="通过serviceid代理的请求">通过ServiceId代理的请求</h4>
<p>由于通过ServiceId的方式代理的请求(包括手动配置的Ribbon 服务和自动服务发现的服务)会走Ribbon和Hystrix，所以我们要控制超时就包括Ribbon请求的超时和Hystrix的访问超时。</p>
<pre><code class="language-yml">test-service:
  ribbon:
    ReadTimeout:100
    ConnectTimeout:500
    MaxAutoRetries:1
    MaxAutoRetriesNextServer:1
</code></pre>
<p>上面这段配置通过Zuul访问test-service服务时，Ribbon的ConnectTimeout是500ms，ReadTimeout是100ms，重试次数为1次； Zuul会根据ribbon设置的超时时间和重试次数，自动设置Hystrix的超时时间(上面这段配置, Zuul会把Hystrix的超时时间设置为:(100+500)*2=1200ms<br>
当然，我们也可以通过添加下面的配置显示指定Hystrix参数</p>
<pre><code class="language-yml">hystrix:
  command:
    service-calc-ribbon:
      execution:
        isolation:
          thread:
            timeoutInMilliseconds: 3000
</code></pre>
<p>这里如果不显示设置，Zuul会根据ribbon设置的ConnectionTimeout和ReadTimeout自动确定Hystrix的超时时间（所以一般可以通过配置ribbon的超时时间来控制hystrix超时），由于ribbon默认重试次数是1，所以Hystrix的超时时间会被设置为(500+2000)*2=5000</p>
<h4 id="通过url代理的请求">通过URL代理的请求</h4>
<p>通过简单url配置的代理由于并没有走Ribbon和Hystrix，所有涉及到的超时参数只有ConnectTimeout和ReadTimeout，我们可以通过下面两个参数来分别设置：</p>
<pre><code>zuul.host.connect-timeout-millis=500 zuul.host.socket-timeout-millis=1000
</code></pre>
<h3 id="设置zuul请求使用的网络客户端">设置Zuul请求使用的网络客户端</h3>
<p>Zuul现在默认使用Apache HTTP Client代替已过时的Ribbon RestClient，可以通过下面的配置更改zuul使用的网络客户端</p>
<pre><code class="language-properties">ribbon.restclient.enabled=true #启用Ribbon RestClient
ribbon.okhttp.enabled=true #启用OkHttpClient
</code></pre>
<p>还可以通过自定义ClosableHttpClient或者OkHttpClient来设置Ribbon RestClient和OkHttpClient客户端的属性</p>
<h3 id="禁用zuul过滤器">禁用Zuul过滤器</h3>
<p>Zuul默认开启了好多各种用途的过滤器，我们也可以根据需要禁用自己不需要的过滤器（具体过滤器可查看ZuulFilter的子类）</p>
<pre><code class="language-properties">zuul.&lt;SimpleClassName&gt;.&lt;filterType&gt;.disable=true
</code></pre>
<p>如：禁用org.springframework.cloud.netflix.zuul.filters.post.SendResponseFilter</p>
<pre><code>zuul.SendResponseFilter.post.disable=true
</code></pre>
<h3 id="zuul针对特定路由的服务熔断">Zuul针对特定路由的服务熔断</h3>
<p>简单的降级处理示例：</p>
<pre><code class="language-java">@Component
public class MyGlobalFallbackProvider implements FallbackProvider {
    @Override
    public String getRoute() {
        return null;    //返回要设置降级的微服务名称或者配置的route名称，return &quot;*&quot;或者null 匹配所有微服务和路由（全局降级配置）
    }

    @Override
    public ClientHttpResponse fallbackResponse() {
        return response(HttpStatus.INTERNAL_SERVER_ERROR);
    }

    @Override
    public ClientHttpResponse fallbackResponse(Throwable cause) {
        if(cause instanceof HystrixTimeoutException) {
            return response(HttpStatus.GATEWAY_TIMEOUT);
        } else {
            return fallbackResponse();
        }
    }

    public ClientHttpResponse response(final HttpStatus httpStatus) {
        return new ClientHttpResponse() {
            @Override
            public HttpStatus getStatusCode() throws IOException {
                return httpStatus;
            }

            @Override
            public int getRawStatusCode() throws IOException {
                return httpStatus.value();
            }

            @Override
            public String getStatusText() throws IOException {
                return httpStatus.getReasonPhrase();
            }

            @Override
            public void close() {

            }

            @Override
            public InputStream getBody() throws IOException {
                return new ByteArrayInputStream(&quot;服务不可用，请稍后再试。&quot;.getBytes());
            }

            @Override
            public HttpHeaders getHeaders() {
                // headers设定
                HttpHeaders headers = new HttpHeaders();
//                MediaType mt = new MediaType(&quot;application&quot;, &quot;json&quot;, Charset.forName(&quot;UTF-8&quot;));
                MediaType mt = MediaType.APPLICATION_JSON_UTF8;
                headers.setContentType(mt);
                return headers;
            }
        };
    }
}
</code></pre>
<blockquote>
<p>Zuul 目前只支持服务级别的熔断，不支持具体到某个URL进行熔断。</p>
</blockquote>
<h3 id="zuul路由重试">Zuul路由重试</h3>
<p>有时候因为网络或者其它原因，服务可能会暂时的不可用，这个时候我们希望可以再次对服务进行重试，Zuul也帮我们实现了此功能，需要结合Spring Retry 一起来实现</p>
<ol>
<li>添加依赖</li>
</ol>
<pre><code class="language-xml">&lt;dependency&gt;
	&lt;groupId&gt;org.springframework.retry&lt;/groupId&gt;
	&lt;artifactId&gt;spring-retry&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<ol start="2">
<li>配置方法</li>
</ol>
<pre><code class="language-yml">#是否开启重试功能
zuul.retryable=true
#对当前服务的重试次数
ribbon.MaxAutoRetries=2
#切换相同Server的次数
ribbon.MaxAutoRetriesNextServer=0
</code></pre>
<p>这样我们就开启了Zuul的重试功能。</p>
<h3 id="zuul高可用">Zuul高可用</h3>
<p><img src="http://www.itmind.net/assets/images/2018/springcloud/zuul-case.png" alt="Zuul高可用"><br>
我们实际使用Zuul的方式如上图，不同的客户端使用不同的负载将请求分发到后端的Zuul，Zuul在通过Eureka调用后端服务，最后对外输出。因此为了保证Zuul的高可用性，前端可以同时启动多个Zuul实例进行负载，在Zuul的前端使用<font color="red">Nginx</font>或者<font color="red">F5</font>进行负载转发以达到高可用性。</p>
<h3 id="zuul的核心filter">Zuul的核心——Filter</h3>
<p>Filter是Zuul的核心，用来实现对外服务的控制。Filter的生命周期有4个，分别是“PRE”、“ROUTING”、“POST”、“ERROR”，整个生命周期可以用下图来表示。<br>
<img src="http://www.itmind.net/assets/images/2018/springcloud/zuul-core.png" alt="Zuul Filter"><br>
Zuul大部分功能都是通过过滤器来实现的，这些过滤器类型对应于请求的典型生命周期。</p>
<ul>
<li>PRE： 这种过滤器在请求被路由之前调用。我们可利用这种过滤器实现身份验证、在集群中选择请求的微服务、记录调试信息等。</li>
<li>ROUTING：这种过滤器将请求路由到微服务。这种过滤器用于构建发送给微服务的请求，并使用Apache HttpClient或Netfilx Ribbon请求微服务。</li>
<li>POST：这种过滤器在路由到微服务以后执行。这种过滤器可用来为响应添加标准的HTTP Header、收集统计信息和指标、将响应从微服务发送给客户端等。</li>
<li>ERROR：在其他阶段发生错误时执行该过滤器。 除了默认的过滤器类型，Zuul还允许我们创建自定义的过滤器类型。例如，我们可以定制一种STATIC类型的过滤器，直接在Zuul中生成响应，而不将请求转发到后端的微服务。</li>
</ul>
<h4 id="zuul中默认实现的filter">Zuul中默认实现的Filter</h4>
<table>
<thead>
<tr>
<th>类型</th>
<th>顺序</th>
<th>过滤器</th>
<th>功能</th>
</tr>
</thead>
<tbody>
<tr>
<td>pre</td>
<td>-3</td>
<td>ServletDetectionFilter</td>
<td>标记处理Servlet的类型</td>
</tr>
<tr>
<td>pre</td>
<td>-2</td>
<td>Servlet30WrapperFilter</td>
<td>包装HttpServletRequest请求</td>
</tr>
<tr>
<td>pre</td>
<td>-1</td>
<td>FormBodyWrapperFilter</td>
<td>包装请求体</td>
</tr>
<tr>
<td>route</td>
<td>1</td>
<td>DebugFilter</td>
<td>标记调试标志</td>
</tr>
<tr>
<td>route</td>
<td>5</td>
<td>PreDecorationFilter</td>
<td>处理请求上下文供后续使用</td>
</tr>
<tr>
<td>route</td>
<td>10</td>
<td>RibbonRoutingFilter</td>
<td>serviceId请求转发</td>
</tr>
<tr>
<td>route</td>
<td>100</td>
<td>SimpleHostRoutingFilter</td>
<td>url请求转发</td>
</tr>
<tr>
<td>route</td>
<td>500</td>
<td>SendForwardFilter</td>
<td>forward请求转发</td>
</tr>
<tr>
<td>post</td>
<td>0</td>
<td>SendErrorFilter</td>
<td>处理有错误的请求响应</td>
</tr>
<tr>
<td>post</td>
<td>1000</td>
<td>SendResponseFilter</td>
<td>处理正常的请求响应</td>
</tr>
</tbody>
</table>
<h4 id="禁用指定的filter">禁用指定的Filter</h4>
<pre><code class="language-yml">zuul:
  FormBodyWrapperFilter:
    pre:
	  disable: true
</code></pre>
<h4 id="自定义filter示例">自定义Filter示例</h4>
<p>我们假设有这样一个场景，因为服务网关应对的是外部的所有请求，为了避免产生安全隐患，我们需要对请求做一定的限制，比如请求中含有Token便让请求继续往下走，如果请求不带Token就直接返回并给出提示。</p>
<ol>
<li>首先自定义一个Filter，在run()方法中验证参数是否含有Token。</li>
</ol>
<pre><code class="language-java">public class TokenFilter extends ZuulFilter {

    private final Logger logger = LoggerFactory.getLogger(TokenFilter.class);

    @Override
    public String filterType() {
        return &quot;pre&quot;; // 可以在请求被路由之前调用
    }

    @Override
    public int filterOrder() {
        return 0; // filter执行顺序，通过数字指定 ,优先级为0，数字越大，优先级越低
    }

    @Override
    public boolean shouldFilter() {
        return true;// 是否执行该过滤器，此处为true，说明需要过滤
    }

    @Override
    public Object run() {
        RequestContext ctx = RequestContext.getCurrentContext();
        HttpServletRequest request = ctx.getRequest();

        logger.info(&quot;---&gt;&gt;&gt; TokenFilter {},{}&quot;, request.getMethod(), request.getRequestURL().toString());

        String token = request.getParameter(&quot;token&quot;);// 获取请求的参数

        if (StringUtils.isNotBlank(token)) {
            ctx.setSendZuulResponse(true); //对请求进行路由
            ctx.setResponseStatusCode(200);
            ctx.set(&quot;isSuccess&quot;, true);
            return null;
        } else {
            ctx.setSendZuulResponse(false); //不对其进行路由
            ctx.setResponseStatusCode(400);
            ctx.setResponseBody(&quot;token is empty&quot;);
            ctx.set(&quot;isSuccess&quot;, false);
            return null;
        }
    }

}
</code></pre>
<ol start="2">
<li>将TokenFilter加入到请求拦截队列，在启动类中添加以下代码</li>
</ol>
<pre><code class="language-java">@Bean
public TokenFilter tokenFilter() {
	return new TokenFilter();
}
</code></pre>
<p>通过上面这例子我们可以看出，我们可以使用“PRE”类型的Filter做很多的验证工作，在实际使用中我们可以结合shiro、oauth2.0等技术去做鉴权、验证。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[SpringCloud全局依赖定义]]></title>
        <id>https://ysjhhhhhhh.github.io/post/springcloud-quan-ju-yi-lai-ding-yi</id>
        <link href="https://ysjhhhhhhh.github.io/post/springcloud-quan-ju-yi-lai-ding-yi">
        </link>
        <updated>2018-06-17T11:28:54.000Z</updated>
        <content type="html"><![CDATA[<h1 id="全局依赖说明">全局依赖说明</h1>
<blockquote>
<p>SpringCloud是基于SpringBoot来构建的，一个SpringCloud工程本身也是一个SpringBoot工程。所以SpringCloud工程也需要添加SpringBoot依赖。</p>
</blockquote>
<h1 id="推荐的配置方法">推荐的配置方法</h1>
<p>总的来说配置方法分为下面几步</p>
<ol>
<li>新建一个全局的parent依赖工程，集中管理依赖</li>
<li>让微服务模块继承全局的pom</li>
<li>在具体微服务模块中添加自己需要的依赖（不加版本）</li>
</ol>
<p>其中，定义全局依赖有下面两种方式</p>
<h2 id="继承springboot依赖">继承SpringBoot依赖</h2>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;com.lanou3g&lt;/groupId&gt;
    &lt;artifactId&gt;springcloud-parent&lt;/artifactId&gt;
    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
    &lt;packaging&gt;pom&lt;/packaging&gt;

    &lt;parent&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
        &lt;!-- 注意：SpringCloud最新的Greenwich版本是基于SpringBoot2.1.x(Greenwich)版本构建的
            所以这里不支持SpringBoot2.2.x版本
            具体SpringBoot与SpringCloud版本对应关系参见：https://spring.io/projects/spring-cloud页面最下方的Release Trains
         --&gt;
        &lt;version&gt;2.1.6.RELEASE&lt;/version&gt;
        &lt;relativePath /&gt;
    &lt;/parent&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
            &lt;version&gt;1.18.10&lt;/version&gt;
            &lt;scope&gt;provided&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;
            &lt;artifactId&gt;logback-classic&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;!--&lt;dependency&gt;
            &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;
            &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt;
        &lt;/dependency&gt;--&gt;
    &lt;/dependencies&gt;

    &lt;dependencyManagement&gt;
        &lt;dependencies&gt;
            &lt;!-- 定义SpringCloud依赖版本 --&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;
                &lt;version&gt;Greenwich.SR2&lt;/version&gt;
                &lt;type&gt;pom&lt;/type&gt;
                &lt;scope&gt;import&lt;/scope&gt;
            &lt;/dependency&gt;
        &lt;/dependencies&gt;
    &lt;/dependencyManagement&gt;
&lt;/project&gt;
</code></pre>
<h2 id="不继承springboot依赖">不继承SpringBoot依赖</h2>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;com.lanou3g&lt;/groupId&gt;
    &lt;artifactId&gt;springcloud-parent&lt;/artifactId&gt;
    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
    &lt;packaging&gt;pom&lt;/packaging&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
            &lt;version&gt;1.18.10&lt;/version&gt;
            &lt;scope&gt;provided&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;
            &lt;artifactId&gt;logback-classic&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;!--&lt;dependency&gt;
            &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;
            &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt;
        &lt;/dependency&gt;--&gt;
    &lt;/dependencies&gt;

    &lt;dependencyManagement&gt;
        &lt;dependencies&gt;
            &lt;!-- 定义SpringBoot依赖版本 --&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt;
                &lt;!-- 注意：SpringCloud最新的Greenwich版本是基于SpringBoot2.1.x(Greenwich)版本构建的
                    所以这里不支持SpringBoot2.2.x版本
                    具体SpringBoot与SpringCloud版本对应关系参见：https://spring.io/projects/spring-cloud页面最下方的Release Trains
                 --&gt;
                &lt;!--&lt;version&gt;2.2.1.RELEASE&lt;/version&gt;--&gt;
                &lt;version&gt;2.1.6.RELEASE&lt;/version&gt;
                &lt;type&gt;pom&lt;/type&gt;
                &lt;scope&gt;import&lt;/scope&gt;
            &lt;/dependency&gt;
            &lt;!-- 定义SpringCloud依赖版本 --&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;
                &lt;version&gt;Greenwich.SR2&lt;/version&gt;
                &lt;type&gt;pom&lt;/type&gt;
                &lt;scope&gt;import&lt;/scope&gt;
            &lt;/dependency&gt;
        &lt;/dependencies&gt;
    &lt;/dependencyManagement&gt;
&lt;/project&gt;
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dubbo框架]]></title>
        <id>https://ysjhhhhhhh.github.io/post/dubbo-kuang-jia</id>
        <link href="https://ysjhhhhhhh.github.io/post/dubbo-kuang-jia">
        </link>
        <updated>2018-06-15T11:32:43.000Z</updated>
        <content type="html"><![CDATA[<h2 id="dubbo介绍">Dubbo介绍</h2>
<h3 id="互联网架构演变过程">互联网架构演变过程</h3>
<figure data-type="image" tabindex="1"><img src="http://dubbo.apache.org/docs/zh-cn/user/sources/images/dubbo-architecture-roadmap.jpg" alt=""></figure>
<h4 id="单一应用架构">单一应用架构</h4>
<p>当网站流量很小时，只需一个应用，将所有功能都部署在一起，以减少部署节点和成本。此时，用于简化增删改查工作量的数据访问框架(ORM)是关键。</p>
<h4 id="垂直应用架构">垂直应用架构</h4>
<p>当访问量逐渐增大，单一应用增加机器带来的加速度越来越小，将应用拆成互不相干的几个应用，以提升效率。此时，用于加速前端页面开发的Web框架(MVC)是关键。</p>
<h4 id="分布式服务架构">分布式服务架构</h4>
<p>当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。此时，用于提高业务复用及整合的分布式服务框架(RPC)是关键。</p>
<h4 id="流动计算架构">流动计算架构</h4>
<p>当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个调度中心基于访问压力实时管理集群容量，提高集群利用率。此时，用于提高机器利用率的资源调度和治理中心(SOA)是关键。</p>
<h3 id="dubbo解决了什么问题">Dubbo解决了什么问题</h3>
<p>在大规模服务化之前，应用可能只是通过 RMI 或 Hessian 等工具，简单的暴露和引用远程服务，通过配置服务的URL地址进行调用，通过 F5 等硬件进行负载均衡。</p>
<p><strong>当服务越来越多时，服务 URL 配置管理变得非常困难，F5 硬件负载均衡器的单点压力也越来越大。</strong> 此时需要一个服务注册中心，动态地注册和发现服务，使服务的位置透明。并通过在消费方获取服务提供方地址列表，实现软负载均衡和 Failover，降低对 F5 硬件负载均衡器的依赖，也能减少部分成本。</p>
<p><strong>当进一步发展，服务间依赖关系变得错踪复杂，甚至分不清哪个应用要在哪个应用之前启动，架构师都不能完整的描述应用的架构关系。</strong> 这时，需要自动画出应用间的依赖关系图，以帮助架构师理清理关系。</p>
<p><strong>接着，服务的调用量越来越大，服务的容量问题就暴露出来，这个服务需要多少机器支撑？什么时候该加机器？</strong> 为了解决这些问题，第一步，要将服务现在每天的调用量，响应时间，都统计出来，作为容量规划的参考指标。其次，要可以动态调整权重，在线上，将某台机器的权重一直加大，并在加大的过程中记录响应时间的变化，直到响应时间到达阈值，记录此时的访问量，再以此访问量乘以机器数反推总容量。</p>
<p>除了服务注册中心之外， Dubbo还帮我们解决了服务远程调用的问题。 之前我们需要显示通过HttpClient、OkHttp、RestTemplate。。这些技术去通过Http协议调用远程服务，其间还要手动处理序列化、反序列化问题。而Dubbo将这些细节屏蔽了，对于我们开发者来说，调用远程的服务就像调用本地服务一样方便。</p>
<blockquote>
<p>总的来说， Dubbo主要帮我们解决了分布式应用中的服务注册发现和RPC（Remote Procedure Call）远程调用这两个核心问题。</p>
</blockquote>
<h2 id="快速开始">快速开始</h2>
<p>因为服务提供者和服务消费者都需要引入共同的服务接口。所以在Dubbo的最佳实践上要求我们将服务接口抽出来作为单独的一个模块，供服务提供者、消费者引用。这样Dubbo应用就包含三部分：共同的api接口、服务提供者、服务消费者三部分（其中服务提供者和消费者都需要依赖API接口）</p>
<figure data-type="image" tabindex="2"><img src="https://ysjhhhhhhh.github.io/post-images/1576143347940.png" alt=""></figure>
<ol>
<li>
<p>引入依赖</p>
<p>依赖主要包含： Spring、Dubbo</p>
<pre><code class="language-xml">&lt;properties&gt;
    &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
    &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;
    &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;
    &lt;spring.version&gt;5.2.1.RELEASE&lt;/spring.version&gt;
    &lt;dubbo.version&gt;2.7.3&lt;/dubbo.version&gt;
&lt;/properties&gt;

&lt;dependency&gt;
    &lt;groupId&gt;org.springframework&lt;/groupId&gt;
    &lt;artifactId&gt;spring-context&lt;/artifactId&gt;
    &lt;version&gt;${spring.version}&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt;
    &lt;artifactId&gt;dubbo&lt;/artifactId&gt;
    &lt;version&gt;${dubbo.version}&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
</li>
<li>
<p>编写核心API接口</p>
<p>新建一个单独的maven module(如<code>dubbo-service-api</code>)，在里面添加需要远程访问的接口</p>
<pre><code class="language-java">public interface ICalcService {

    int plus(int num1, int num2);

    int minus(int num1, int num2);

}
</code></pre>
</li>
<li>
<p>开发服务提供者</p>
<p>​	新建单独的服务提供者模块 (如<code>dubbo-service-provider</code>)</p>
<ol>
<li>
<p>开发API接口实现逻辑</p>
<pre><code class="language-java">public class CalcServiceImpl implements ICalcService {
    public int plus(int num1, int num2) {
        int result = num1 + num2;
        System.out.println(num1 + &quot; + &quot; + num2 + &quot; = &quot; + result);
        return result;
    }

    public int minus(int num1, int num2) {
        int result = num1 - num2;
        System.out.println(num1 + &quot; - &quot; + num2 + &quot; = &quot; + result);
        return result;
    }
}
</code></pre>
</li>
<li>
<p>通过Dubbo注册中心暴露服务（发布服务到注册中心）</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;
       xmlns:dubbo=&quot;http://dubbo.apache.org/schema/dubbo&quot;
       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans
        http://www.springframework.org/schema/beans/spring-beans.xsd
        http://dubbo.apache.org/schema/dubbo
        http://dubbo.apache.org/schema/dubbo/dubbo.xsd&quot;&gt;

    &lt;!-- 给dubbo应用命名 --&gt;
    &lt;dubbo:application name=&quot;hello-dubbo&quot;&gt;
        &lt;dubbo:parameter key=&quot;qos.enable&quot; value=&quot;false&quot; /&gt;
    &lt;/dubbo:application&gt;

    &lt;!-- 配置Dubbo服务注册中心（这里使用的是基于multicast协议的注册中心） --&gt;
    &lt;dubbo:registry address=&quot;multicast://224.5.6.7:1234&quot; /&gt;
    &lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20880&quot; /&gt;
    
    &lt;!-- 对外暴露服务 --&gt;
    &lt;dubbo:service interface=&quot;com.lanou3g.dubbo.service.ICalcService&quot; ref=&quot;calcService&quot; /&gt;

    &lt;bean id=&quot;calcService&quot; class=&quot;com.lanou3g.dubbo.service.impl.CalcServiceImpl&quot; /&gt;

&lt;/beans&gt;
</code></pre>
</li>
<li>
<p>启动服务提供者</p>
<pre><code class="language-java">public class ProviderApplication {
    public static void main(String[] args) throws IOException {

        ClassPathXmlApplicationContext ctx = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;);
        ctx.start();
        ctx.registerShutdownHook();

        System.out.println(&quot;Provider启动完成&quot;);

        // 阻塞当前应用，直到输入任意字符后才退出
        System.in.read();
    }
}
</code></pre>
</li>
</ol>
</li>
<li>
<p>开发服务消费者</p>
<p>​	新建一个单独的服务消费者模块(如<code>dubbo-service-consumer</code>)</p>
<ol>
<li>
<p>通过Dubbo注册中心引用远程服务</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;
       xmlns:p=&quot;http://www.springframework.org/schema/p&quot;
       xmlns:dubbo=&quot;http://dubbo.apache.org/schema/dubbo&quot;
       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans
        http://www.springframework.org/schema/beans/spring-beans.xsd
        http://dubbo.apache.org/schema/dubbo
        http://dubbo.apache.org/schema/dubbo/dubbo.xsd&quot;&gt;

    &lt;!-- 给dubbo应用命名 --&gt;
    &lt;dubbo:application name=&quot;hello-dubbo&quot;&gt;
        &lt;dubbo:parameter key=&quot;qos.enable&quot; value=&quot;false&quot; /&gt;
    &lt;/dubbo:application&gt;

    &lt;!-- 配置Dubbo服务注册中心（这里使用的是基于multicast协议的注册中心） --&gt;
    &lt;dubbo:registry address=&quot;multicast://224.5.6.7:1234?unicast=false&quot; /&gt;

    &lt;!-- 指定Dubbo底层在远程调用服务时通过什么协议，哪个端口调用 --&gt;
    &lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20880&quot; /&gt;

    &lt;dubbo:reference id=&quot;calcService&quot; interface=&quot;com.lanou3g.dubbo.service.ICalcService&quot; /&gt;

&lt;/beans&gt;
</code></pre>
</li>
</ol>
</li>
<li>
<p>通过公共的API接口调用服务方法，完成远程接口调用</p>
<pre><code class="language-java">   public class ConsumerApplication {
       public static void main(String[] args) {
           ClassPathXmlApplicationContext ctx = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;);
           ctx.registerShutdownHook();
           ctx.start();
   
           // 通过公共接口像调用本地方法一样调用远程服务
   		ICalcService calcService = ctx.getBean(&quot;calcService&quot;, ICalcService.class);
           int result = calcService.plus(11, 89);
           System.out.println(&quot;调用远程服务计算结果：&quot; + result);
       }
   }
</code></pre>
</li>
</ol>
<h2 id="深入dubbo知识点">深入Dubbo知识点</h2>
<h3 id="dubbo的架构图">Dubbo的架构图</h3>
<figure data-type="image" tabindex="3"><img src="http://dubbo.apache.org/docs/zh-cn/user/sources/images/dubbo-architecture.jpg" alt=""></figure>
<ol start="0">
<li>服务容器负责启动，加载，运行服务提供者。</li>
<li>服务提供者在启动时，向注册中心注册自己提供的服务。</li>
<li>服务消费者在启动时，向注册中心订阅自己所需的服务。</li>
<li>注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。</li>
<li>服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。</li>
<li>服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。</li>
</ol>
<h3 id="dubbo中的角色">Dubbo中的角色</h3>
<table>
<thead>
<tr>
<th>节点</th>
<th>角色说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Provider</code></td>
<td>暴露服务的服务提供方</td>
</tr>
<tr>
<td><code>Consumer</code></td>
<td>调用远程服务的服务消费方</td>
</tr>
<tr>
<td><code>Registry</code></td>
<td>服务注册与发现的注册中心</td>
</tr>
<tr>
<td><code>Monitor</code></td>
<td>统计服务的调用次数和调用时间的监控中心</td>
</tr>
<tr>
<td><code>Container</code></td>
<td>服务运行容器</td>
</tr>
</tbody>
</table>
<h3 id="dubbo支持的服务注册中心">Dubbo支持的服务注册中心</h3>
<h4 id="基于zookeeper的注册中心">基于Zookeeper的注册中心</h4>
<ol>
<li>
<p>需要启动zookeeper服务</p>
<p>下载、启动zookeeper服务</p>
</li>
<li>
<p>在dubbo的应用中修改注册中心配置为zookeeper方式</p>
<pre><code class="language-xml">&lt;!-- 服务提供方和消费方都添加如下配置 --&gt;
&lt;!-- 配置基于zookeeper的服务注册中心  --&gt;
&lt;!--&lt;dubbo:registry address=&quot;zookeeper://127.0.0.1:2181&quot; client=&quot;curator&quot; /&gt;--&gt;
</code></pre>
</li>
<li>
<p>在dubbo应用中需要添加zookeeper客户端依赖</p>
<pre><code class="language-xml">&lt;!-- zookeeper客户端 —— curator依赖 --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;com.netflix.curator&lt;/groupId&gt;
    &lt;artifactId&gt;curator-framework&lt;/artifactId&gt;
    &lt;version&gt;1.1.10&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.curator&lt;/groupId&gt;
    &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt;
    &lt;version&gt;4.0.1&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
</li>
</ol>
<h4 id="基于redis的注册中心">基于Redis的注册中心</h4>
<ol>
<li>
<p>启动redis服务</p>
</li>
<li>
<p>修改注册中心配置为redis</p>
<pre><code class="language-xml">&lt;!-- 配置基于redis的服务注册中心 --&gt;
&lt;dubbo:registry address=&quot;redis://localhost:6379&quot; /&gt;
</code></pre>
<blockquote>
<p>注意： 如果说Redis需要口令验证，则不能作为Dubbo的注册中心</p>
</blockquote>
</li>
<li>
<p>添加redis客户端依赖到工程中（服务提供者、消费者都需要）</p>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;
    &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;
    &lt;version&gt;2.7.0&lt;/version&gt;
&lt;/dependency&gt;

&lt;dependency&gt;
    &lt;groupId&gt;redis.clients&lt;/groupId&gt;
    &lt;artifactId&gt;jedis&lt;/artifactId&gt;
    &lt;version&gt;3.1.0&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
</li>
</ol>
<h4 id="基于multicast组播的注册中心">基于Multicast组播的注册中心</h4>
<blockquote>
<p>参见快速开始配置</p>
</blockquote>
<h2 id="dubbo支持的配置方式">Dubbo支持的配置方式</h2>
<p>Dubbo支持以下几种方式的配置方式：</p>
<ul>
<li>基于SpringBean的XML配置</li>
<li>基于注解的配置</li>
<li>基于Properties属性文件的配置</li>
<li>基于硬编码的配置</li>
<li>支持加载存储在外部配置中心中的配置（如存储在zookeeper中的dubbo.properties配置）</li>
</ul>
<h3 id="dubbo支持的rpc通讯协议">Dubbo支持的RPC通讯协议</h3>
<p>Dubbo支持以下几种服务远程调用的通讯协议：</p>
<ul>
<li>dubbo(默认)</li>
<li>rest</li>
<li>http</li>
<li>redis</li>
<li>webservice</li>
<li>......</li>
</ul>
<h2 id="springboot整合dubbo">SpringBoot整合Dubbo</h2>
<p>现在SpringBoot技术非常流行，可以极大程度上让我们从管理项目依赖和配置的工作中解放出来，更专注于核心业务实现（更傻瓜），Dubbo官方也提供了对SpringBoot的支持。</p>
<p>使用步骤如下：</p>
<h3 id="第一步在parent中定义所有依赖">第一步：在parent中定义所有依赖</h3>
<p>在企业开发中的建议做法，便于统一管理整个工程中所有模块的依赖和版本。如果你不想这样做，这步可以省略，直接在各个module中添加需要的依赖也是可以滴。</p>
<ul>
<li>pom.xml</li>
</ul>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;com.lanou3g&lt;/groupId&gt;
    &lt;artifactId&gt;dubbo-springboot-parent&lt;/artifactId&gt;
    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;

    &lt;properties&gt;
        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
        &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;
        &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;
    &lt;/properties&gt;

    &lt;dependencyManagement&gt;
        &lt;dependencies&gt;
            &lt;!-- 引入SpringBoot --&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt;
                &lt;version&gt;2.2.1.RELEASE&lt;/version&gt;
                &lt;type&gt;pom&lt;/type&gt;
                &lt;scope&gt;import&lt;/scope&gt;
            &lt;/dependency&gt;

            &lt;!-- dubbo springboot依赖 --&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt;
                &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt;
                &lt;version&gt;2.7.3&lt;/version&gt;
            &lt;/dependency&gt;

            &lt;!-- redis注册中心依赖 --&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;
                &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;
                &lt;version&gt;2.7.0&lt;/version&gt;
            &lt;/dependency&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;redis.clients&lt;/groupId&gt;
                &lt;artifactId&gt;jedis&lt;/artifactId&gt;
                &lt;version&gt;3.1.0&lt;/version&gt;
            &lt;/dependency&gt;

            &lt;!-- zookeeper注册中心依赖 --&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;com.netflix.curator&lt;/groupId&gt;
                &lt;artifactId&gt;curator-framework&lt;/artifactId&gt;
                &lt;version&gt;1.1.10&lt;/version&gt;
            &lt;/dependency&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;org.apache.curator&lt;/groupId&gt;
                &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt;
                &lt;version&gt;4.0.1&lt;/version&gt;
            &lt;/dependency&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;com.lanou3g&lt;/groupId&gt;
                &lt;artifactId&gt;dubbo-springboot-api&lt;/artifactId&gt;
                &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
            &lt;/dependency&gt;
        &lt;/dependencies&gt;
    &lt;/dependencyManagement&gt;
&lt;/project&gt;
</code></pre>
<h3 id="第二步定义公共的服务api接口模块">第二步：定义公共的服务API接口模块</h3>
<p>该模块不需要添加什么依赖， 主要是定义各个服务的接口文件。以便让服务提供者和消费者依赖和复用。</p>
<ul>
<li>pom.xml</li>
</ul>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;com.lanou3g&lt;/groupId&gt;
    &lt;artifactId&gt;dubbo-springboot-api&lt;/artifactId&gt;
    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
&lt;/project&gt;
</code></pre>
<ul>
<li>服务接口示例：</li>
</ul>
<p>IHelloService.java</p>
<pre><code class="language-java">package com.lanou3g.dubbo.service;

public interface IHelloService {
    String hello();
    String hello(String name);
}
</code></pre>
<h3 id="第三步开发服务提供者模块">第三步：开发服务提供者模块</h3>
<p>该模块提供了服务接口的具体实现逻辑，并且通过Dubbo的服务注册中心将服务暴露出去。</p>
<ul>
<li>pom.xml</li>
</ul>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;parent&gt;
        &lt;artifactId&gt;dubbo-springboot-parent&lt;/artifactId&gt;
        &lt;groupId&gt;com.lanou3g&lt;/groupId&gt;
        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
        &lt;relativePath&gt;../dubbo-springboot-parent/pom.xml&lt;/relativePath&gt;
    &lt;/parent&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;artifactId&gt;dubbo-springboot-provider&lt;/artifactId&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt;
            &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;!-- redis注册中心依赖 --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;redis.clients&lt;/groupId&gt;
            &lt;artifactId&gt;jedis&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;
            &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;!-- 如果注册中心是zookeeper换成此依赖 --&gt;
        &lt;!--&lt;dependency&gt;
            &lt;groupId&gt;com.netflix.curator&lt;/groupId&gt;
            &lt;artifactId&gt;curator-framework&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.curator&lt;/groupId&gt;
            &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt;
        &lt;/dependency&gt;
		--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.lanou3g&lt;/groupId&gt;
            &lt;artifactId&gt;dubbo-springboot-api&lt;/artifactId&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
&lt;/project&gt;
</code></pre>
<ul>
<li>服务实现示例代码</li>
</ul>
<p>HelloService.java</p>
<pre><code class="language-java">package com.lanou3g.provider.service;

import com.lanou3g.dubbo.service.IHelloService;
import org.apache.dubbo.config.annotation.Service;

// 通过此注解将服务注册到Dubbo的服务注册中心（注意包名是dubbo而不是spring的）
// 该注解还支持添加服务的版本、所属组等参数，都是可选的
@Service
public class HelloService implements IHelloService {
    @Override
    public String hello() {
        String msg = &quot;Hello Dubbo&quot;;
        System.out.println(msg);
        return msg;
    }

    @Override
    public String hello(String name) {
        String msg = &quot;Hello, &quot; + name;
        System.out.println(msg);
        return msg;
    }
}
</code></pre>
<ul>
<li>配置Dubbo的注册中心、应用名等参数</li>
</ul>
<p>application.yml</p>
<pre><code class="language-yml">dubbo:
  application:
    name: hello-dubbo-springboot
    qos-enable: false

  registry:
    address: redis://localhost:6379
</code></pre>
<ul>
<li>启动类</li>
</ul>
<p>ProviderApplication.java</p>
<pre><code class="language-java">package com.lanou3g;

import org.apache.dubbo.config.spring.context.annotation.EnableDubbo;
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;

@SpringBootApplication
// 服务提供方一定要添加此注解，开启Dubbo的注解扫描（扫描我们配置的@Service注解）
@EnableDubbo(scanBasePackages = &quot;com.lanou3g.provider.service&quot;)
public class ProvicerApplication {
    public static void main(String[] args) {
        SpringApplication.run(ProvicerApplication.class, args);
    }
}

</code></pre>
<h3 id="第四步开发服务消费者模块">第四步：开发服务消费者模块</h3>
<p>该模块同样依赖公共的服务接口模块，通过接口类型，结合Dubbo的服务中心和RPC可以像调用本地Service方法一样调用远程的服务接口实现。</p>
<ul>
<li>
<p>pom依赖</p>
<p>和服务提供者一样，参见上面服务提供者pom文件</p>
</li>
<li>
<p>配置Dubbo的注册中心、应用名等参数</p>
<p>application.yml</p>
<pre><code class="language-yml">dubbo:
  application:
    name: hello-dubbo-springboot
    qos-enable: false

  registry:
    address: redis://localhost:6379
</code></pre>
</li>
<li>
<p>在需要调用远程服务的地方通过Dubbo引入远程服务（这里直接在Application类中通过生命周期方法调用）</p>
<p>ConsumerApplication.java</p>
<pre><code class="language-java">package com.lanou3g;

import com.lanou3g.dubbo.service.IHelloService;
import org.apache.dubbo.config.annotation.Reference;
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;

import javax.annotation.PostConstruct;

@SpringBootApplication
public class ConsumerApplication {
    
    // 通过Dubbo提供的Reference注解引用远程服务
    // 如果服务提供者暴露服务时配置的版本、所属组等参数，这里引用时也需要加上，所有参数匹配才能调用
    @Reference
    private IHelloService helloService;

    public static void main(String[] args) {
        SpringApplication.run(ConsumerApplication.class, args);
    }

    @PostConstruct
    public void invokeService() {
        String result = helloService.hello();
        System.out.println(&quot;远程服务hello()调用结果: &quot; + result);

        result = helloService.hello(&quot;John&quot;);
        System.out.println(&quot;远程服务hello(name)调用结果: &quot; + result);
    }
}
</code></pre>
</li>
</ul>
<h2 id="dubbo监控工具dubboadmin">Dubbo监控工具DubboAdmin</h2>
<ol>
<li>
<p>下载安装</p>
</li>
<li>
<p>修改配置</p>
<p>主要修改dubbo注册中心地址为你现在使用的注册中心地址：</p>
<pre><code class="language-proper">dubbo.registry.address=zookeeper://teacher.lanou.com:2181?client=curator
# dubbo.registry.address=multicast://224.5.6.7:1234?unicast=false
# dubbo.registry.address=redis://127.0.0.1:6379
</code></pre>
</li>
<li>
<p>重新打包</p>
<pre><code>mvn clean package
</code></pre>
</li>
<li>
<p>启动</p>
<pre><code>java -jar dubbo-admin-0.0.1-SNAPSHOT.jar
</code></pre>
</li>
<li>
<p>使用方法</p>
<p>登录时，用户名和密码都是root</p>
<p>界面效果：</p>
</li>
</ol>
<figure data-type="image" tabindex="4"><img src="https://ysjhhhhhhh.github.io/post-images/1576143409450.png" alt=""></figure>
<h2 id="常见问题">常见问题</h2>
<h3 id="问题一找不到服务提供者">问题一：找不到服务提供者</h3>
<p>问题描述：</p>
<p>​		使用multicast注册中心时，一直报 <code>No provider available for the service xxxx Service1</code></p>
<p>问题原因：</p>
<p>​		dubbo的服务消费方在服务注册中心中无法找到匹配的服务提供者，导致服务无法调用</p>
<p>问题解决：</p>
<ol>
<li>
<p>检查服务提供者、消费者配置是否和快速开始或者官方multicast示例中一致</p>
</li>
<li>
<p>如果服务提供者和消费者处于同一台服务器上，或者一个服务提供者有多个服务消费者，在消费者这方需要关闭multicast的单播模式，改为广播模式，否则消费者可能无法接收到服务提供者发出的服务注册消息。</p>
<pre><code class="language-xml">&lt;dubbo:registry address=&quot;multicast://224.5.6.7:1234?unicast=false&quot; /&gt;
</code></pre>
<p>或</p>
<pre><code class="language-xml">&lt;dubbo:registry protocol=&quot;multicast&quot; address=&quot;224.5.6.7:1234&quot;&gt;
    &lt;dubbo:parameter key=&quot;unicast&quot; value=&quot;false&quot; /&gt;
&lt;/dubbo:registry&gt;
</code></pre>
<p>参见：<a href="http://dubbo.apache.org/zh-cn/docs/user/references/registry/multicast.html">官方说明</a></p>
</li>
<li>
<p>如果上面两步都排除掉了，依然无法解决。 使用终极大法，将你的网线拔掉，或者网络断掉，然后重启服务提供者、消费者，你会发现已经解决了。之后你再插上网线也不会再有问题，就是这么神奇~</p>
</li>
</ol>
<h3 id="问题二启动消费者时有qos-server无法启动的警告">问题二：启动消费者时，有qos server无法启动的警告</h3>
<p>问题描述：</p>
<pre><code>警告:  [DUBBO] Fail to start qos server: , dubbo version: 2.7.3, current host: 10.10.13.127
java.net.BindException: Address already in use: bind
</code></pre>
<p>问题原因：</p>
<pre><code>通常这种情况发生在消费者和提供者运行在同一台服务器上，因为dubbo应用在启动时默认会启动一个心跳服务运行在22222端口，当一台服务器运行多个dubbo应用时，就会端口冲突。
</code></pre>
<p>问题解决：</p>
<p>​	在开发过程中可以直接将qos心跳服务停掉</p>
<pre><code class="language-xml">&lt;dubbo:application name=&quot;hello-dubbo&quot;&gt;
    &lt;!-- 关闭qos心跳服务 --&gt;
    &lt;dubbo:parameter key=&quot;qos.enable&quot; value=&quot;false&quot; /&gt;
&lt;/dubbo:application&gt;
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Solr]]></title>
        <id>https://ysjhhhhhhh.github.io/post/solr</id>
        <link href="https://ysjhhhhhhh.github.io/post/solr">
        </link>
        <updated>2018-06-07T15:08:32.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1-solr入门">1. Solr入门</h1>
<h2 id="11-solr下载安装">1.1. Solr下载安装</h2>
<p>官方下载地址：https://archive.apache.org/dist/lucene/solr/</p>
<p>Windows系统下载zip包，Linux、MaxOS系统下载tgz包</p>
<figure data-type="image" tabindex="1"><img src="https://ysjhhhhhhh.github.io/post-images/1576141759791.png" alt=""></figure>
<h2 id="111-solr目录结构">1.1.1. Solr目录结构</h2>
<figure data-type="image" tabindex="2"><img src="https://ysjhhhhhhh.github.io/post-images/1576141786354.png" alt=""></figure>
<ul>
<li>bin： 存放solr的可执行文件</li>
<li>contrib： 存放solr提供的扩展包</li>
<li>dist: Solr运行需要的jar包</li>
<li>docs: 文档目录</li>
<li>example: 官方提供的示例目录，配合官方示例教程，体验Solr功能</li>
<li>licences: 协议目录</li>
<li>server: solr工作的主目录，里面有默认的配置，将来创建的核心也会默认存储到此目录下，Solr Admin程序也在此目录下</li>
</ul>
<h2 id="12-solr入门">1.2. Solr入门</h2>
<h3 id="121-运行官方示例项目">1.2.1. 运行官方示例项目</h3>
<p>官方示例教程文档： https://lucene.apache.org/solr/guide/8_2/solr-tutorial.html</p>
<p>官方提供了三个示例教程，从Solr怎么简单使用，到怎么创建自己的搜索库，一步一步有引导，推荐跟着练习一遍。</p>
<h3 id="122-solr-admin-ui的使用">1.2.2. Solr Admin UI的使用</h3>
<p>Solr Admin是Solr给我们提供的一个方便查询和管理Solr的Web控制台应用，通过此应用，我们不需要编写任何程序就可以对Solr的很多功能进行操作。</p>
<p>默认访问地址： http://localhost:8983/solr</p>
<figure data-type="image" tabindex="3"><img src="https://ysjhhhhhhh.github.io/post-images/1576141818790.png" alt=""></figure>
<h4 id="1221-简单查询">1.2.2.1. 简单查询</h4>
<h4 id="1222-按照某个字段搜索">1.2.2.2. 按照某个字段搜索</h4>
<h4 id="1223-搜索短语">1.2.2.3. 搜索短语</h4>
<h4 id="1224-搜索结果中只返回某些字段">1.2.2.4. 搜索结果中只返回某些字段</h4>
<h4 id="1225-搜索结果分页">1.2.2.5. 搜索结果分页</h4>
<figure data-type="image" tabindex="4"><img src="https://ysjhhhhhhh.github.io/post-images/1576141846360.png" alt=""></figure>
<h4 id="1226-搜索结果高亮显示">1.2.2.6. 搜索结果高亮显示</h4>
<p>搜索参数设置：</p>
<figure data-type="image" tabindex="5"><img src="https://ysjhhhhhhh.github.io/post-images/1576141871632.png" alt=""></figure>
<p>搜索结果展示：</p>
<h4 id="1227-删除solr索引库中的数据">1.2.2.7. 删除Solr索引库中的数据</h4>
<figure data-type="image" tabindex="6"><img src="https://ysjhhhhhhh.github.io/post-images/1576141898303.png" alt=""></figure>
<h1 id="2-深入solr">2. 深入Solr</h1>
<h2 id="21-solr配置文件">2.1. Solr配置文件</h2>
<h3 id="211-managed-schema文件">2.1.1. managed-schema文件</h3>
<p>managed-schema文件是Solr中core或collection的搜索库定义配置文件，里面配置了搜索库有哪些Field和FieldType等。</p>
<p>Solr的工作流程大体如下：</p>
<ul>
<li>创建用于存储被搜索数据的core或collection(集群模式)；</li>
<li>定义创建的core有哪些字段，以及哪些字段需要索引、哪些字段只存储，不需要索引。具体来说，就是通过Solr提供的SchemaAPI去管理core中的字段；</li>
<li>将数据导入到Solr中，在此过程中，Solr会对导入的数据建索引（所以一定要先定义Schema字段，再导入数据）；</li>
<li>调用Solr的HttpAPI搜索数据</li>
</ul>
<blockquote>
<p>managed-schema文件就是用来管理某个core中有哪些字段或者字段类型，可以把Solr当成是一个数据库，里面有字段、有字段类型、能存储、能查询（搜索）</p>
</blockquote>
<h4 id="2111-solr中常用的数据类型">2.1.1.1. Solr中常用的数据类型</h4>
<p>Solr中主要的数据类型由实现类和类型定义两部分组成， 数据类型是由Solr中定义好的Java类，类型定义是在managed-schema文件中定义的，数据类型不能直接使用，必须在managed-schema中定义后才能直接在字段中引用。</p>
<p>在managed-schema中定义字段类型时，会将数据类型和其他属性（如：是否多值、是否存储）组合到一起</p>
<p>默认的managed-schema配置文件中已经定义了一些常用的数据类型，如</p>
<pre><code class="language-xml">&lt;fieldType name=&quot;string&quot; class=&quot;solr.StrField&quot; sortMissingLast=&quot;true&quot; docValues=&quot;true&quot; /&gt;
&lt;fieldType name=&quot;strings&quot; class=&quot;solr.StrField&quot; sortMissingLast=&quot;true&quot; multiValued=&quot;true&quot; docValues=&quot;true&quot; /&gt;
&lt;fieldType name=&quot;boolean&quot; class=&quot;solr.BoolField&quot; sortMissingLast=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;booleans&quot; class=&quot;solr.BoolField&quot; sortMissingLast=&quot;true&quot; multiValued=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;pint&quot; class=&quot;solr.IntPointField&quot; docValues=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;pfloat&quot; class=&quot;solr.FloatPointField&quot; docValues=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;plong&quot; class=&quot;solr.LongPointField&quot; docValues=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;pdouble&quot; class=&quot;solr.DoublePointField&quot; docValues=&quot;true&quot;/&gt;

&lt;fieldType name=&quot;pints&quot; class=&quot;solr.IntPointField&quot; docValues=&quot;true&quot; multiValued=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;pfloats&quot; class=&quot;solr.FloatPointField&quot; docValues=&quot;true&quot; multiValued=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;plongs&quot; class=&quot;solr.LongPointField&quot; docValues=&quot;true&quot; multiValued=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;pdoubles&quot; class=&quot;solr.DoublePointField&quot; docValues=&quot;true&quot; multiValued=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;random&quot; class=&quot;solr.RandomSortField&quot; indexed=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;pdate&quot; class=&quot;solr.DatePointField&quot; docValues=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;pdates&quot; class=&quot;solr.DatePointField&quot; docValues=&quot;true&quot; multiValued=&quot;true&quot;/&gt;
&lt;fieldType name=&quot;binary&quot; class=&quot;solr.BinaryField&quot;/&gt;
</code></pre>
<p>可以看到每个字段类型定义都由类型的实现类和若干个其他属性组合而成</p>
<p>除了上面定义的简单类型之外默认的managed-schema文件中还定义了一些特殊的字段类型</p>
<pre><code class="language-xml">&lt;!-- ignored类型本身是一个StrField类型，但是将stored和indexed都定义成了false，代表不存储、不建索引，实际上就是忽略数据中的此字段不处理 --&gt;
&lt;fieldType name=&quot;ignored&quot; stored=&quot;false&quot; indexed=&quot;false&quot; multiValued=&quot;true&quot; class=&quot;solr.StrField&quot; /&gt;
</code></pre>
<p>带分词功能的字段类型</p>
<pre><code class="language-xml">&lt;!-- text_general类型和上面的字段类型定义语法一样，本身数据solr.TextField类型，但是声明时通过内部的子标签指定了数据存储索引和数据搜索索引的分词器 --&gt;
&lt;fieldType name=&quot;text_general&quot; class=&quot;solr.TextField&quot; positionIncrementGap=&quot;100&quot; multiValued=&quot;true&quot;&gt;
    &lt;analyzer type=&quot;index&quot;&gt;
        &lt;tokenizer class=&quot;solr.StandardTokenizerFactory&quot;/&gt;
        &lt;filter class=&quot;solr.StopFilterFactory&quot; ignoreCase=&quot;true&quot; words=&quot;stopwords.txt&quot; /&gt;
        &lt;!-- in this example, we will only use synonyms at query time
        &lt;filter class=&quot;solr.SynonymGraphFilterFactory&quot; synonyms=&quot;index_synonyms.txt&quot; ignoreCase=&quot;true&quot; expand=&quot;false&quot;/&gt;
        &lt;filter class=&quot;solr.FlattenGraphFilterFactory&quot;/&gt;
        --&gt;
        &lt;filter class=&quot;solr.LowerCaseFilterFactory&quot;/&gt;
    &lt;/analyzer&gt;
    &lt;analyzer type=&quot;query&quot;&gt;
        &lt;tokenizer class=&quot;solr.StandardTokenizerFactory&quot;/&gt;
        &lt;filter class=&quot;solr.StopFilterFactory&quot; ignoreCase=&quot;true&quot; words=&quot;stopwords.txt&quot; /&gt;
        &lt;filter class=&quot;solr.SynonymGraphFilterFactory&quot; synonyms=&quot;synonyms.txt&quot; ignoreCase=&quot;true&quot; expand=&quot;true&quot;/&gt;
        &lt;filter class=&quot;solr.LowerCaseFilterFactory&quot;/&gt;
    &lt;/analyzer&gt;
&lt;/fieldType&gt;
</code></pre>
<h4 id="2112-添加字段类型定义fieldtype">2.1.1.2. 添加字段类型定义(FieldType)</h4>
<p>我们添加自定义字段类型的一个重要应用场景就是当我们的字段需要支持中文分词时，指定字段的实现类型是</p>
<p>solr.TextField，然后指定数据存储索引和搜索的索引分词器为支持中文的分词器。</p>
<p>语法参见上一章节 带分词功能的字段类型，中文分词器的配置参见配置中文分词器章节</p>
<h4 id="2113-solr中的无模式模式和字段类型自动推测">2.1.1.3. Solr中的&quot;无模式&quot;模式和字段类型自动推测</h4>
<p>我们在将数据导入到Solr中时，如果事先没有添加字段，Solr会根据数据的内容，自动推测应该用什么字段类型，并且自动生成field配置标签到当前core对应的managed-schema配置文件中</p>
<h4 id="2114-添加字段field">2.1.1.4. 添加字段(Field)</h4>
<p>前面说过managed-schema中主要就是定义了fieldType和field， 在以前老版本的solr中managed-schema的名字叫做schema.xml，可以直接手动编辑文件维护其中的字段定义。</p>
<p>而在新版本的Solr中，官方不建议手动修改此文件，改用Schema API的方式来维护字段</p>
<p>配置示例</p>
<pre><code class="language-xml">&lt;field name=&quot;price&quot; type=&quot;float&quot; default=&quot;0.0&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt;
</code></pre>
<p>定义字段需要指定字段的名称、类型(引用上面声明的fieldType的名称)、默认值、是否存储、是否索引等。</p>
<h4 id="2115-添加拷贝字段copy-field">2.1.1.5. 添加拷贝字段(Copy Field)</h4>
<p>Solr支持通过配置Copy Field，将多个字段拷贝到某个字段上，这样在搜索时，可以只用一个字段实现同时搜索多个字段内容的效果。</p>
<p>配置示例</p>
<pre><code class="language-xml">&lt;copyField source=&quot;cat&quot; dest=&quot;text&quot; maxChars=&quot;30000&quot; /&gt;
</code></pre>
<h4 id="2116-动态字段dynamic-fields">2.1.1.6. 动态字段(Dynamic Fields)</h4>
<p>Solr可以通过配置动态字段来实现对某些名称相似的字段统一管理，因为动态字段定义时名称中允许包含通配符。</p>
<p>动态字段和普通字段作用一致，唯一不同的就是名称中允许包含通配符，Solr在索引数据时会优先查找配置中定义的准确字段(通过field配置的字段)，如果没有找到匹配的，就从动态字段中找是否有匹配的，如果找到，就用动态字段的字段定义来索引数据。</p>
<p>配置示例</p>
<pre><code class="language-xml">&lt;dynamicField name=&quot;*_i&quot; type=&quot;int&quot; indexed=&quot;true&quot;  stored=&quot;true&quot;/&gt;
</code></pre>
<h3 id="212-schema-api">2.1.2. Schema API</h3>
<p>为了减少手动编辑managed-schema文件引入的错误，新版本的Solr提供了一套基于HTTP协议的Schema API来维护managed-schema文件</p>
<p>Schema API可以完成以下操作</p>
<h4 id="2121-add-field">2.1.2.1. add-field</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;add-field&quot;:{
     &quot;name&quot;:&quot;sell_by&quot;,
     &quot;type&quot;:&quot;pdate&quot;,
     &quot;stored&quot;:true }
}' http://localhost:8983/api/cores/gettingstarted/schema
</code></pre>
<h4 id="2122-delete-field">2.1.2.2. delete-field</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;delete-field&quot; : { &quot;name&quot;:&quot;sell_by&quot; }
}' http://localhost:8983/api/cores/gettingstarted/schema
</code></pre>
<h4 id="2123-replace-field">2.1.2.3. replace-field</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;replace-field&quot;:{
     &quot;name&quot;:&quot;sell_by&quot;,
     &quot;type&quot;:&quot;date&quot;,
     &quot;stored&quot;:false }
}' http://localhost:8983/api/cores/gettingstarted/schema
</code></pre>
<h4 id="2124-add-dynamic-field">2.1.2.4. add-dynamic-field</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;add-dynamic-field&quot;:{
     &quot;name&quot;:&quot;*_s&quot;,
     &quot;type&quot;:&quot;string&quot;,
     &quot;stored&quot;:true }
}' http://localhost:8983/api/cores/gettingstarted/schema
</code></pre>
<h4 id="2125-delete-dynamic-field">2.1.2.5. delete-dynamic-field</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;delete-dynamic-field&quot;:{ &quot;name&quot;:&quot;*_s&quot; }
}' http://localhost:8983/api/cores/gettingstarted/schema
</code></pre>
<h4 id="2126-replace-dynamic-field">2.1.2.6. replace-dynamic-field</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;replace-dynamic-field&quot;:{
     &quot;name&quot;:&quot;*_s&quot;,
     &quot;type&quot;:&quot;text_general&quot;,
     &quot;stored&quot;:false }
}' http://localhost:8983/solr/gettingstarted/schema
</code></pre>
<h4 id="2127-add-field-type">2.1.2.7. add-field-type</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;add-field-type&quot;:{
     &quot;name&quot;:&quot;myNewTextField&quot;,
     &quot;class&quot;:&quot;solr.TextField&quot;,
     &quot;indexAnalyzer&quot;:{
        &quot;tokenizer&quot;:{
           &quot;class&quot;:&quot;solr.PathHierarchyTokenizerFactory&quot;,
           &quot;delimiter&quot;:&quot;/&quot; }},
     &quot;queryAnalyzer&quot;:{
        &quot;tokenizer&quot;:{
           &quot;class&quot;:&quot;solr.KeywordTokenizerFactory&quot; }}}
}' http://localhost:8983/api/cores/gettingstarted/schema
</code></pre>
<h4 id="2128-delete-field-type">2.1.2.8. delete-field-type</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;delete-field-type&quot;:{ &quot;name&quot;:&quot;myNewTxtField&quot; }
}' http://localhost:8983/api/cores/gettingstarted/schema
</code></pre>
<h4 id="2129-replace-field-type">2.1.2.9. replace-field-type</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;replace-field-type&quot;:{
     &quot;name&quot;:&quot;myNewTxtField&quot;,
     &quot;class&quot;:&quot;solr.TextField&quot;,
     &quot;positionIncrementGap&quot;:&quot;100&quot;,
     &quot;analyzer&quot;:{
        &quot;tokenizer&quot;:{
           &quot;class&quot;:&quot;solr.StandardTokenizerFactory&quot; }}}
}' http://localhost:8983/api/cores/gettingstarted/schema
</code></pre>
<h4 id="21210-add-copy-field">2.1.2.10. add-copy-field</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;add-copy-field&quot;:{
     &quot;source&quot;:&quot;shelf&quot;,
     &quot;dest&quot;:[ &quot;location&quot;, &quot;catchall&quot; ]}
}' http://localhost:8983/api/cores/gettingstarted/schema
</code></pre>
<h4 id="21211-delete-copy-field">2.1.2.11. delete-copy-field</h4>
<p>使用示例</p>
<pre><code class="language-bash">curl -X POST -H 'Content-type:application/json' --data-binary '{
  &quot;delete-copy-field&quot;:{ &quot;source&quot;:&quot;shelf&quot;, &quot;dest&quot;:&quot;location&quot; }
}' http://localhost:8983/api/cores/gettingstarted/schema
</code></pre>
<h3 id="213-solrconfigxml文件">2.1.3. solrconfig.xml文件</h3>
<p>solrconfig.xml文件中定义了Solr core的数据目录、需要的第三方jar包、索引配置等。一般我们修改这个配置文件主要是配置中文分词器，因为Solr官方默认没有配置支持中文分词器的字段类型。</p>
<h2 id="22-core-vs-collection">2.2. Core VS Collection</h2>
<blockquote>
<p>在单机模式启动的Solr中一个搜索数据集叫做core，而在集群模式启动的Solr中搜索数据集的名称叫做collection</p>
</blockquote>
<h3 id="221-单机模式使用solr">2.2.1. 单机模式使用Solr</h3>
<h4 id="2211-以单机模式启动solr">2.2.1.1. 以单机模式启动Solr</h4>
<pre><code class="language-bash">bin/solr start  # linux、macos
bin\solr.cmd start # windows
</code></pre>
<p>启动成功后命令行会有如下输出</p>
<pre><code>Started Solr server on port 8983. Happy searching!
</code></pre>
<h4 id="2212-创建core核心">2.2.1.2. 创建core核心</h4>
<pre><code class="language-bash">bin/solr create -c 核心名  # linux、macos
bin\solr.cmd create -c 核心名 # windows
</code></pre>
<h4 id="2213-导入数据到solr">2.2.1.3. 导入数据到Solr</h4>
<blockquote>
<p>参见使用SpringBoot操作Solr章节</p>
</blockquote>
<h4 id="2214-停止单机版solr">2.2.1.4. 停止单机版Solr</h4>
<pre><code class="language-bash">bin/solr stop -all  # linux、macos
bin\solr.cmd stop -all # windows
</code></pre>
<h3 id="222-以集群模式启动solr">2.2.2. 以集群模式启动Solr</h3>
<h4 id="2221-以集群模式启动solr">2.2.2.1. 以集群模式启动Solr</h4>
<p>以集群模式启动Solr</p>
<pre><code class="language-bash">bin/solr start -c  # linux、macos
bin\solr.cmd start -c # windows
</code></pre>
<p>以集群模式启动后，如果没指定端口号，Solr默认会启动一个8983的节点；同时还会将内置的Zookeeper服务也启动起来，运行到9983端口上</p>
<p>向Solr集群中添加节点</p>
<pre><code class="language-bash">bin/solr start -c -p 节点端口号 -z localhost:9983 # linux、macos
bin\solr.cmd start -c -p 节点端口号 -z localhost:9983 # windows
</code></pre>
<p>-p参数指定节点运行的端口号，-z参数将新创建的节点添加到集群中</p>
<blockquote>
<p>Zookeeper是一个分布式管理框架，专门用来管理集群中各节点的状态。</p>
</blockquote>
<h4 id="2222-创建collection">2.2.2.2. 创建collection</h4>
<pre><code class="language-bash">bin/solr create -c collection名称 -s 2 -rf 2  # linux、macos
bin\solr.cmd create -c collection名称 -s 2 -rf 2 # windows
</code></pre>
<p>-c 参数指定创建的collection名称</p>
<p>-s 参数表示该collection要分布到几个分片上</p>
<p>-rf 参数表示每个分片有几个副本（用于容灾）</p>
<blockquote>
<p>Solr的集群模式和Reids集群类似，每个分片都有一个master节点和若干个slave节点组成，当master节点发生故障无法对外提供服务时，Solr集群会自动选举一个slave节点作为master对外服务。</p>
</blockquote>
<h4 id="2223-导入数据到solr集群">2.2.2.3. 导入数据到Solr集群</h4>
<blockquote>
<p>参见使用SpringBoot操作Solr章节</p>
</blockquote>
<h4 id="2224-停止solr集群">2.2.2.4. 停止Solr集群</h4>
<ul>
<li>
<p>停止集群中某个节点</p>
<pre><code class="language-bash">bin/solr stop -p 要停止的节点的端口号 # linux、macos
bin\solr.cmd stop -p 要停止的节点的端口号 # windows
</code></pre>
</li>
<li>
<p>停止整个Solr集群</p>
<pre><code class="language-bash">bin/solr stop -all # linux、macos
bin\solr.cmd stop -all # windows
</code></pre>
</li>
</ul>
<h2 id="23-配置中文分词器">2.3. 配置中文分词器</h2>
<p>分词器的作用在于将搜索的文本按照词组进行分割，可以大大的提高搜索的准确度。Solr对大部分的语言分词都进行了支持，其中也包括简体中文，但是遗憾的是截止最新的8.3.0版本，官方只是提供了中文分词的jar包，但是并没有对其进行配置。这就需要我们在用的时候配置中文分词器。</p>
<p>Solr官方提供了两种中文分词器：smartcn和icu</p>
<p>以smartcn分词器为例，配置方法如下：</p>
<h3 id="231-修改solrconfigxml配置文件添加中文分词器依赖">2.3.1. 修改solrconfig.xml配置文件，添加中文分词器依赖</h3>
<pre><code class="language-xml">......
&lt;lib dir=&quot;${solr.install.dir:../../../..}/dist/&quot; regex=&quot;solr-ltr-\d.*\.jar&quot; /&gt;
&lt;!-- 添加这行 --&gt;
&lt;lib dir=&quot;${solr.install.dir:../../../..}/contrib/analysis-extras/lucene-libs&quot; regex=&quot;.*\.jar&quot; /&gt;
......
</code></pre>
<h3 id="232-修改managed-schema配置文件新建fieldtype">2.3.2. 修改managed-schema配置文件，新建fieldType</h3>
<pre><code class="language-xml">&lt;!-- 添加自定义的支持中文分词的字段类型 --&gt;
&lt;fieldType name=&quot;text_zh&quot; class=&quot;solr.TextField&quot; positionIncrementGap=&quot;100&quot;&gt;
    &lt;analyzer type=&quot;index&quot;&gt;
        &lt;tokenizer class=&quot;org.apache.lucene.analysis.cn.smart.HMMChineseTokenizerFactory&quot;/&gt;
        &lt;filter class=&quot;solr.CJKWidthFilterFactory&quot;/&gt;
        &lt;filter class=&quot;solr.StopFilterFactory&quot;
                words=&quot;org/apache/lucene/analysis/cn/smart/stopwords.txt&quot;/&gt;
        &lt;filter class=&quot;solr.PorterStemFilterFactory&quot;/&gt;
        &lt;filter class=&quot;solr.LowerCaseFilterFactory&quot;/&gt;
    &lt;/analyzer&gt;
    &lt;analyzer type=&quot;query&quot;&gt;
        &lt;tokenizer class=&quot;org.apache.lucene.analysis.cn.smart.HMMChineseTokenizerFactory&quot;/&gt;
        &lt;filter class=&quot;solr.CJKWidthFilterFactory&quot;/&gt;
        &lt;filter class=&quot;solr.StopFilterFactory&quot;
                words=&quot;org/apache/lucene/analysis/cn/smart/stopwords.txt&quot;/&gt;
        &lt;filter class=&quot;solr.PorterStemFilterFactory&quot;/&gt;
        &lt;filter class=&quot;solr.LowerCaseFilterFactory&quot;/&gt;
    &lt;/analyzer&gt;
&lt;/fieldType&gt;
</code></pre>
<blockquote>
<p>在%solr安装目录%/server/configsets/_default/conf目录下有一份默认的配置文件managed-schema、solrconfig.xml。建议配置中文分词器时直接修改这个默认配置文件。因为在新建核心时，Solr会将这里的默认配置文件拷贝一份作为新核心的配置文件。</p>
</blockquote>
<h2 id="24-使用springboot操作solr">2.4. 使用SpringBoot操作Solr</h2>
<p>添加依赖</p>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-data-solr&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<p>application.yml中配置</p>
<pre><code class="language-yml">spring:
  data:
    solr:
      host: http://localhost:8983/solr/
</code></pre>
<p>通过Java代码导入数据到Solr和搜索</p>
<pre><code class="language-java">@Slf4j
@Service
public class SolrService {

    @Autowired
    private SolrClient solrClient;

    @Autowired
    private MessageDao messageDao;

    public static final int BATCH_SIZE = 10;

    public static final String CORE_NAME = &quot;lanou3g&quot;;

    /**
     * 将数据批量导入Solr中
     * @throws IOException
     * @throws SolrServerException
     */
    public void importData2Solr() throws IOException, SolrServerException {
        List&lt;Message&gt; messages = messageDao.loadAllMessage();
        List&lt;SolrInputDocument&gt; batchList = new ArrayList&lt;&gt;();
        messages.forEach((message -&gt; {

            // 将message对象转换成solr的inputDocument
            SolrInputDocument inDoc = new SolrInputDocument();
            inDoc.addField(&quot;id&quot;, message.getId());
            inDoc.addField(&quot;from_id&quot;, message.getFromId());
            inDoc.addField(&quot;to_id&quot;, message.getToId());
            inDoc.addField(&quot;subject&quot;, message.getSubject());
            inDoc.addField(&quot;content&quot;, message.getContent());
            inDoc.addField(&quot;createtime&quot;, message.getCreatetime());
            inDoc.addField(&quot;status&quot;, message.getStatus());
            inDoc.addField(&quot;attachment&quot;, message.getAttachment());

            batchList.add(inDoc);
            if(batchList.size() % BATCH_SIZE == 0) {
                try {
                    solrClient.add(CORE_NAME ,batchList);
                    batchList.clear();
                    log.info(&quot;批量导入&quot;+BATCH_SIZE+&quot;条到solr.&quot;);
                } catch (SolrServerException e) {
                    e.printStackTrace();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
        }));

        if(batchList.size() &gt; 0) {
            solrClient.add(CORE_NAME, batchList);
            log.info(&quot;批量导入&quot;+batchList.size()+&quot;条到solr.&quot;);
            batchList.clear();
        }
        log.info(&quot;数据导入完成！&quot;);

        // 提交数据到solr
//        solrClient.commit();  // 无参的需要在配置文件中将核心名称添加到solr url中，参见application.yml
        solrClient.commit(CORE_NAME);
    }


    /**
     * 从Solr中分页搜索数据
     * @param q 搜索关键字
     * @param fields 限制返回的结果集中只允许哪个字段
     * @param start 分页参数
     * @param pageSize   分页参数
     */
    public void searchFromSolr(String q, String[] fields, int start, int pageSize) {

        SolrQuery params = new SolrQuery(q);
        if(fields != null &amp;&amp; fields.length &gt; 0) {
            params.setFields(fields);
        }

        // 分页参数
        params.setStart(start);
        params.setRows(pageSize);

        // 不设置按照哪个字段搜索的时候，默认搜索哪个字段
        // （一般会将系统中所有支持检索的字段通过CopyField的方式拷贝到一个统一的字段上，用于搜索，比如下面的keywords）
        params.setParam(&quot;df&quot;, &quot;keywords&quot;);

        // 设置搜索结果高亮显示
        params.setHighlight(true);
        // 设置往搜索结果中所有匹配关键字的地方添加指定的前缀和后缀（内容随意）
        params.setHighlightSimplePre(&quot;&lt;i class=\&quot;keywords\&quot;&gt;&quot;);
        params.setHighlightSimplePost(&quot;&lt;/i&gt;&quot;);

        try {
//            QueryResponse queryResp = solrClient.query(params);
            QueryResponse queryResp = solrClient.query(CORE_NAME, params);
            SolrDocumentList results = queryResp.getResults();
            long numFound = results.getNumFound();
            System.out.println(&quot;总共搜索到&quot;+numFound+&quot;条结果&quot;);
            results.forEach((solrDoc) -&gt; {
                StringBuilder sb = new StringBuilder();
                sb.append(&quot;{&quot;);
                Collection&lt;String&gt; fieldNames = solrDoc.getFieldNames();
                fieldNames.forEach((fieldName) -&gt; {
                    Object fieldValue = solrDoc.getFieldValue(fieldName);
                    sb.append(&quot;\&quot;&quot;+fieldName+&quot;\&quot;:\&quot;&quot;+fieldValue+&quot;\&quot;,&quot;);
                });
                if(sb.length() &gt; 1) {
                    sb.deleteCharAt(sb.length() - 1);
                }
                sb.append(&quot;}&quot;);

                System.out.println(&quot;row: &quot; + sb.toString());
            });
        } catch (SolrServerException e) {
            e.printStackTrace();
        } catch (IOException e) {
            e.printStackTrace();
        }

    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Redis]]></title>
        <id>https://ysjhhhhhhh.github.io/post/redis</id>
        <link href="https://ysjhhhhhhh.github.io/post/redis">
        </link>
        <updated>2018-06-02T03:50:43.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1-redis介绍">1. redis介绍</h1>
<h2 id="11-什么是redis">1.1. 什么是redis</h2>
<blockquote>
<p>Redis是用C语言开发的一个开源的高性能键值对（key-value）数据库。它通过提供多种键值数据类型来适应不同场景下的存储需求</p>
</blockquote>
<h3 id="redis支持的键值数据类型">Redis支持的键值数据类型</h3>
<p>字符串类型</p>
<p>散列类型  (对应Java中的Object，它主要用来存储对象)</p>
<p>列表类型  （List）</p>
<p>集合类型    (Set)</p>
<p>有序集合类型。 (TreeSet)</p>
<h2 id="12-redis的应用场景">1.2. redis的应用场景</h2>
<p>缓存（数据查询、短连接、新闻内容、商品内容等等）。（最多使用）</p>
<p>分布式集群架构中的session分离。</p>
<p>聊天室的在线好友列表。</p>
<p>任务队列。（秒杀、抢购、12306等等）</p>
<p>应用排行榜。</p>
<p>网站访问统计。</p>
<p>数据过期处理（可以精确到毫秒）</p>
<h1 id="2-redis的安装">2. Redis的安装</h1>
<h2 id="21-在windows上安装">2.1 在Windows上安装</h2>
<h2 id="22-在linux上安装">2.2 在Linux上安装</h2>
<p>redis是C语言开发，建议在linux上运行，示例使用CentOS7作为安装环境。</p>
<ol>
<li>
<p>安装redis需要先将官网下载的源码进行编译，编译依赖gcc环境，如果没有gcc环境，需要安装gcc</p>
<pre><code class="language-bash">yum install gcc-c++
</code></pre>
<blockquote>
<p>阿里云的CentOS7默认已经内置了gcc，可以跳过这一步</p>
</blockquote>
</li>
<li>
<p>下载redis</p>
<p>从官网下载</p>
<p>http://download.redis.io/releases/redis-5.0.5.tar.gz</p>
<p>将redis-5.0.5.tar.gz拷贝任意路径下，如 /home/john/opt/</p>
</li>
<li>
<p>解压源码</p>
<pre><code class="language-bash">cd /home/john/opt/
tar -zxvf redis-5.0.5.tar.gz  
</code></pre>
</li>
<li>
<p>进入解压后的目录进行编译安装</p>
<pre><code class="language-bash">cd /home/john/opt/redis-5.0.5/src
make # 编译源代码
make install  # 安装
# 上面两步也可以直接通过 make &amp;&amp; make install两步并一步执行
</code></pre>
<blockquote>
<p>Redis默认的安装目录是/usr/local/bin， 我们在执行make install命令时添加prefix参数可修改默认安装位置，如： make PREFIX=/usr/local/redis install</p>
</blockquote>
</li>
</ol>
<h1 id="3-redis启动">3. redis启动</h1>
<p>redis.conf是redis的配置文件，默认在redis源码包解压后的根目录有一份redis.conf文件，我们可将其拷贝一份到上一步中redis的安装目录</p>
<pre><code class="language-bash">cp /home/john/opt/redis-5.0.5/src/redis.conf /usr/local/bin
</code></pre>
<p>我们装完redis以后，默认的安装路径是/usr/local/bin，系统会自动来此目录寻找命令，所以我们不需要在配置环境变量，在任意目录都可以使用redis相关的命令，如redis-server、redis-cli</p>
<h2 id="31-前端模式启动">3.1.   前端模式启动</h2>
<p>启动命令：</p>
<pre><code class="language-bash">redis-server /usr/local/bin/redis.conf
</code></pre>
<p>通过上面的命令启动，redis将以前端模式启动，前端模式启动的缺点是ssh命令窗口关闭则redis-server程序结束，不推荐使用此方法。</p>
<h2 id="32-后端模式启动">3.2.   后端模式启动</h2>
<h3 id="321-开启远程连接">3.2.1 开启远程连接</h3>
<ul>
<li>注释掉 bind 127.0.0.1这行</li>
<li>关闭保护模式  将protected-mode yes 改成 protected-mode no</li>
</ul>
<h3 id="322-添加密码验证">3.2.2 添加密码验证</h3>
<p>放开 # requirepass foobared 这行注释，将后面的foobared改成你自己需要设置的密码</p>
<p>客户端连接时，需要添加-a 参数指定密码才能连上来。</p>
<h3 id="323-开启后台守护进程运行模式">3.2.3 开启后台守护进程运行模式</h3>
<p>将 # daemonize no 这行放开注释， 并且改成 yes， Redis server将以后台方式运行。</p>
<h3 id="324-指定日志文件">3.2.4 指定日志文件</h3>
<p>将 logfile &quot;&quot; 改成 logfile &quot;你需要的redis日志文件名称&quot;， 默认的空字符串代表输出到前端控制台（标准输出）</p>
<p>修改redis.conf配置文件， daemonize yes 以后端模式启动。</p>
<h3 id="325-启动">3.2.5 启动</h3>
<p>启动命令和前端启动一样，只不过控制台不会输出任何信息，而且命令结束，如果没有异常会马上退出。</p>
<h1 id="4-通过java操作redis">4. 通过Java操作redis</h1>
<h2 id="41-sringboot方式">4.1 SringBoot方式</h2>
<h3 id="411-引入依赖">4.1.1   引入依赖</h3>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<h3 id="412-springboot配置">4.1.2   SpringBoot配置</h3>
<p>application.yml</p>
<pre><code class="language-yml">spring:
    redis:
    host: www.taotao.com
#    port: 6379
#    password:
    jedis:
      pool:
        max-idle: 2
        max-wait: 1000ms
</code></pre>
<h2 id="42-单实例连接">4.2.   单实例连接</h2>
<p>通过创建单实例jedis对象连接redis服务，如下代码：</p>
<pre><code class="language-java">@Slf4j
@SpringBootTest
public class TestRedisClient {

   @Autowired
   private StringRedisTemplate redisTemplate;

   @Test
   public void testRedis() {
      Set&lt;String&gt; keys = redisTemplate.keys(&quot;*&quot;);
      log.info(&quot;操作前存在的keys: &quot; + keys);

      String key = &quot;lanou_F4&quot;;

      redisTemplate.opsForList().rightPushAll(key, new String[]{&quot;宋超&quot;, &quot;国胜&quot;, &quot;国伟&quot;, &quot;高飞&quot;});

      long size = redisTemplate.opsForList().size(key);
      log.info(&quot;当前&quot;+key+&quot;值的数量： &quot; + size);

      List&lt;String&gt; values = redisTemplate.opsForList().range(key, 0, size);
      log.info(&quot;当前&quot; + key +&quot;的值： &quot; + values);

      keys = redisTemplate.keys(&quot;*&quot;);
      log.info(&quot;操作后存在的keys: &quot; + keys);
   }
}
</code></pre>
<h2 id="43-外部连接不上redis的解决方法">4.3. 外部连接不上redis的解决方法</h2>
<p>由于linux防火墙默认开启，redis的服务端口6379并不在开放规则之内，所有需要将此端口开放访问或者关闭防火墙。</p>
<p>查看防火墙状态：sevice iptables status</p>
<p>关闭防火墙命令：sevice iptables stop</p>
<p>如果是修改防火墙规则，可以修改：/etc/sysconfig/iptables文件</p>
<h1 id="5-redis集群">5.   redis集群</h1>
<h2 id="51-集群原理">5.1. 集群原理</h2>
<h3 id="511-redis-cluster架构图">5.1.1.   redis-cluster架构图</h3>
<figure data-type="image" tabindex="1"><img src="https://ysjhhhhhhh.github.io/post-images/1576140891972.jpg" alt=""></figure>
<p>架构细节:</p>
<ol>
<li>
<p>所有的redis节点彼此互联(PING-PONG机制),内部使用二进制协议优化传输速度和带宽.</p>
</li>
<li>
<p>节点的fail是通过集群中超过半数的节点检测失效时才生效.</p>
</li>
<li>
<p>客户端与redis节点直连,不需要中间proxy层.客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可</p>
</li>
<li>
<p>redis-cluster把所有的物理节点映射到[0-16383]slot上,cluster 负责维护node&lt;-&gt;slot&lt;-&gt;value  Redis 集群中内置了 16384 个哈希槽，当需要在 Redis 集群中放置一个 key-value 时，redis 先对 key 使用 crc16 算法算出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，redis 会根据节点数量大致均等的将哈希槽映射到不同的节点</p>
</li>
</ol>
<h3 id="512-redis-cluster投票容错">5.1.2.   redis-cluster投票:容错</h3>
<figure data-type="image" tabindex="2"><img src="https://ysjhhhhhhh.github.io/post-images/1576140973801.jpg" alt=""></figure>
<ol>
<li>
<p>投票过程是集群中所有master参与,如果半数以上master节点与master节点通信超过(cluster-node-timeout),认为当前master节点挂掉.</p>
</li>
<li>
<p>什么时候整个集群不可用(cluster_state:fail)?</p>
<ol>
<li>如果集群任意master挂掉,且当前master没有slave.集群进入fail状态,也可以理解成集群的slot映射[0-16383]不完成时进入fail状态</li>
<li>如果集群超过半数以上master挂掉，无论是否有slave集群进入fail状态.</li>
</ol>
</li>
</ol>
<blockquote>
<p>当集群不可用时,所有对集群的操作做都不可用，收到((error) CLUSTERDOWN The cluster is down)错误</p>
</blockquote>
<h2 id="53-创建集群">5.3. 创建集群</h2>
<h3 id="531-集群结点规划">5.3.1.   集群结点规划</h3>
<p>这里在同一台服务器用不同的端口表示不同的redis服务器(伪集群)，如下：</p>
<pre><code>主节点：192.168.101.3:7001 192.168.101.3:7002 192.168.101.3:7003

从节点：192.168.101.3:7004 192.168.101.3:7005 192.168.101.3:7006
</code></pre>
<h3 id="532-修改配置">5.3.2 修改配置</h3>
<p>修改redis.conf配置文件</p>
<pre><code class="language-conf">port 7001  # 将每个节点的端口号改成不一样的(因为同一台机器上一个端口只能被一个进程绑定)
cluster-enabled yes #是否开启集群模式
cluster-config-file nodes.conf	#集群配置文件名称
cluster-node-timeout 5000	#集群中节点间投票通信的超时时间
appendonly yes  #配置集群中当前节点仅开启AOF持久化模式
pidfile /var/run/redis_7001.pid  #将pid文件改成不同的名称，建议和当前节点的端口号对应
</code></pre>
<h3 id="533-创建集群目录">5.3.3 创建集群目录</h3>
<p>在/usr/local下创建redis-cluster目录，其下创建7001、7002。。7006目录，如下：</p>
<figure data-type="image" tabindex="3"><img src="https://ysjhhhhhhh.github.io/post-images/1576140996309.png" alt=""></figure>
<p>将redis安装目录bin下的文件拷贝到每个700X目录内，并且将配置文件也拷贝一份到每个700X目录</p>
<pre><code class="language-bash">cp /usr/local/bin/redis/redis* /usr/local/redis-cluster/7001
cp /home/john/opt/redis-5.0.5/src/redis.conf /usr/local/redis-cluster/7001
</code></pre>
<p>修改每个700X目录下的redis.conf配置文件中的端口号和pid文件路径</p>
<h3 id="534-启动每个节点redis服务">5.3.4.   启动每个节点redis服务</h3>
<p>进入/usr/local/redis_cluster目录下，编写启动集群脚本：start_redis_cluster.sh</p>
<p>cd /usr/local/redis_cluster</p>
<p>vim start_redis_cluster.sh</p>
<pre><code class="language-bash">#!/bin/bash

work_dir=`pwd`

echo &quot;开始启动redis集群中的每个节点&quot;
for idx in {1..6}
do
    cd $work_dir
    cd &quot;./700$idx&quot; &amp;&amp; ./redis-server ./redis.conf
    if [ $? != 0 ] 
    then
        echo &quot;启动700$idx节点失败，停止启动集群&quot;
        exit 1
    fi  
    echo &quot;启动700$idx&quot;
done
echo &quot;所有集群节点启动完成&quot;
</code></pre>
<p>编辑完成后，按ESC切换到命令模式， 输入ZZ 或者 :wq保存退出。</p>
<p>启动Redis集群中所有节点</p>
<pre><code class="language-bash">./start_redis_cluster.sh 
</code></pre>
<p>查看redis进程：</p>
<p>ps aux | grep redis</p>
<figure data-type="image" tabindex="4"><img src="https://ysjhhhhhhh.github.io/post-images/1576141024160.jpg" alt=""></figure>
<h3 id="534-执行创建集群命令">5.3.4.   执行创建集群命令</h3>
<p>Redis 5开始，集群不需要依赖Ruby，官方直接提供了集群管理支持</p>
<pre><code class="language-bash">redis-cli --cluster create 127.0.0.1:7001 127.0.0.1:7002 \
127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 127.0.0.1:7006 \
--cluster-replicas 1
</code></pre>
<blockquote>
<p>注意，这里用127.0.0.1仅适用于在本机练习集群搭建，真实环境下需要换成外公网IP，否则无法远程连接到你的redis集群</p>
</blockquote>
<p>命令说明：</p>
<p>redis集群至少需要3个主节点，每个主节点有一个从节点总共6个节点</p>
<p>--cluster-replicas指定为1表示为集群中每个master都指定一个slave，也就是说上面6个节点会有3个主节点和对应的3个从节点</p>
<figure data-type="image" tabindex="5"><img src="https://ysjhhhhhhh.github.io/post-images/1576141039429.png" alt=""></figure>
<p>如果一切正常，最后会看到如下输出</p>
<pre><code class="language-bash">[OK] All 16384 slots covered.
</code></pre>
<h4 id="可能会遇到的错误">可能会遇到的错误</h4>
<p>错误一：</p>
<p>如果创建redis集群的时候，ip用的是127.0.0.1，那么你在用Java客户端远程操作Redis集群的时候，会死活连不上，一直是报<strong>127.0.0.1:7001</strong>无法连接</p>
<p>解决办法：创建Redis集群时，创建命令中传入的节点IP参数列表使用外部可以访问的IP</p>
<p>错误二：</p>
<p>如果执行时报如下错误：</p>
<p>[ERR] Node XXXXXX is not empty. Either the node already knows other nodes (check with CLUSTER NODES) or contains some key in database 0</p>
<p>解决方法是删除生成的配置文件nodes.conf，如果不行则说明现在创建的节点包括了旧集群的结点信息，需要删除redis的持久化文件后再重启redis，比如：appendonly.aof、dump.rdb</p>
<h2 id="54-停止redis集群">5.4. 停止Redis集群</h2>
<p>在/usr/local/redis_cluster目录下，创建脚本文件：stop_redis_cluster.sh</p>
<p>输入以下内容：</p>
<pre><code class="language-bash">#!/bin/bash

work_dir=`pwd`

count=0
err_count=0
echo &quot;开始停止redis集群&quot;
for idx in {1..6}
do
    cd $work_dir
    cd &quot;./700$idx&quot; &amp;&amp; ./redis-cli -c -p &quot;700$idx&quot; shutdown
    if [ $? != 0 ] 
    then
        echo &quot;停止700$idx节点失败&quot;
        let err_count++
    fi  
    echo &quot;停止700$idx节点&quot;
    let count++
done
echo &quot;Redis集群一共有$count个节点，成功停止`expr $count - $err_count`个节点，有$err_count个节点停止失败.&quot;
</code></pre>
<p>执行此脚本可以停止redis集群</p>
<h2 id="55-查询集群信息">5.5. 查询集群信息</h2>
<p>集群创建成功登陆任意redis结点查询集群中的节点情况。</p>
<p>客户端以集群方式登陆：</p>
<figure data-type="image" tabindex="6"><img src="https://ysjhhhhhhh.github.io/post-images/1576141076488.png" alt=""></figure>
<p>说明：</p>
<p><code>./redis-cli -c -h 192.168.101.3 -p 7001</code>，其中<code>-c</code>表示以集群方式连接redis，<code>-h</code>指定ip地址，<code>-p</code>指定端口号</p>
<h3 id="551-查看集群状态相关命令">5.5.1 查看集群状态相关命令</h3>
<p>cluster nodes 查询集群结点信息</p>
<p>cluster info 查询集群状态信息</p>
<h2 id="56-添加主节点">5.6. 添加主节点</h2>
<p>集群创建成功后可以向集群中添加节点，下面是添加一个master主节点</p>
<p>添加7007节点，参考集群节点规划章节添加一个“7007”目录作为新节点。</p>
<p>Redis 5 添加主节点命令：</p>
<p>语法：</p>
<pre><code>redis-cli –cluster add-node 要添加节点的ip:端口 集群中当前存在的任何一个节点的ip和端口
</code></pre>
<p>示例：</p>
<pre><code class="language-bash">redis-cli --cluster add-node 10.10.14.166:7006 10.10.14.166:7000
</code></pre>
<p>输出结果</p>
<figure data-type="image" tabindex="7"><img src="https://ysjhhhhhhh.github.io/post-images/1576141123082.png" alt=""></figure>
<p>查看集群结点发现7007已添加到集群中：</p>
<figure data-type="image" tabindex="8"><img src="https://ysjhhhhhhh.github.io/post-images/1576141136927.png" alt=""></figure>
<p>注意：新添加的master node有以下两个特征</p>
<ol>
<li>由于它没有分配hash槽，所以该节点无法存储任何数据</li>
<li>由于它没有分配hash槽，所以在其他从节点要升级成主节点的过程中，该节点不参与投票（没有投票权）</li>
</ol>
<h3 id="561-hash槽重新分配">5.6.1.   hash槽重新分配</h3>
<p>添加完主节点需要对主节点进行hash槽分配这样该主节才可以存储数据。</p>
<p>redis集群有16384个槽，集群中的每个结点分配自已的槽，通过查看集群结点（cluster nodes命令）可以看到槽占用情况。 可以看到新添加的7007节点并没有分配到hash槽</p>
<p>给刚添加的7007结点分配槽</p>
<p>第一步：连接上集群</p>
<pre><code class="language-bash">redis-cli --cluster reshard 127.0.0.1:7001  #（连接集群中任意一个可用结点就行）
</code></pre>
<p>第二步：输入要分配的槽数量</p>
<figure data-type="image" tabindex="9"><img src="https://ysjhhhhhhh.github.io/post-images/1576141184462.png" alt=""></figure>
<p>输入 500表示分配500个槽</p>
<p>第三步：输入接收槽的结点id</p>
<figure data-type="image" tabindex="10"><img src="https://ysjhhhhhhh.github.io/post-images/1576141196669.png" alt=""></figure>
<p>这里准备给7007分配槽，通过cluster nodes查看7007结点id为15b809eadae88955e36bcdbb8144f61bbbaf38fb</p>
<p>输入：15b809eadae88955e36bcdbb8144f61bbbaf38fb</p>
<p>第四步：输入源结点id</p>
<figure data-type="image" tabindex="11"><img src="https://ysjhhhhhhh.github.io/post-images/1576141206971.png" alt=""></figure>
<p>这里输入all</p>
<p>第五步：输入yes开始移动槽到目标结点id</p>
<figure data-type="image" tabindex="12"><img src="https://ysjhhhhhhh.github.io/post-images/1576141234709.png" alt=""></figure>
<p>至此，新添加的7007 master节点的hash槽就分配完毕，可以存储数据了！</p>
<p>关于Redis 集群的hash slots相关知识，可以参阅：</p>
<p><a href="https://www.cnblogs.com/abc-begin/p/8203613.html">redis hash slot（虚拟桶）</a></p>
<p><a href="https://www.jianshu.com/p/fe7b7800473e">Redis Cluster及hash slot 算法</a></p>
<h2 id="57-添加从节点">5.7. 添加从节点</h2>
<p>集群创建成功后可以向集群中添加节点，下面是添加一个slave从节点。</p>
<p>添加7008从结点，将7008作为7007的从结点。</p>
<p>Redis 5中添加从节点命令：</p>
<p>语法：</p>
<pre><code class="language-bash">redis-cli –cluster add-node 要添加节点的ip:端口 集群中任意已有master的ip和端口 --cluster-slave [--cluster-master-id masterid]
</code></pre>
<p>示例：</p>
<p>添加一个从节点，不指定目标主节点</p>
<pre><code class="language-bash">redis-cli --cluster add-node 10.10.14.166:7008 10.10.14.166:7001 --cluster-slave
</code></pre>
<blockquote>
<p>注意：该命令只是向集群中添加了一个从节点，但并没有指名要作为哪个master node的从节点，Redis集群会将其添加到集群中随机挑一个从节点较少的master node上，作为其从节点</p>
</blockquote>
<p>添加一个从节点，并指定所属主节点</p>
<pre><code class="language-bash">redis-cli --cluster add-node 10.10.14.166:7008 10.10.14.166:7001 --cluster-slave --cluster-master-id 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e
</code></pre>
<blockquote>
<p>我们通过增加了一个cluster-master-id参数，指定从节点要添加到哪个主节点上。主节点的ID可以通过cluster nodes查看到</p>
</blockquote>
<p>执行如下命令：</p>
<p>./redis-trib.rb add-node --slave --master-id cad9f7413ec6842c971dbcc2c48b4ca959eb5db4  192.168.101.3:7008 192.168.101.3:7001</p>
<p>cad9f7413ec6842c971dbcc2c48b4ca959eb5db4  是7007结点的id，可通过cluster nodes查看。</p>
<figure data-type="image" tabindex="13"><img src="file:///C:%5CUsers%5CJohn%5CAppData%5CLocal%5CTemp%5Cmsohtmlclip1%5C01%5Cclip_image044.jpg" alt="img"></figure>
<p>注意：如果原来该结点在集群中的配置信息已经生成cluster-config-file指定的配置文件中（如果cluster-config-file没有指定则默认为nodes.conf），这时可能会报错：</p>
<p>[ERR] Node XXXXXX is not empty. Either the node already knows other nodes (check with CLUSTER NODES) or contains some key in database 0</p>
<p>解决方法是删除生成的配置文件nodes.conf，删除后再执行**./redis-trib.rb add-node**指令</p>
<p>查看集群中的结点，刚添加的7008为7007的从节点：</p>
<figure data-type="image" tabindex="14"><img src="file:///C:%5CUsers%5CJohn%5CAppData%5CLocal%5CTemp%5Cmsohtmlclip1%5C01%5Cclip_image046.jpg" alt="img"></figure>
<h2 id="58-删除结点">5.8. 删除结点：</h2>
<p>Redis5以后删除节点命令：</p>
<p>语法：</p>
<pre><code class="language-bash">redis-cli --cluster del-node ip:port node_id
</code></pre>
<blockquote>
<p>注：上面的ip:port为集群中存在的任意节点，node_id是你要删除的节点的id</p>
</blockquote>
<p>示例：</p>
<pre><code class="language-bash">redis-cli --cluster del-node 10.10.14.166:7001 d3b977fd46386db84fd85b9240deb602087c8617
</code></pre>
<p>删除已经占有hash槽的结点会失败，报错如下：</p>
<p>[ERR] Node 127.0.0.1:7005 is not empty! Reshard data away and try again.</p>
<p>需要将该结点占用的hash槽分配出去（参考hash槽重新分配章节）。</p>
<h2 id="59-使用springboot整合rediscluster">5.9. 使用springboot整合RedisCluster</h2>
<p>配置文件：application.yml</p>
<pre><code class="language-yml">spring:
   redis:
   host: www.taotao.com
   #    port: 6379
   #    password:
   jedis:
     pool:
       max-idle: 2
       max-wait: 1000ms
   cluster:
     nodes: 10.10.14.166:7001,10.10.14.166:7002,10.10.14.166:7003,10.10.14.166:7004,10.10.14.166:7005,10.10.14.166:7006

</code></pre>
<p>测试代码</p>
<pre><code class="language-java">@Slf4j
@SpringBootTest
@RunWith(SpringRunner.class)
public class TestRedisClient {

  @Autowired
  private StringRedisTemplate redisTemplate;

  @Test
  public void testRedis() {
     Set&lt;String&gt; keys = redisTemplate.keys(&quot;*&quot;);
     log.info(&quot;操作前存在的keys: &quot; + keys);

     String key = &quot;lanou_F4&quot;;

     redisTemplate.opsForList().rightPushAll(key, new String[]{&quot;宋超&quot;, &quot;国胜&quot;, &quot;国伟&quot;, &quot;高飞&quot;});

     long size = redisTemplate.opsForList().size(key);
     log.info(&quot;当前&quot;+key+&quot;值的数量： &quot; + size);

     List&lt;String&gt; values = redisTemplate.opsForList().range(key, 0, size);
     log.info(&quot;当前&quot; + key +&quot;的值： &quot; + values);

     keys = redisTemplate.keys(&quot;*&quot;);
     log.info(&quot;操作后存在的keys: &quot; + keys);
  }
}
</code></pre>
<h1 id="6-redis持久化策略">6. Redis持久化策略</h1>
<h2 id="61-rdb快照模式">6.1 RDB快照模式</h2>
<p>缺省情况情况下，Redis把数据快照存放在磁盘上的二进制文件中，文件名为dump.rdb。你可以配置Redis的持久化策略，例如数据集中每N秒钟有超过M次更新，就将数据写入磁盘；或者你可以手工调用命令SAVE或BGSAVE。</p>
<h3 id="611-工作步骤">6.1.1 工作步骤</h3>
<ol>
<li>
<p>Redis forks；</p>
</li>
<li>
<p>子进程开始将数据写到临时RDB文件中；</p>
</li>
<li>
<p>当子进程完成写RDB文件，用新文件替换老文件；</p>
</li>
<li>
<p>当RedisServer重新启动时，读取RDB文件恢复到内存中。</p>
</li>
</ol>
<figure data-type="image" tabindex="15"><img src="redis-rdb.png" alt="RDB原理示意图"></figure>
<h3 id="612-配置参数">6.1.2 配置参数</h3>
<pre><code>save 900 1           #在900秒(15分钟)之后，如果至少有1个key发生变化，则dump内存快照。

save 300 10          #在300秒(5分钟)之后，如果至少有10个key发生变化，则dump内存快照。

save 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，则dump内存快照。
</code></pre>
<h2 id="62-aof模式">6.2 AOF模式</h2>
<p>快照模式并不十分健壮，当系统停止，或者无意中Redis被kill掉，最后写入Redis的数据就会丢失。这对某些应用也许不是大问题，但对于要求高可靠性的应用来说，</p>
<p>Redis就不是一个合适的选择。</p>
<p>Append-only-file 模式是另一种选择。</p>
<p>你可以在配置文件中打开AOF模式</p>
<h3 id="621-工作步骤">6.2.1 工作步骤</h3>
<ol>
<li>Redis客户端发送读写命令</li>
<li>RedisServer接收并执行命令，同时同步记录命令到AOF文件中</li>
<li>Redis重新启动时读取AOF文件，执行其中每一条指令完成数据恢复</li>
</ol>
<figure data-type="image" tabindex="16"><img src="redis-aof.png" alt="AOF原理示意图"></figure>
<h3 id="622-配置参数">6.2.2 配置参数</h3>
<pre><code># appendfsync always    # 命令过来后，立刻写入AOF文件（会强制flush操作系统IO缓冲）
appendfsync everysec	# 默认策略， 每秒钟将缓存的命令写入到AOF文件中
# appendfsync no        # 关闭AOF备份
</code></pre>
<h2 id="63-rdb模式与aof模式的对比">6.3 RDB模式与AOF模式的对比</h2>
<h3 id="631-rdb模式的优点">6.3.1 RDB模式的优点</h3>
<ol>
<li>
<p>一旦采用该方式，那么你的整个Redis数据库将只包含一个文件，这对于文件备份而言是非常完美的。比如，你可能打算每个小时归档一次最近24小时的数据，同时还要每天归档一次最近30天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。</p>
</li>
<li>
<p>对于灾难恢复而言，RDB是非常不错的选择。因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。</p>
</li>
<li>
<p>性能最大化。对于Redis的服务进程而言，在开始持久化时，它唯一需要做的只是fork出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行IO操作了。</p>
</li>
<li>
<p>相比于AOF机制，如果数据集很大，RDB的启动效率会更高。</p>
</li>
</ol>
<h3 id="632-rdb模式的缺点">6.3.2 RDB模式的缺点</h3>
<ol>
<li>
<p>如果你想保证数据的高可用性，即最大限度的避免数据丢失，那么RDB将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。</p>
</li>
<li>
<p>由于RDB是通过fork子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是1秒钟。</p>
</li>
</ol>
<h3 id="633-aof模式的优点">6.3.3 AOF模式的优点</h3>
<ol>
<li>
<p>该机制可以带来更高的数据安全性，即数据持久性。Redis中提供了3中同步策略，即每秒同步、每修改同步和不同步。事实上，每秒同步也是异步完成的，其效率也是非常高的，所差的是一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失。而每修改同步，我们可以将其视为同步持久化，即每次发生的数据变化都会被立即记录到磁盘中。可以预见，这种方式在效率上是最低的。至于无同步，无需多言，我想大家都能正确的理解它。</p>
</li>
<li>
<p>由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。然而如果我们本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在Redis下一次启动之前，我们可以通过redis-check-aof工具来帮助我们解决数据一致性的问题。</p>
</li>
<li>
<p>如果日志过大，Redis可以自动启用rewrite机制。即Redis以append模式不断的将修改数据写入到老的磁盘文件中，同时Redis还会创建一个新的文件用于记录此期间有哪些修改命令被执行。因此在进行rewrite切换时可以更好的保证数据安全性。</p>
</li>
<li>
<p>AOF包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作。事实上，我们也可以通过该文件完成数据的重建。</p>
</li>
</ol>
<h3 id="634-aof模式的缺点">6.3.4 AOF模式的缺点</h3>
<ol>
<li>
<p>对于相同数量的数据集而言，AOF文件通常要大于RDB文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。</p>
</li>
<li>
<p>根据同步策略的不同，AOF在运行效率上往往会慢于RDB。总之，每秒同步策略的效率是比较高的，同步禁用策略的效率和RDB一样高效。</p>
</li>
</ol>
<blockquote>
<p>二者选择的标准，就是看系统是愿意牺牲一些性能，换取更高的缓存一致性（aof），还是愿意写操作频繁的时候，不启用备份来换取更高的性能，待手动运行save的时候，再做备份（rdb）。rdb这个就更有些 eventually consistent的意思了。</p>
</blockquote>
<blockquote>
<h4 id="如果rdb文件和aof同时存在当redis重启的时候会优先载入aof文件来恢复原始的数据因为在通常情况下aof文件保存的数据集要比rdb文件完整">如果RDB文件和AOF同时存在，当redis重启的时候会优先载入AOF文件来恢复原始的数据,因为在通常情况下AOF文件保存的数据集要比RDB文件完整</h4>
</blockquote>
<h1 id="7-系统添加缓存逻辑示例">7.   系统添加缓存逻辑示例</h1>
<p>添加缓存逻辑的原则：缓存逻辑不能影响正常的业务逻辑执行。</p>
<h2 id="71-添加缓存后系统架构">7.1. 添加缓存后系统架构</h2>
<p>​</p>
<figure data-type="image" tabindex="17"><img src="https://ysjhhhhhhh.github.io/post-images/1576141457011.jpg" alt=""></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Git]]></title>
        <id>https://ysjhhhhhhh.github.io/post/git</id>
        <link href="https://ysjhhhhhhh.github.io/post/git">
        </link>
        <updated>2018-05-09T08:32:08.000Z</updated>
        <content type="html"><![CDATA[<h1 id="git是什么">Git是什么</h1>
<p>Git(读音为/gɪt/。)是一个开源的分布式版本控制系统，可以有效、高速地处理从很小到非常大的项目版本管理。 [1]  Git 是 [Linus Torvalds](https://baike.baidu.com/item/Linus Torvalds/9336769) 为了帮助管理 Linux 内核开发而开发的一个开放源码的版本控制软件。</p>
<h1 id="为什么要用git">为什么要用Git</h1>
<p>当我们在企业中开发程序时，往往不是一个人而是一个团队共同协作。我们需要有一个工具来将各个不同成员所开发的代码做一个共享和同步。这是第一个原因。另外，当我们不小心将代码误删除、或者我们自己电脑故障无法打开时，需要有一个地方来备份我们的代码，以便很方便的恢复。上述的几种场景Git都可以很轻松的解决。</p>
<h1 id="什么场景下要用git">什么场景下要用Git</h1>
<p>团队中多人协作开发、跨国多地协作开发项目时。</p>
<h1 id="如何使用git">如何使用Git</h1>
<h2 id="git下载-安装">Git下载、安装</h2>
<p>官方下载地址： https://git-scm.com/download/win</p>
<h2 id="git的工作区-暂存区-本地仓库-远程仓库">Git的工作区、暂存区、本地仓库、远程仓库</h2>
<h3 id="工作区">工作区</h3>
<p>就是我们在电脑里能看到的目录，我们平常直接编写的代码就在工作区。</p>
<h3 id="暂存区">暂存区</h3>
<p>英文叫stage, 或index。一般存放在 &quot;.git目录下&quot; 下的index文件（.git/index）中，所以我们把暂存区有时也叫作索引（index）。</p>
<h3 id="本地仓库">本地仓库</h3>
<p>工作区有一个隐藏目录.git，这个目录就是Git的版本库。</p>
<p>本地仓库用来存储代码历次修改信息的仓库。类似于SVN的远程仓库。里面存储了代码提交内容，提交人，提交备注，代码分支信息。</p>
<h3 id="远程仓库">远程仓库</h3>
<ul>
<li>公司内部搭建的远程仓库</li>
<li>Github、Gitee</li>
</ul>
<h3 id="工作区-暂存区-本地仓库之间的关系">工作区、暂存区、本地仓库之间的关系</h3>
<figure data-type="image" tabindex="1"><img src="https://ysjhhhhhhh.github.io/post-images/1576139559687.jpg" alt=""></figure>
<p>图中左侧为工作区，右侧为版本库。在版本库中标记为 &quot;index&quot; 的区域是暂存区（stage, index），标记为 &quot;master&quot; 的是 master 分支所代表的目录树。</p>
<p>图中我们可以看出此时 &quot;HEAD&quot; 实际是指向 master 分支的一个&quot;游标&quot;。所以图示的命令中出现 HEAD 的地方可以用 master 来替换。</p>
<p>图中的 objects 标识的区域为 Git 的对象库，实际位于 &quot;.git/objects&quot; 目录下，里面包含了创建的各种对象及内容。</p>
<p>当对工作区修改（或新增）的文件执行 &quot;git add&quot; 命令时，暂存区的目录树被更新，同时工作区修改（或新增）的文件内容被写入到对象库中的一个新的对象中，而该对象的ID被记录在暂存区的文件索引中。</p>
<p>当执行提交操作（git commit）时，暂存区的目录树写到版本库（对象库）中，master 分支会做相应的更新。即 master 指向的目录树就是提交时暂存区的目录树。</p>
<p>当执行 &quot;git reset HEAD&quot; 命令时，暂存区的目录树会被重写，被 master 分支指向的目录树所替换，但是工作区不受影响。</p>
<p>当执行 &quot;git rm --cached <file>&quot; 命令时，会直接从暂存区删除文件，工作区则不做出改变。</p>
<p>当执行 &quot;git checkout .&quot; 或者 &quot;git checkout -- <file>&quot; 命令时，会用暂存区全部或指定的文件替换工作区的文件。这个操作很危险，会清除工作区中未添加到暂存区的改动。</p>
<p>当执行 &quot;git checkout HEAD .&quot; 或者 &quot;git checkout HEAD <file>&quot; 命令时，会用 HEAD 指向的 master 分支中的全部或者部分文件替换暂存区和以及工作区中的文件。这个命令也是极具危险性的，因为不但会清除工作区中未提交的改动，也会清除暂存区中未提交的改动。</p>
<h2 id="git命令行的使用">Git命令行的使用</h2>
<ul>
<li>git init:  初始化git本地仓库</li>
<li>git status:  查看当前分支状态</li>
<li>git add: 将修改添加到工作区（暂存区）</li>
<li>git commit: 将修改提交到本地仓库</li>
<li>git log: 查看历次提交记录</li>
<li>git remote: 操作远程仓库</li>
</ul>
<h2 id="git第三方客户端使用">Git第三方客户端使用</h2>
<p>安装完git以后，官方其实自带了两个客户端，一个是纯命令行的Git Bash.exe另一个是图形界面工具Git GUI.exe，只不过官方自带的图形界面工具使用并不友好。我们常用的第三方客户端工具</p>
<ul>
<li>
<p>TortoiseGit</p>
</li>
<li>
<p>IDEA</p>
</li>
<li>
<p>Eclipse</p>
</li>
</ul>
<h2 id="在ide中使用">在IDE中使用</h2>
<p>我们常用的eclipse和IDEA集成开发环境已经默认都集成maven插件， 在平常的开发工程中，我们可以通过IDE很方便的随时完成代码提交。配置过程比较简单，这里不再赘述。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[SpringMVC]]></title>
        <id>https://ysjhhhhhhh.github.io/post/springmvc</id>
        <link href="https://ysjhhhhhhh.github.io/post/springmvc">
        </link>
        <updated>2018-04-30T13:07:49.000Z</updated>
        <content type="html"><![CDATA[<h1 id="springmvc">SpringMVC</h1>
<h2 id="springmvc-2">SpringMVC</h2>
<h3 id="什么是springmvc">什么是SpringMVC</h3>
<blockquote>
<p>SpringMVC是一种基于Java的实现MVC设计模式的请求驱动类型的轻量级Web框架，使用了MVC架构模式的思想，将web层进行职责解耦，基于请求驱动指的就是使用请求-响应模型，框架的目的就是帮助我们简化开发。</p>
</blockquote>
<h3 id="springmvc的优点">SpringMVC的优点</h3>
<blockquote>
<p>1.简单、容易上手；<br>
2.性能优异：jsp+servlet&gt;Struts=SpringMVC&gt;Struts2；<br>
3.灵活、易于扩展；<br>
4.易于和Spring容器整合；</p>
</blockquote>
<h3 id="springmvc依赖">SpringMVC依赖</h3>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework&lt;/groupId&gt;
    &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt;
    &lt;version&gt;5.2.0.RELEASE&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<h3 id="springmvc配置文件">SpringMVC配置文件</h3>
<h4 id="servletwebapplicationcontextxml-和-rootwebapplicationcontextxml">ServletWebApplicationContext.xml 和 RootWebApplicationContext.xml</h4>
<figure data-type="image" tabindex="1"><img src="https://docs.spring.io/spring/docs/5.2.0.RELEASE/spring-framework-reference/images/mvc-context-hierarchy.png" alt=""></figure>
<blockquote>
<p>dispatcher-servlet.xml 要比 applicationContext.xml后初始化，因此在dispatcher-servlet.xml中可以引用applicationContext.xml中配置的bean，反之不行</p>
</blockquote>
<h4 id="dispatcher-servlet">Dispatcher-servlet</h4>
<blockquote>
<p>DispatcherServlet是前置控制器，配置在web.xml文件中的。拦截匹配的请求，Servlet拦截匹配规则要自己定义，把拦截下来的请求，依据相应的规则分发到目标Controller来处理，是配置spring MVC的第一步。</p>
<p>DispatcherServlet是前端控制器设计模式的实现，提供Spring Web MVC的集中访问点，而且负责职责的分派，而且与Spring IoC容器无缝集成，从而可以获得Spring的所有好处。</p>
</blockquote>
<h3 id="springmvc中的组件">SpringMVC中的组件</h3>
<h4 id="视图解析器">视图解析器</h4>
<p>作用：将controller中方法的返回值解析成一个页面</p>
<p>配置视图解析器的方法：</p>
<p>(在dispatcher-servlet.xml中加入)</p>
<pre><code class="language-xml">&lt;mvc:view-resolvers&gt;
        &lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt;
            &lt;!-- 将返回的字符串的前面拼上‘/’ --&gt;
            &lt;property name=&quot;prefix&quot; value=&quot;/&quot;/&gt;
            &lt;!-- 将返回的字符串的前面拼上‘.jsp’ --&gt;
            &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;/&gt;
        &lt;/bean&gt;
&lt;/mvc:view-resolvers&gt;
</code></pre>
<h4 id="参数传递">参数传递</h4>
<p>Controller中接收页面传递的数据通过：</p>
<blockquote>
<h5 id="requestparam请求参数">@RequestParam	请求参数</h5>
<h5 id="requestheader请求头参数">@RequestHeader	请求头参数</h5>
<h5 id="requestattributerequest作用域参数">@RequestAttribute	request作用域参数</h5>
<h5 id="sessionattributesession作用域参数">@SessionAttribute	session作用域参数</h5>
<h5 id="cookievaluecookie中的数据">@CookieValue	cookie中的数据</h5>
</blockquote>
<pre><code class="language-java">//自动绑定到对象上
    @RequestMapping(&quot;/student&quot;)
    public String tostu(Student student, Model model){
        model.addAttribute(&quot;student&quot;,student);
        return &quot;student&quot;;
    }

    //获取请求头中的参数
    @RequestMapping(&quot;/reqparam&quot;)
    public String toreqparam(@RequestHeader(&quot;user-agent&quot;) String userAgent, Model model){
        model.addAttribute(&quot;tou&quot;,userAgent);
        return &quot;reqparam&quot;;
    }

    //获取cookie中的数据
    @RequestMapping(&quot;/tocookie&quot;)
    public String tocookie(@CookieValue(&quot;JSESSIONID&quot;) String JSESSIONID, Model model){
        model.addAttribute(&quot;cookieinfo&quot;,JSESSIONID);
        return &quot;cookie&quot;;
    }
</code></pre>
<p>从controller中向页面传递数据</p>
<p>Model</p>
<pre><code class="language-java">//获取Model然后将参数添加进Model中传递到前端
    @RequestMapping(&quot;/reqparam&quot;)
    public String toreqparam(@RequestHeader(&quot;user-agent&quot;) String userAgent, Model model){
        model.addAttribute(&quot;tou&quot;,userAgent);
        return &quot;reqparam&quot;;
    }
</code></pre>
<p>ModelAndView</p>
<pre><code class="language-java">//使用ModelAndView，如：
@RequestMapping(&quot;/userLogin&quot;)
    public ModelAndView userLogin(@RequestParam String username, @RequestParam String password, ModelMap model, HttpSession session){

        ModelAndView mav;

        User user = userService.UserLogin(username, password);

        if (user==null){
            model.addAttribute(&quot;errorInfo&quot;,&quot;登录失败，账号或密码错误!&quot;);

            mav = new ModelAndView(&quot;forward:login.jsp&quot;,model);


            return mav;
        }else{
            UserAndRole userAndRole = userService.selectUserAndRoleById(user.getId());
            List&lt;Menu&gt; menuListByRoleName = userService.getMenuListByRoleName(userAndRole.getRoleName());
            session.setAttribute(&quot;userId&quot;,user.getId());
            session.setAttribute(&quot;userName&quot;,user.getUserName());
            session.setAttribute(&quot;roleName&quot;,userAndRole.getRoleName());
            session.setAttribute(&quot;menuList&quot;,menuListByRoleName);
            session.setAttribute(&quot;user&quot;,user);


            mav = new ModelAndView(&quot;index&quot;).addAllObjects(model);
        return mav;

        }

    }
</code></pre>
<h4 id="视图控制器">视图控制器</h4>
<p>作用：</p>
<blockquote>
<p>当在使用springmvc时，且想要进入某个页面不经过controller时，可以使用视图控制器来进行页面访问。</p>
</blockquote>
<p>用法</p>
<p>在dispatcher-servlet.xml中配置视图控制器</p>
<pre><code class="language-xml">&lt;!-- path是拦截的请求路径，view-name是进入的页面 --&gt;
&lt;mvc:view-controller path=&quot;&quot; view-name=&quot;&quot;/&gt;
</code></pre>
<h4 id="处理静态资源">处理静态资源</h4>
<p>由于dispatcher-servlet会拦截除jsp外的所有请求，因此对静态资源的访问也会被拦截，此时我们就需要配置静态资源放行，来放行对应的静态资源。放行静态资源的方法为：</p>
<pre><code class="language-xml">&lt;!--  在dispatcher-servlet.xml中配置以下标签放行静态资源 --&gt;
&lt;mvc:resources mapping=&quot;/static/**&quot; location=&quot;/static/&quot;/&gt;
</code></pre>
<h4 id="springmvc中请求重定向和请求转发">SpringMVC中请求重定向和请求转发</h4>
<p>在controller中重定向的方法</p>
<pre><code class="language-java">@RequestMapping(&quot;/aaa&quot;)
    public String aaa(@RequestParam Integer userId, @RequestParam Integer permissionStatus, HttpServletResponse resp) throws IOException {

        //重定向
        return &quot;redirect:login.jsp&quot;

    }
</code></pre>
<p>在controller中请求转发的方法</p>
<pre><code class="language-java">@RequestMapping(&quot;/bbb&quot;)
    public String bbb(@RequestParam Integer userId, @RequestParam Integer permissionStatus, HttpServletResponse resp) throws IOException {

        //重定向
        return &quot;forward:login.jsp&quot;

    }
</code></pre>
<p>注意：</p>
<blockquote>
<p>通过加redirect 和 forward 请求转发和重定向 不会经过视图解析器 ，因此需要加入.jsp之类的后缀</p>
</blockquote>
<h3 id="处理springmvc中的乱码">处理SpringMVC中的乱码</h3>
<p>在web.xml中配置SpringMVC中带的处理字符乱码的filter</p>
<pre><code class="language-xml">&lt;filter&gt;
    &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt;
    &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt;
    &lt;init-param&gt;
      &lt;param-name&gt;encoding&lt;/param-name&gt;
      &lt;param-value&gt;UTF-8&lt;/param-value&gt;
    &lt;/init-param&gt;
  &lt;/filter&gt;
  &lt;filter-mapping&gt;
    &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt;
    &lt;url-pattern&gt;/*&lt;/url-pattern&gt;
  &lt;/filter-mapping&gt;
</code></pre>
<h3 id="高级请求映射">高级请求映射</h3>
<h4 id="匹配请求地址上的参数">匹配请求地址上的参数</h4>
<pre><code class="language-java">@RequestMapping(&quot;/hello/01/{info}&quot;)
    public String hello001(@PathVariable String info, Model model){

        model.addAttribute(&quot;info&quot;, info);

        return &quot;info&quot;;
    }
</code></pre>
<h4 id="匹配以helloaaa开头的可以匹配零个或多个字符">匹配以/hello/aaa/开头的(*可以匹配零个或多个字符)</h4>
<pre><code class="language-java">@RequestMapping(&quot;/hello/aaa/*&quot;)
    public String hello003(Model model){

        model.addAttribute(&quot;info&quot;, &quot;匹配到*的&quot;);

        return &quot;info&quot;;
    }
</code></pre>
<h4 id="匹配到以helloaaa开头的只能匹配一个字符">匹配到以/hello/aaa/开头的（？只能匹配一个字符）</h4>
<pre><code class="language-java">@RequestMapping(&quot;/hello/aaa/?&quot;)
    public String hello002(Model model){

        model.addAttribute(&quot;info&quot;, &quot;匹配到？的&quot;);

        return &quot;info&quot;;
    }
</code></pre>
<h4 id="匹配到以helloaaa开头的可以匹配多个路径">匹配到以/hello/aaa/开头的（**可以匹配多个路径）</h4>
<pre><code class="language-java">@RequestMapping(&quot;/hello/aaa/**&quot;)
    public String hello004(Model model){

        model.addAttribute(&quot;info&quot;, &quot;匹配到**的&quot;);

        return &quot;info&quot;;
    }
</code></pre>
<h4 id="根据正则表达式匹配并且可以获取其中的参数">根据正则表达式匹配，并且可以获取其中的参数</h4>
<pre><code class="language-java">@RequestMapping(&quot;/hello/aaa/{name:[a-z-]+}-{version:\\d\\.\\d\\.\\d}{ext:\\.[a-z]+}&quot;)
public String hello005(@PathVariable String name,@PathVariable String version,@PathVariable String ext,Model model){    
    model.addAttribute(&quot;info&quot;, name+version+ext);    
    return &quot;info&quot;;
}
</code></pre>
<h3 id="文件上传">文件上传</h3>
<h4 id="25方式">2.5方式</h4>
<ol>
<li>导包</li>
</ol>
<pre><code class="language-xml">&lt;dependency&gt;
      &lt;groupId&gt;commons-fileupload&lt;/groupId&gt;
      &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt;
      &lt;version&gt;1.4&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;commons-io&lt;/groupId&gt;
      &lt;artifactId&gt;commons-io&lt;/artifactId&gt;
      &lt;version&gt;2.6&lt;/version&gt;
    &lt;/dependency&gt;
</code></pre>
<ol start="2">
<li>配置bean</li>
</ol>
<pre><code class="language-xml">&lt;bean id=&quot;multipartResolver&quot; class=&quot;org.springframework.web.multipart.commons.CommonsMultipartResolver&quot;/&gt;
</code></pre>
<h4 id="30方式">3.0方式</h4>
<ol>
<li>
<p>配置bean</p>
<pre><code class="language-xml">&lt;bean id=&quot;multipartResolver&quot; class=&quot;org.springframework.web.multipart.support.StandardServletMultipartResolver&quot;/&gt;
</code></pre>
</li>
<li>
<p>添加注解</p>
</li>
</ol>
<pre><code class="language-xml">&lt;servlet&gt;
    &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt;
    &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;
    &lt;init-param&gt;
      &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;
      &lt;param-value&gt;/WEB-INF/dispatcher-servlet.xml&lt;/param-value&gt;
    &lt;/init-param&gt;
    
    
    &lt;!-- 相当于不使用springmvc时的文件上传添加注解的效果 --&gt;
    &lt;multipart-config/&gt;
    
  &lt;/servlet&gt;
  &lt;servlet-mapping&gt;
    &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt;
    &lt;url-pattern&gt;/&lt;/url-pattern&gt;
  &lt;/servlet-mapping&gt;
</code></pre>
<h4 id="使用">使用</h4>
<pre><code class="language-java">@RequestMapping(&quot;/upload&quot;)
    public String upload1(@RequestParam MultipartFile file, Model model, HttpServletRequest req){

        String filename= file.getOriginalFilename();

        String filePath = null;

                try {
                    filePath = WebUtils.getRealPath(req.getServletContext(),&quot;/upload/&quot;+filename);
//                    System.out.println(filePath);
                    if (filePath!= null){
                        file.transferTo(new File(filePath));
                    }
                }catch (Exception e){

                }

        model.addAttribute(&quot;filename&quot;,filename);
                model.addAttribute(&quot;filepath&quot;,&quot;http://localhost:8080/upload/&quot;+filename);
        return &quot;fileuploadsuccess&quot;;
    }
</code></pre>
<h3 id="restfull服务">RESTfull服务</h3>
<blockquote>
<p>我们可以通过以下两种方式提供RESTFull的服务</p>
<ul>
<li>用<code>@RestController</code>注解替换Controller类上的<code>@Controller</code>注解，这样该类里面所有的RequestMapping方法都会强制输出返回的内容本身给调用方</li>
<li>在需要提供RESTFull的RequestMapping方法上添加<code>@ResonpseBody</code>注解，这样会强制此方法输出返回的内容本身给调用方。</li>
</ul>
<p>此外，SpringMVC还给我们提供了专用的RESTFull相关注解<code>GetMapping</code>、<code>PostMapping</code>、<code>PutMapping</code>、<code>DeleteMapping</code>、<code>PatchMapping</code>用于简化<code>@RequestMapping</code>注解， 比如<code>@GetMapping</code>注解就相当于<code>@RequestMapping(method=RequestMethod.GET)</code></p>
</blockquote>
<h3 id="拦截器">拦截器</h3>
<p>使用拦截器步骤：</p>
<ol>
<li>
<p>新建拦截器类并实现HandlerInterceptor接口</p>
<pre><code class="language-java">package com.lanou3g.springmvc.interceptor;

import org.springframework.lang.Nullable;
import org.springframework.web.servlet.HandlerInterceptor;
import org.springframework.web.servlet.ModelAndView;

import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;

/**
 * @author Administrator
 */
public class MyTestInterceptor implements HandlerInterceptor {

    //handler执行前
    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {
        System.out.println(&quot;方法被拦截&quot;);
        return false;
    }

    //handler执行后
    @Override
    public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, @Nullable ModelAndView modelAndView) throws Exception {
    }

    
    //请求完成之后，返回到客户端之前
    @Override
    public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, @Nullable Exception ex) throws Exception {
    }
}
</code></pre>
</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mybatis]]></title>
        <id>https://ysjhhhhhhh.github.io/post/mybatis</id>
        <link href="https://ysjhhhhhhh.github.io/post/mybatis">
        </link>
        <updated>2018-04-21T05:12:11.000Z</updated>
        <content type="html"><![CDATA[<h1 id="mybatis">Mybatis</h1>
<h2 id="mybatis简介">Mybatis简介</h2>
<p>了解mybatis前先了解一下ORM 和 JPA的概念</p>
<h3 id="orm">ORM</h3>
<p>ORM（Object-Relationship-Mapping）：是对象关系映射的意思，它是一种思想，是指将数据库中的每一行数据用对象的形式表现出来。</p>
<h3 id="jpa">JPA</h3>
<p>JPA（Java-Persistence-API）：是Java持久化接口的意思，它是JavaEE关于ORM思想的一套标准接口，仅仅是一套接口，不是具体的实现。</p>
<h3 id="什么是mybatis">什么是Mybatis?</h3>
<blockquote>
<p>MyBatis是一个实现了JPA规范的用来连接数据库并对其进行增删改查操作的开源框架 （就和传统的JDBC一样，就是个连接数据库的东西），其实，它底层就是一个JDBC封装的组件。MyBatis的前身是Ibatis，Ibatis创建与2002年最初为Apache下面的一个开源项目，2010迁移到google code下面并改名为MyBatis。</p>
<p>MyBatis虽然实现了JPA但是它并不是一个完完全全的ORM组件，而是一个基于SQL开发的半ORM组件。</p>
<p>而Hibernate是一个完完全全的ORM组件，它是完全基于对象来操作数据库中的记录，并不和MyBatis一样是一个假把式。</p>
</blockquote>
<h3 id="mybatis有什么优点">Mybatis有什么优点</h3>
<blockquote>
<p>简单易学，容易上手（相比于Hibernate） ---- 基于SQL编程<br>
消除了JDBC大量冗余的代码，不需要手动开关连接<br>
很好的与各种数据库兼容（因为MyBatis使用JDBC来连接数据库，所以只要JDBC支持的数据库MyBatis都支持，而JDB提供了可扩展性，所以只要这个数据库有针对Java的jar包就可以就可以与MyBatis兼容），开发人员不需要考虑数据库的差异性。<br>
提供了很多第三方插件（分页插件 / 逆向工程）<br>
能够与Spring很好的集成</p>
</blockquote>
<h2 id="mybatis环境搭建">MyBatis环境搭建</h2>
<h3 id="maven项目下">Maven项目下</h3>
<p>在pom.xml文件中添加依赖信息</p>
<pre><code class="language-xml">&lt;!-- https://mvnrepository.com/artifact/org.mybatis/mybatis --&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.mybatis&lt;/groupId&gt;
      &lt;artifactId&gt;mybatis&lt;/artifactId&gt;
      &lt;version&gt;x.x.x&lt;/version&gt;
    &lt;/dependency&gt;
&lt;!-- mybatis需要依赖jdbc --&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;mysql&lt;/groupId&gt;
      &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
      &lt;version&gt;5.1.47&lt;/version&gt;
    &lt;/dependency&gt;
&lt;!-- mybatis需要配置数据源，任选一种即可.如： --&gt;
&lt;dependency&gt;
      &lt;groupId&gt;com.mchange&lt;/groupId&gt;
      &lt;artifactId&gt;c3p0&lt;/artifactId&gt;
      &lt;version&gt;0.9.5.4&lt;/version&gt;
    &lt;/dependency&gt;

</code></pre>
<h3 id="非maven项目下">非Maven项目下</h3>
<p>引入相应的jar包</p>
<blockquote>
<ul>
<li>mybatis-x.x.x.jar</li>
<li>mysql-connector-java-5.1.47.jar</li>
<li>c3p0-0.9.5.4.jar</li>
</ul>
</blockquote>
<h3 id="配置jdbcproperties文件">配置jdbc.properties文件</h3>
<pre><code class="language-properties">driverClass=com.mysql.jdbc.Driver
jdbcUrl=jdbc:mysql://127.0.0.1:3306/test
user=root
password=root
</code></pre>
<h2 id="深入了解mybatis">深入了解MyBatis</h2>
<h3 id="mybatis的配置文件和组件">MyBatis的配置文件和组件</h3>
<h4 id="mybatis-configxml文件的配置">mybatis-config.xml文件的配置</h4>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;
&lt;!DOCTYPE configuration
        PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot;
        &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;

&lt;configuration&gt;
    
    &lt;!-- 引入外部配置文件 --&gt;
    &lt;properties resource=&quot;&quot;&gt;&lt;/properties&gt;
    
    &lt;!-- typeAliases因为MyBatis配置中使用的类名是全限定类名，类名较长，可以配置别名 --&gt;
    &lt;typeAliases&gt;
    &lt;/typeAliases&gt;
    
    &lt;!-- MyBatis的环境配置，可以配置具体的事务管理和数据源 --&gt;
    &lt;environments default=&quot;development&quot;&gt;
        &lt;environment id=&quot;development&quot;&gt;
            &lt;transactionManager type=&quot;JDBC&quot;&gt;&lt;/transactionManager&gt;
            &lt;dataSource type=&quot;POOLED&quot;&gt;
                &lt;property name=&quot;driver&quot; value=&quot;${database.driver}&quot;/&gt;
                &lt;property name=&quot;url&quot; value=&quot;${database.url}&quot;/&gt;
                &lt;property name=&quot;username&quot; value=&quot;${database.username}&quot;/&gt;
                &lt;property name=&quot;password&quot; value=&quot;${database.password}&quot;/&gt;
            &lt;/dataSource&gt;
        &lt;/environment&gt;
    &lt;/environments&gt;
    
    &lt;!-- 关联mapper映射 --&gt;
    &lt;mappers&gt;
        &lt;mapper resource=&quot;mybatis/mappers/StudentMapper.xml&quot;/&gt;
    &lt;/mappers&gt;

&lt;/configuration&gt;
</code></pre>
<h4 id="sqlsessionfactory">SqlSessionFactory</h4>
<p>SqlSessionFactory是MyBatis的关键对象,它是个单个数据库映射关系经过编译后的内存镜像.SqlSessionFactory对象的实例可以通过SqlSessionFactoryBuilder对象类获得,而SqlSessionFactoryBuilder则可以从XML配置文件或一个预先定制的Configuration的实例构建出SqlSessionFactory的实例.每一个MyBatis的应用程序都以一个SqlSessionFactory对象的实例为核心.同时SqlSessionFactory也是线程安全的,SqlSessionFactory一旦被创建,应该在应用执行期间都存在.在应用运行期间不要重复创建多次,建议使用单例模式.SqlSessionFactory是创建SqlSession的工厂.</p>
<h4 id="sqlsession">SqlSession</h4>
<p>SqlSession是MyBatis的关键对象,是执行持久化操作的独享,类似于JDBC中的Connection.它是应用程序与持久层之间执行交互操作的一个单线程对象,也是MyBatis执行持久化操作的关键对象.SqlSession对象完全包含以数据库为背景的所有执行SQL操作的方法,它的底层封装了JDBC连接,可以用SqlSession实例来直接执行被映射的SQL语句.每个线程都应该有它自己的SqlSession实例.SqlSession的实例不能被共享,同时SqlSession也是线程不安全的,绝对不能讲SqlSeesion实例的引用放在一个类的静态字段甚至是实例字段中.也绝不能将SqlSession实例的引用放在任何类型的管理范围中,比如Servlet当中的HttpSession对象中.使用完SqlSeesion之后关闭Session很重要,应该确保使用finally块来关闭它.</p>
<h4 id="mapper">Mapper</h4>
<p>Mapper接口和Mapper的xml文件是一一对应的。</p>
<p>具体的sql语句写在Mapper.xml中的insert delete select update标签内，只需做好相应的映射。Mybatis就会自动创建具体的接口实现类实现具体的方法供我们调用</p>
<p>绑定Mapper映射需要注意以下几点：</p>
<blockquote>
<ul>
<li>mapper.xml配置的namespace要是对应的接口的全限定接口名</li>
<li>mapper.xml配置的相应insert delete select update标签的id和接口中的方法名一一对应</li>
<li>select标签一定要设置resultType属性的值为要返回的查询结果的类型，或者指定对应的resultMap结果集映射</li>
</ul>
</blockquote>
<h3 id="具体的使用mybatis步骤">具体的使用Mybatis步骤</h3>
<h4 id="先创建实体bean">先创建实体bean</h4>
<h5 id="girl类">girl类</h5>
<pre><code class="language-java">package com.lanou3g.bean;

import lombok.Getter;
import lombok.Setter;
import lombok.ToString;

@Getter
@Setter
@ToString
public class Girl {
    private Integer id;
    private String name;
    private Integer king_id;
}

</code></pre>
<h5 id="queen类">queen类</h5>
<pre><code class="language-java">package com.lanou3g.bean;

import lombok.Getter;
import lombok.Setter;
import lombok.ToString;

@Getter
@Setter
@ToString
public class Queen {
    private Integer id;
    private String name;
    private Integer king_id;
}
</code></pre>
<h5 id="king类">king类</h5>
<pre><code class="language-java">package com.lanou3g.bean;

import lombok.Getter;
import lombok.Setter;
import lombok.ToString;

import java.util.List;

@Getter
@Setter
@ToString
public class King {
    private Integer id;
    private String name;
    private Queen queen;
    private List&lt;Girl&gt; girls;
}

</code></pre>
<h4 id="新建一个mybatis-configxml配置文件并进行相应的配置">新建一个mybatis-config.xml配置文件并进行相应的配置</h4>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;
        &lt;!DOCTYPE configuration
                PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot;
                &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;
&lt;configuration&gt;
    &lt;!-- 引入外部properties文件 --&gt;
&lt;properties resource=&quot;jdbc.properties&quot;&gt;&lt;/properties&gt;
&lt;typeAliases&gt;
&lt;!-- 为指定包中的类起别名 --&gt;
    &lt;package name=&quot;com.lanou3g.bean&quot;/&gt;
&lt;/typeAliases&gt;
&lt;environments default=&quot;development&quot;&gt;
    &lt;environment id=&quot;development&quot;&gt;
        &lt;transactionManager type=&quot;JDBC&quot;&gt;&lt;/transactionManager&gt;
        &lt;dataSource type=&quot;POOLED&quot;&gt;
            &lt;property name=&quot;driver&quot; value=&quot;${jdbc.driver}&quot;/&gt;
            &lt;property name=&quot;url&quot; value=&quot;${jdbc.url}&quot;/&gt;
            &lt;property name=&quot;username&quot; value=&quot;${jdbc.username}&quot;/&gt;
            &lt;property name=&quot;password&quot; value=&quot;${jdbc.password}&quot;/&gt;
        &lt;/dataSource&gt;
    &lt;/environment&gt;
&lt;/environments&gt;
    
&lt;!-- 关联mapper映射 --&gt;
&lt;mappers&gt;
    &lt;mapper resource=&quot;mybatis/mappers/StudentMapper.xml&quot;/&gt;
&lt;/mappers&gt;

&lt;/configuration&gt;
</code></pre>
<h4 id="创建mapper接口">创建mapper接口</h4>
<pre><code class="language-java">package com.lanou3g.dao;

import com.lanou3g.bean.King;

public interface KingDao {
    King getKingById(Integer id);
}

</code></pre>
<h4 id="创建mapperxml">创建mapper.xml</h4>
<h5 id="mapperxml文件中resultmap">mapper.xml文件中resultMap</h5>
<p>为什么使用resultMap：当查询出来的字段名和对象中的属性名不一致的情况就没办法使用resultType来默认映射</p>
<blockquote>
<p>每个具体的标签的column属性代表在数据库中查到的字段，最后映射结果的时候会映射到实体类中名为property对应字符的属性中（如：一个国王有一个王后和多个妃子）</p>
<ul>
<li>id 子标签是对应数据库中主键且自增的字段</li>
<li>result 子标签对应普通字段</li>
<li>association 子标签用来处理一对一关系映射（用来处理王后）</li>
<li>collection 字标签用来处理一对多关系映射（用来处理妃子）</li>
</ul>
</blockquote>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;
&lt;!DOCTYPE mapper
        PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;
        &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;
&lt;mapper namespace=&quot;com.lanou3g.dao.KingDao&quot;&gt;

    &lt;resultMap id=&quot;kingMap&quot; type=&quot;king&quot;&gt;
        &lt;id column=&quot;kid&quot; property=&quot;id&quot;/&gt;
        &lt;result column=&quot;kname&quot; property=&quot;name&quot;/&gt;
        &lt;association property=&quot;queen&quot; javaType=&quot;queen&quot; columnPrefix=&quot;q_&quot;&gt;
            &lt;id column=&quot;id&quot; property=&quot;id&quot;/&gt;
            &lt;result column=&quot;name&quot; property=&quot;name&quot;/&gt;
            &lt;result column=&quot;king_id&quot; property=&quot;king_id&quot;/&gt;
        &lt;/association&gt;
        &lt;collection property=&quot;girls&quot; ofType=&quot;girl&quot; columnPrefix=&quot;g_&quot;&gt;
            &lt;id column=&quot;id&quot; property=&quot;id&quot;/&gt;
            &lt;result column=&quot;name&quot; property=&quot;name&quot;/&gt;
            &lt;result column=&quot;king_id&quot; property=&quot;king_id&quot;/&gt;
        &lt;/collection&gt;
    &lt;/resultMap&gt;

    &lt;!-- 通过此查询语句查询出king的信息以及king的queen的信息和众多girl的信息 --&gt;
    &lt;select id=&quot;getKingById&quot; resultMap=&quot;kingMap&quot;&gt;
        select
        king.id kid,
        king.name kname,
        q.id q_id,
        q.`name` q_name,
        q.king_id q_king_id,
        g.id g_id,
        g.`name` g_name,
        g.king_id g_king_id
        from king
        LEFT JOIN queen q ON king.id = q.king_id
        LEFT JOIN girl g on q.king_id = g.king_id
        where g.king_id = #{id}
    &lt;/select&gt;
&lt;/mapper&gt;
</code></pre>
<h4 id="获取mybatis文件的输入流">获取mybatis文件的输入流</h4>
<pre><code class="language-java">InputStream is = Resources.getResourceAsStream(&quot;mybatis-config.xml&quot;);
</code></pre>
<h4 id="获取sqlsessionfactory对象">获取SqlSessionFactory对象</h4>
<pre><code class="language-java">SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(is)
</code></pre>
<h4 id="获取sqlsession对象">获取SqlSession对象</h4>
<pre><code class="language-java">//添加参数true设置事务自动提交，默认不会自动提交
SqlSession sqlSession = sqlSessionFactory.openSession(true);
</code></pre>
<h4 id="获取mybatis自动生成的接口的具体实现类并执行方法接收返回值">获取mybatis自动生成的接口的具体实现类并执行方法，接收返回值。</h4>
<pre><code class="language-java">King king = sqlSession.getMapper(KingDao.class).getKingById(1);
</code></pre>
<h3 id="和的作用和区别">#{}和${}的作用和区别</h3>
<h4 id="作用">作用</h4>
<p>通过#{}和${}取出调用方法时传入的参数，并将其应用在sql语句中</p>
<h4 id="区别">区别</h4>
<blockquote>
<p>#{}是预编译处理，${}是字符串替换。</p>
<p>（1）mybatis在处理#{}时，会将sql中的#{}替换为?号，调用PreparedStatement的set方法来赋值。</p>
<p>（2）mybatis在处理<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mrow></mrow><mi mathvariant="normal">时</mi><mi mathvariant="normal">，</mi><mi mathvariant="normal">就</mi><mi mathvariant="normal">是</mi><mi mathvariant="normal">把</mi></mrow><annotation encoding="application/x-tex">{}时，就是把</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0em;vertical-align:0em;"></span><span class="mord"></span><span class="mord cjk_fallback">时</span><span class="mord cjk_fallback">，</span><span class="mord cjk_fallback">就</span><span class="mord cjk_fallback">是</span><span class="mord cjk_fallback">把</span></span></span></span>{}替换成变量的值。</p>
<p>（3）使用#{}可以有效的防止SQL注入，提高系统安全性。原因在于：预编译机制。</p>
<p>预编译是提前对SQL语句进行预编译，而其后注入的参数将不会再进行SQL编译。我们知道，SQL注入是发生在编译的过程中，因为恶意注入了某些特殊字符，最后被编译成了恶意的执行操作。而预编译机制则可以很好的防止SQL注入。预编译完成之后，SQL的结构已经固定，即便用户输入非法参数，也不会对SQL的结构产生影响，从而避免了潜在的安全风险。</p>
</blockquote>
<h3 id="动态sql如何使用">动态sql如何使用</h3>
<h5 id="什么是动态sql">什么是动态sql</h5>
<blockquote>
<p>动态SQL是MyBatis的强大特性之一，MyBatis3采用了功能强大的基于OGNL的表达式来完成动态SQL。</p>
</blockquote>
<h5 id="动态sql的作用">动态sql的作用</h5>
<blockquote>
<p>MyBatis的动态SQL主要就是为了解决手动拼接SQL的麻烦。</p>
</blockquote>
<h5 id="动态sql有哪些标签">动态sql有哪些标签</h5>
<figure data-type="image" tabindex="1"><img src="https://images2017.cnblogs.com/blog/1240732/201711/1240732-20171101153219685-1084206827.png" alt=""></figure>
<h6 id="if标签的使用">if标签的使用</h6>
<pre><code class="language-xml">&lt;select id=&quot;queryStudentById&quot; resultType=&quot;com.lanou3g.bean.Student&quot; &gt;
        select * from stu 
        where name = #{name}
    	&lt;if test=&quot;sex!=null&quot;&gt;
            and sex = #{sex}
        &lt;/if&gt;
&lt;/select&gt;
</code></pre>
<h6 id="choose标签的使用">choose标签的使用</h6>
<pre><code class="language-xml">select * from stu where 1=1
      &lt;choose&gt;
           &lt;when test=&quot;name !=null and name !=''&quot;&gt;
                       and name = #{username}
           &lt;/when&gt;
           &lt;when test=&quot;sex !=null and sex !=''&quot;&gt;
                       and sex= #{sex}
           &lt;/when&gt;
           &lt;otherwise&gt;
                   
           &lt;/otherwise&gt;
      &lt;/choose&gt;
</code></pre>
<h6 id="where标签的使用">where标签的使用</h6>
<pre><code class="language-xml">select * from stu
&lt;where&gt;
     &lt;if test=&quot;name !=null and name !=''&quot;&gt;
           and username = #{username}
     &lt;/if&gt;
     &lt;if test=&quot;sex !=null and sex !=''&quot;&gt;
           and sex= #{sex}
     &lt;/if&gt;
&lt;/where&gt;
</code></pre>
<h6 id="foreach标签的使用">foreach标签的使用</h6>
<pre><code class="language-xml">select * from stu where id in
      &lt;foreach item=&quot;id&quot; index=&quot;index&quot; collection=&quot;list&quot; 
                      open=&quot;(&quot; separator=&quot;,&quot; close=&quot;)&quot;&gt;
             #{id}
      &lt;/foreach&gt;
</code></pre>
<h3 id="批量插入">批量插入</h3>
<h4 id="通过foreach子标签">通过<foreach>子标签</h4>
<pre><code class="language-xml">&lt;!-- 传入的要是list --&gt;
&lt;insert id=&quot;insertStudentBatch1&quot;&gt;
        insert into student (sno,sname,ssex,sage)
        values
        &lt;foreach collection=&quot;list&quot; item=&quot;stu&quot; separator=&quot;,&quot;&gt;
            (#{stu.sno},#{stu.sname},#{stu.ssex},#{stu.sage})
        &lt;/foreach&gt;
    &lt;/insert&gt;
</code></pre>
<p>可能会出现sql语句过大插入失败的结果</p>
<h4 id="通过设置executortypebatch属性">通过设置ExecutorType.BATCH属性</h4>
<pre><code class="language-java">SqlSession sqlSession = sqlSessionFactory.openSession(ExecutorType.BATCH, true);
</code></pre>
<p>每次只插入一条</p>
<pre><code class="language-xml">&lt;insert id=&quot;insertStudentBatch2&quot;&gt;
        insert into student (sno,sname,ssex,sage)
        value (#{sno},#{sname},#{ssex},#{sage})
&lt;/insert&gt;
</code></pre>
<p>循环插入</p>
<pre><code class="language-java">    private static void insert2() throws Exception{
        InputStream is = Resources.getResourceAsStream(&quot;mybatis-config.xml&quot;);

        SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder();

        SqlSessionFactory sqlSessionFactory = sqlSessionFactoryBuilder.build(is);

//        SqlSession sqlSession = sqlSessionFactory.openSession(true);
        SqlSession sqlSession = sqlSessionFactory.openSession(ExecutorType.BATCH, true);

        StudentDao mapper = sqlSession.getMapper(StudentDao.class);

        List&lt;Student&gt; stuList = App.getStuList();

        int total = 10;

        int count = 0 ;

        List&lt;BatchResult&gt; br = new ArrayList&lt;&gt;();

        for (Student student: stuList) {
            mapper.insertStudentBatch2(student);
            count++;
            System.out.println(&quot;count:&quot;+count);
            if (count%total==0){
                List&lt;BatchResult&gt; batchResults = sqlSession.flushStatements();
                br.addAll(batchResults);
            }
        }

        List&lt;BatchResult&gt; batchResults = sqlSession.flushStatements();
        br.addAll(batchResults);

        int a = 0;
        for (BatchResult b:br
             ) {
            System.out.println(222);
            int[] c = b.getUpdateCounts();
            for (int cc: c
            ) {
                System.out.println(cc);
                a+=cc;
            }
        }

        System.out.println(&quot;影响行数为：&quot; + a);
    }
</code></pre>
<p>可以通过sqlSession.flushStatements();刷新将数据插入到数据库</p>
<h3 id="缓存">缓存</h3>
<h4 id="一级缓存本地缓存">一级缓存（本地缓存）</h4>
<p>一级缓存默认开启，范围是同一个SqlSession</p>
<p>同一个SqlSession内执行同样一条查询语句时先访问缓存，如果命中缓存则不再去数据库中查询</p>
<p>关闭一级缓存，设置localCacheScope为STATEMENT就可以了</p>
<h4 id="二级缓存">二级缓存</h4>
<p>二级缓存可以跨SqlSession</p>
<p>开启二级缓存的方法</p>
<p>在mybatis配置文件中加入</p>
<pre><code class="language-xml">&lt;settings&gt; 
    &lt;!-- 开启全局二级缓存 --&gt;  
    &lt;setting name=&quot;cacheEnabled&quot; value=&quot;true&quot;/&gt; 
&lt;/settings&gt; 
</code></pre>
<p>在mapper映射文件中加入</p>
<pre><code class="language-xml">&lt;mapper namespace=&quot;com.lanou3g.dao.KingDao&quot;&gt;
&lt;cache /&gt;
&lt;/mapper&gt;
</code></pre>
<p>关闭指定语句不适用二级缓存</p>
<pre><code class="language-xml">&lt;select id=&quot;queryStudentById&quot; resultType=&quot;com.lanou3g.bean.Student&quot; useCache=&quot;false&quot;&gt;
        select * from stu 
        where name = #{name}
&lt;/select&gt;
</code></pre>
<p>注意事项</p>
<p>因为缓存要做到持久化就必须存入物理硬盘，因此对应的类要实现可序列化接口</p>
<pre><code class="language-java">public class Student implements Serializable { }
</code></pre>
<h1 id="spring-和mybatis整合">Spring 和MyBatis整合</h1>
<h2 id="加入整合jar包">加入整合jar包</h2>
<pre><code class="language-xml">&lt;!-- mybatis-spring整合包 --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.mybatis&lt;/groupId&gt;
    &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt;
    &lt;version&gt;2.0.1&lt;/version&gt;
&lt;/dependency&gt;

&lt;!-- Spring和数据源相关依赖 --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework&lt;/groupId&gt;
    &lt;artifactId&gt;spring-context&lt;/artifactId&gt;
    &lt;version&gt;5.2.0.RELEASE&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework&lt;/groupId&gt;
    &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt;
    &lt;version&gt;5.2.0.RELEASE&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
</code></pre>
<h2 id="对应的applicationcontextxml配置">对应的applicationContext.xml配置</h2>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;
       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;
       xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot;
       xmlns:mybatis=&quot;http://mybatis.org/schema/mybatis-spring&quot;
       xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot;
       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans
       http://www.springframework.org/schema/beans/spring-beans.xsd
       http://www.springframework.org/schema/context
       https://www.springframework.org/schema/context/spring-context.xsd
       http://www.springframework.org/schema/tx
       http://www.springframework.org/schema/tx/spring-tx.xsd
      http://mybatis.org/schema/mybatis-spring
      http://mybatis.org/schema/mybatis-spring.xsd
      http://www.springframework.org/schema/aop
      https://www.springframework.org/schema/aop/spring-aop.xsd&quot;&gt;



    &lt;aop:aspectj-autoproxy  expose-proxy=&quot;true&quot; proxy-target-class=&quot;true&quot;/&gt;

    &lt;bean id=&quot;dataSource&quot; class=&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot;/&gt;

    &lt;bean id=&quot;sqlSessionFactoryBean&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt;
        &lt;!-- 注入数据源 --&gt;
        &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt;
        &lt;!-- 设置mybatis核心配置文件路径（可选） --&gt;
        &lt;property name=&quot;configLocation&quot; value=&quot;mybatis-config.xml&quot; /&gt;
        &lt;!-- 配置mybatis xml映射文件位置（如果Mapper是用注解配置的，这里就不用设置此属性了） --&gt;
&lt;!--        &lt;property name=&quot;mapperLocations&quot; value=&quot;classpath:/mabatis/mappers/*&quot; /&gt;--&gt;
    &lt;/bean&gt;
    
    &lt;mybatis:scan base-package=&quot;com.lanou3g.mapper&quot;/&gt;

    &lt;context:component-scan base-package=&quot;com.lanou3g&quot; resource-pattern=&quot;com.lanou3g.mapper&quot;/&gt;


&lt;/beans&gt;
</code></pre>
<h2 id="添加事务">添加事务</h2>
<pre><code class="language-xml">&lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt;
        &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt;
    &lt;/bean&gt;
    &lt;bean id=&quot;service&quot; class=&quot;com.lanou3g.service.MyService&quot;/&gt;

    &lt;tx:advice id=&quot;myadc&quot; transaction-manager=&quot;transactionManager&quot;&gt;
        &lt;tx:attributes&gt;
            &lt;tx:method name=&quot;*&quot; rollback-for=&quot;Exception&quot; /&gt;
        &lt;/tx:attributes&gt;
    &lt;/tx:advice&gt;

    &lt;aop:config&gt;
        &lt;aop:pointcut id=&quot;myCut&quot; expression=&quot;execution(* com.lanou3g.service.*.*(..))&quot;/&gt;
        &lt;aop:advisor advice-ref=&quot;myadc&quot; pointcut-ref=&quot;myCut&quot;/&gt;
    &lt;/aop:config&gt;
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spring框架]]></title>
        <id>https://ysjhhhhhhh.github.io/post/spring-kuang-jia</id>
        <link href="https://ysjhhhhhhh.github.io/post/spring-kuang-jia">
        </link>
        <updated>2018-04-12T07:38:28.000Z</updated>
        <content type="html"><![CDATA[<h1 id="spring">Spring</h1>
<ul>
<li>
<p>什么是spring</p>
<blockquote>
<p>Spring是一个开源框架，Spring是于2003 年兴起的一个轻量级的Java 开发框架，由Rod Johnson开发。</p>
<p>它是为了解决企业应用开发的复杂性而创建的。框架的主要优势之一就是其分层架构，分层架构允许使用者选择使用哪一个组件，同时为 J2EE 应用程序开发提供集成的框架</p>
<p>dao(JdbcTemplate)  service(spring控制事务)   web(springmvc)</p>
<p>Spring的核心是控制反转（IoC）和面向切面（AOP）。</p>
<p>简单来说，Spring是一个分层的JavaSE/EE full-stack 轻量级开源框架。  1）IoC  和DI  2）AOP</p>
<p>一句话描述spring：full-stack 轻量级开源框架</p>
</blockquote>
</li>
<li>
<p>spring核心</p>
<blockquote>
<p>Spring的核心是控制反转IOC和面向切面AOP</p>
</blockquote>
</li>
</ul>
<h2 id="ioc">IOC</h2>
<ul>
<li>
<p>IOC是什么</p>
<blockquote>
<p>**Ioc—Inversion of Control，即“控制反转”，不是什么技术，而是一种设计思想。**在Java开发中，<strong>Ioc意味着将你设计好的对象交给容器控制，而不是传统的在你的对象内部直接控制。</strong></p>
</blockquote>
</li>
<li>
<p>spring IOC容器初始化方式</p>
<pre><code class="language-java">//xml初始化
ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;classpath:/ioc.xml&quot;);

//注解类初始化
ApplicationContext acc = new AnnotationConfigApplicationContext(ApplicationContextTest.class);
</code></pre>
</li>
<li>
<p>通过xml方式配置容器</p>
<blockquote>
<p>bean标签代指容器中的一个对象</p>
<p>property标签使用在bean标签之中为bean对象属性赋值</p>
</blockquote>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;
       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;
       xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot;
       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd&quot;&gt;


    &lt;bean id=&quot;stu01&quot; class=&quot;com.lanou.bean.Student&quot;&gt;
        &lt;property name=&quot;name&quot; value=&quot;张三&quot;&gt;&lt;/property&gt;
        &lt;property name=&quot;sex&quot; value=&quot;男&quot;&gt;&lt;/property&gt;
        &lt;property name=&quot;age&quot; value=&quot;28&quot;&gt;&lt;/property&gt;
    &lt;/bean&gt;

    &lt;bean id=&quot;stu02&quot; class=&quot;com.lanou.bean.Student&quot;&gt;
        &lt;constructor-arg value=&quot;李四&quot;&gt;&lt;/constructor-arg&gt;
        &lt;constructor-arg value=&quot;28&quot;&gt;&lt;/constructor-arg&gt;
    &lt;/bean&gt;

    &lt;context:property-placeholder location=&quot;classpath:jdbcConfig.properties&quot;/&gt;

    &lt;bean id=&quot;dataSource&quot; class=&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot;&gt;
        &lt;property name=&quot;user&quot; value=&quot;${jdbc.username}&quot;&gt;&lt;/property&gt;
        &lt;property name=&quot;password&quot; value=&quot;${jdbc.password}&quot;&gt;&lt;/property&gt;
        &lt;property name=&quot;driverClass&quot; value=&quot;${jdbc.driverClass}&quot;&gt;&lt;/property&gt;
        &lt;property name=&quot;jdbcUrl&quot; value=&quot;${jdbc.jdbcUrl}&quot;&gt;&lt;/property&gt;
    &lt;/bean&gt;

    &lt;bean id=&quot;plane&quot; class=&quot;com.lanou.bean.plane&quot; autowire=&quot;constructor&quot;&gt;
        &lt;property name=&quot;hight&quot; value=&quot;#{3*12}&quot;&gt;&lt;/property&gt;
    &lt;/bean&gt;

    &lt;bean id=&quot;teacher&quot; class=&quot;com.lanou.bean.Teacher&quot; p:name=&quot;#{T(java.util.UUID).randomUUID().toString()}&quot; p:age=&quot;20&quot; p:sex=&quot;女&quot;&gt;&lt;/bean&gt;
&lt;!--    &lt;bean id=&quot;teacher2&quot; class=&quot;com.lanou.bean.Teacher&quot; p:name=&quot;李老师&quot; p:age=&quot;20&quot; p:sex=&quot;男&quot;&gt;&lt;/bean&gt;--&gt;

    &lt;bean id=&quot;banji&quot; class=&quot;com.lanou.bean.BanJi&quot; autowire=&quot;constructor&quot;&gt;
&lt;!--        &lt;property name=&quot;teacher&quot; value=&quot;#{teacher2}&quot;&gt;&lt;/property&gt;--&gt;
    &lt;/bean&gt;

    &lt;bean id=&quot;dog1&quot; class=&quot;com.lanou.bean.Dog&quot;&gt;
        &lt;property name=&quot;name&quot; value=&quot;红狗&quot;&gt;&lt;/property&gt;
        &lt;property name=&quot;age&quot; value=&quot;2&quot;&gt;&lt;/property&gt;
    &lt;/bean&gt;

    &lt;bean class=&quot;com.lanou.bean.Man&quot;&gt;

    &lt;/bean&gt;

    &lt;!-- 扫描通过注解配置的容器bean --&gt;
    &lt;context:component-scan base-package=&quot;com.lanou&quot;&gt;&lt;/context:component-scan&gt;
&lt;/beans&gt;
</code></pre>
<p>bean初始化方法：</p>
<p>1.普通方式</p>
<pre><code class="language-xml">&lt;bean class=&quot;com.lanou.bean.Man&quot;&gt;
</code></pre>
<p>2.静态工厂方式</p>
<pre><code class="language-xml">&lt;!-- 
	class：指定的是静态工厂类 factory-method: 指定的是工厂中的静态方法 
--&gt;
&lt;bean id=&quot;getMan&quot; class=&quot;com.test.ManFactory&quot; factory-method=&quot;getMan&quot; /&gt;
</code></pre>
<p>3.实例工厂方式</p>
<pre><code class="language-xml">&lt;!-- 工厂实例bean --&gt;
&lt;bean id=&quot;manFactory&quot; class=&quot;com.lanou.ManFactory&quot;&gt;&lt;/bean&gt;

&lt;bean id=&quot;getMan&quot; factory-bean=&quot;manFactory&quot; factory-method=&quot;getMan&quot;&gt;&lt;/bean&gt;
</code></pre>
</li>
<li>
<p>通过注解的方式配置容器</p>
<pre><code class="language-java">package com.lanou3g;

import com.lanou3g.bean.Man;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.*;

import javax.annotation.Resource;

@Configuration //通过这个注解指定此类为IOC容器配置类
@ComponentScan(&quot;com.lanou3g&quot;)//次注解是指定容器初始化时扫描那些包下
@ImportResource({&quot;ioc.xml&quot;})//此注解表示在此配置类初始化时包含其他配置文件中的配置
@PropertySource(&quot;classpath:/manproperties.properties&quot;)//此注解表示在初始化容器时读取某properties文件中的配置信息
public class ApplicationContextTest {

    //此注解为属性赋值
    @Value(&quot;${name}&quot;)
    private String name;

    @Value(&quot;${age}&quot;)
    private Integer age;

    //此注解向容器中配置bean
    @Bean(&quot;man123&quot;)
    public Man aaa(){
        Man man = new Man();
        man.setName(&quot;哈哈&quot;);
        man.setAge(1);
        return man;
    }

    @Bean(&quot;manTest&quot;)
    public Man bbb(){
        Man man = new Man();
        man.setName(name);
        man.setAge(age);
        return man;
    }

}
</code></pre>
</li>
<li>
<p>bean的命名</p>
<blockquote>
<p>id是唯一标识，每个bean只能有一个id，且不同bean之间id也不能重复</p>
<p>name也是bean的标识，每个bean可以拥有多个name。name属性已久不能重复</p>
</blockquote>
</li>
<li>
<p>bean的作用域</p>
<blockquote>
<p>prototype:此属性表示此bean为多例，因此对象不会在容器初始化时创建</p>
<p>singleton(默认):单例bean会在容器初始化时创建bean对象</p>
</blockquote>
</li>
</ul>
<p>多例图解：</p>
<figure data-type="image" tabindex="1"><img src="https://docs.spring.io/spring/docs/5.2.0.RELEASE/spring-framework-reference/images/prototype.png" alt=""></figure>
<p>单例图解：</p>
<figure data-type="image" tabindex="2"><img src="https://docs.spring.io/spring/docs/5.2.0.RELEASE/spring-framework-reference/images/singleton.png" alt=""></figure>
<ul>
<li>
<p>bean懒加载：</p>
<p>lazy-init属性 默认是false</p>
<p>（懒加载主要是针对单例，可以让单例在容器初始化时不进行加载。在使用此bean是才去加载）</p>
</li>
</ul>
<h2 id="di">DI</h2>
<ul>
<li>
<p>DI-依赖注入</p>
<blockquote>
<p>创建对象的过程中Spring可以依据配置对对象的属性 进行设置，这个过程称之为依赖注入，即DI</p>
</blockquote>
</li>
<li>
<p>set方法注入</p>
<blockquote>
<p>通常javabean的属性都会私有化，而对外暴露setXx()getXx()方法，此时spring可以通过这样的setXx()方法将属性的值注入对象。</p>
<p>1)spring内置的可直接注入类型的注入</p>
<p>在<bean>标签下添加<property name="set方法名中set之后的单词(首字母小写)" value="要设置的属性的值"></p>
<p>2)非spring内置(即另外的实体类，比如定义一个Person类中有猫和狗两个属性，而猫和狗分别是两个实体类Cat和Dog的对象)的可以直接注入类型的注入</p>
<p>需要添加对应类的<bean>标签，在原始类中添加<property name="自定义名称(一般与类中的属性名称一致)" ref="非spring内置类配置的id值"></p>
</blockquote>
</li>
<li>
<p>基于构造方法的注入</p>
<blockquote>
<p>在<bean>标签下添加&lt;constructor-arg index=&quot;构造方法的第几个参数，下标从0开始&quot; name=&quot;为构造方法的哪个名字的参数ref:该构造方法参数的值,用来指定引用其他bean的值&gt;<br>
ps：index和name可以配置任何一个或同时配置，但要求一旦配置必须正确，推荐优先使用index方式配置，防止没有源码造成name无法匹配到对应的参数</p>
</blockquote>
</li>
<li>
<p>自动装配</p>
<blockquote>
<p>在Spring的set方式实现的注入过程中，支持自动装配机制。所谓自动装配机制，会根据要设置的javabean属性的名字或类型，到spring中自动寻找对应id或类型的<bean>进行设置，从而省去依次配置的过程，简化了配置。</p>
<p>自动装配的两种方式</p>
<p>1)为指定<bean>开启自动装配</p>
<p>在<bean>标签中添加autowire属性：<br>
byName：根据javabean（javabean简单的讲就是实体类，用来封装对象，这个类里面全部都是属性值和get、set方法）中需要注入的属性的名字，在spring容器中找对应id的<bean>，将该<bean>的对象赋值给当前的属性<br>
byType：根据javabean中需要注入的属性的类型，在Spring容器中找对应class类型的<bean>将该<bean>的对象赋值给当前的属性<br>
byType方式根据类型进行匹配，可能匹配到多个<bean>，此时会抛出异常，而byName是通过id来寻找<bean>，id没有重复，不会有这方面的问题，所以推荐使用byName方式<br>
总结：自动装配机制简化了set方法注入中的非Spring内置的可以直接注入类型的注入</p>
<p>2)为全局配置自动装配</p>
<p>在<beans>标签中添加default-autowire属性：<br>
byName与byType和第一点相同</p>
</blockquote>
</li>
</ul>
<h2 id="aop">AOP</h2>
<ul>
<li>
<p>什么是AOP</p>
<blockquote>
<p>在软件业，AOP为Aspect Oriented Programming的缩写，意为：面向切面编程，通过预编译方<br>
式和运行期动态代理实现程序功能的统一维护的一种技术。AOP是OOP的延续，是软件开发中的一个<br>
热点，也是Spring框架中的一个重要内容，是函数式编程的一种衍生范型。利用AOP可以对业务逻辑<br>
的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高<br>
了开发的效率。</p>
</blockquote>
</li>
<li>
<p>aop术语</p>
<blockquote>
<p>切面（Aspect）</p>
<p>简单来说，切面就是我们要往目标代码中插入进去的代码。</p>
<p>连接点（Join Pointer）</p>
<p>理论上所有可能会被切入的地方都可以称之为连接点</p>
<p>切入点(Pointcut)</p>
<p>选择某个连接点切入，将切面代码织入进去。这个连接点就叫做切入点。</p>
<p>织入(Weaving)</p>
<p>把切面代码糅合到目标代码中的过程就是织入。</p>
<p>通知(Advice)</p>
<p>通知决定了切面代码织入到目标代码中后，运行的时机(比如是在目标方法执行前，还是执行后)。</p>
</blockquote>
</li>
<li>
<p>在spring中使用aop</p>
<p>定义被切的类和方法</p>
<pre><code class="language-java">package com.lanou3g.bean;

import com.lanou3g.Calculator;
import org.springframework.stereotype.Component;

public class MyCalculator implements Calculator {
    @Override
    public int add(int a, int b) {
        return a+b;
    }

    @Override
    public int sub(int a, int b) {
        return a-b;
    }

    @Override
    public int mul(int a, int b) {
        return a*b;
    }

    @Override
    public int div(int a, int b) {
        return a/b;
    }
}

</code></pre>
<p>定义切面类</p>
<pre><code class="language-java">package com.lanou3g.log;


import org.aspectj.lang.JoinPoint;
import org.aspectj.lang.ProceedingJoinPoint;
import org.aspectj.lang.annotation.Aspect;
import org.springframework.stereotype.Component;

import java.util.Arrays;

public class CalculatorLog {

//    public static void cutclass(){}

    public static void logStart(JoinPoint joinPoint){
        String methodname = joinPoint.getSignature().getName();
        System.out.println(methodname+&quot;方法前置切面方法启动，参数为:&quot;+ Arrays.asList(joinPoint.getArgs()));
    }



    public static void logThrowing(JoinPoint joinPoint,Exception e){
        String methodname = joinPoint.getSignature().getName();
        System.out.println(methodname+&quot;方法异常切面方法启动，错误信息为:&quot;+ e.getMessage());
    }

    public static void logEnd(JoinPoint joinPoint){
        String methodname = joinPoint.getSignature().getName();
        System.out.println(methodname+&quot;方法最终切面方法启动&quot;);
    }

    public static Object logAround(ProceedingJoinPoint pjp) throws Throwable {
        String methodname = pjp.getSignature().getName();
        Object[] args = pjp.getArgs();
        Object res = null;

        try {
            System.out.println(methodname+&quot;方法[环绕]前置切面方法启动，参数为:&quot;+ Arrays.asList(args));
            res = pjp.proceed(args);
            System.out.println(methodname+&quot;方法[环绕]返回切面方法启动，结果为:&quot;+ res);

        }catch (Exception e){
            System.out.println(methodname+&quot;方法[环绕]异常切面方法启动，异常信息为:&quot;+ e.getMessage());
        }finally {
            System.out.println(methodname+&quot;方法[环绕]最终切面方法启动&quot;);
        }

        return res;
    }
    public static void logReturning(JoinPoint joinPoint,Object res){
        String methodname = joinPoint.getSignature().getName();
        System.out.println(methodname+&quot;方法返回切面方法启动，结果为:&quot;+ res);
    }

}
</code></pre>
<blockquote>
<p>在xml文件中配置aop</p>
</blockquote>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;
       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;
       xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot;
       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop https://www.springframework.org/schema/aop/spring-aop.xsd&quot;&gt;



    &lt;bean id=&quot;man&quot; class=&quot;com.lanou3g.bean.Man&quot; lazy-init=&quot;true&quot; init-method=&quot;init&quot; destroy-method=&quot;destroy&quot;&gt;
        &lt;property name=&quot;name&quot; value=&quot;张三&quot;&gt;&lt;/property&gt;
        &lt;property name=&quot;age&quot; value=&quot;28&quot;&gt;&lt;/property&gt;
        &lt;property name=&quot;hobbys&quot;&gt;
            &lt;map&gt;
                &lt;entry key=&quot;王者&quot; value=&quot;最强王者&quot;/&gt;
            &lt;/map&gt;
        &lt;/property&gt;
    &lt;/bean&gt;
    &lt;aop:aspectj-autoproxy  expose-proxy=&quot;true&quot;    proxy-target-class=&quot;true&quot;/&gt;

    &lt;bean id=&quot;myc&quot; class=&quot;com.lanou3g.bean.MyCalculator&quot; /&gt;

    &lt;bean id=&quot;callog&quot; class=&quot;com.lanou3g.log.CalculatorLog&quot; /&gt;

    &lt;aop:config&gt;
        &lt;aop:pointcut id=&quot;mycutpoint&quot; expression=&quot;execution(* com.lanou3g.bean.MyCalculator.*(int,int))&quot;/&gt;

        &lt;aop:aspect ref=&quot;callog&quot;&gt;
            &lt;aop:before method=&quot;logStart&quot; pointcut-ref=&quot;mycutpoint&quot; /&gt;
            &lt;aop:after-returning method=&quot;logReturning&quot; pointcut-ref=&quot;mycutpoint&quot; returning=&quot;res&quot;/&gt;
            &lt;aop:after-throwing method=&quot;logThrowing&quot; pointcut-ref=&quot;mycutpoint&quot; throwing=&quot;e&quot;/&gt;
            &lt;aop:after method=&quot;logEnd&quot; pointcut-ref=&quot;mycutpoint&quot; /&gt;
            &lt;aop:around method=&quot;logAround&quot; pointcut-ref=&quot;mycutpoint&quot; /&gt;
        &lt;/aop:aspect&gt;

    &lt;/aop:config&gt;

    &lt;context:component-scan base-package=&quot;com.lanou3g&quot; resource-pattern=&quot;com.lanou3g.log.*&quot;/&gt;
   
&lt;/beans&gt;
</code></pre>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linux常用命令大全]]></title>
        <id>https://ysjhhhhhhh.github.io/post/linux-chang-yong-ming-ling-da-quan</id>
        <link href="https://ysjhhhhhhh.github.io/post/linux-chang-yong-ming-ling-da-quan">
        </link>
        <updated>2018-04-06T02:28:57.000Z</updated>
        <content type="html"><![CDATA[<p>最近都在和Linux打交道，这方面基础比较薄弱的我只好买了本鸟哥的书看看，感觉还不错。我觉得Linux相比windows比较麻烦的就是很多东西都要用命令来控制，当然，这也是很多人喜欢linux的原因，比较短小但却功能强大。为了方便大家查找linux的相关命令，我就将我了解到的命令列举一下，仅供大家参考：</p>
<h2 id="系统信息">系统信息</h2>
<p>arch 显示机器的处理器架构(1)<br>
uname -m 显示机器的处理器架构(2)<br>
uname -r 显示正在使用的内核版本<br>
dmidecode -q 显示硬件系统部件 - (SMBIOS / DMI)<br>
hdparm -i /dev/hda 罗列一个磁盘的架构特性<br>
hdparm -tT /dev/sda 在磁盘上执行测试性读取操作<br>
cat /proc/cpuinfo 显示CPU info的信息<br>
cat /proc/interrupts 显示中断<br>
cat /proc/meminfo 校验内存使用<br>
cat /proc/swaps 显示哪些swap被使用<br>
cat /proc/version 显示内核的版本<br>
cat /proc/net/dev 显示网络适配器及统计<br>
cat /proc/mounts 显示已加载的文件系统<br>
lspci -tv 罗列 PCI 设备<br>
lsusb -tv 显示 USB 设备<br>
date 显示系统日期<br>
cal 2007 显示2007年的日历表<br>
date 041217002007.00 设置日期和时间 - 月日时分年.秒<br>
clock -w 将时间修改保存到 BIOS</p>
<h2 id="关机-系统的关机-重启以及登出">关机 (系统的关机、重启以及登出 )</h2>
<p>shutdown -h now 关闭系统(1)<br>
init 0 关闭系统(2)<br>
telinit 0 关闭系统(3)<br>
shutdown -h hours:minutes &amp; 按预定时间关闭系统<br>
shutdown -c 取消按预定时间关闭系统<br>
shutdown -r now 重启(1)<br>
reboot 重启(2)<br>
logout 注销</p>
<h2 id="文件和目录">文件和目录</h2>
<p>cd /home 进入 '/ home' 目录'<br>
cd .. 返回上一级目录<br>
cd ../.. 返回上两级目录<br>
cd 进入个人的主目录<br>
cd ~user1 进入个人的主目录<br>
cd - 返回上次所在的目录<br>
pwd 显示工作路径<br>
ls 查看目录中的文件<br>
ls -F 查看目录中的文件<br>
ls -l 显示文件和目录的详细资料<br>
ls -a 显示隐藏文件<br>
ls <em>[0-9]</em> 显示包含数字的文件名和目录名<br>
tree 显示文件和目录由根目录开始的树形结构(1)<br>
lstree 显示文件和目录由根目录开始的树形结构(2)<br>
mkdir dir1 创建一个叫做 'dir1' 的目录'<br>
mkdir dir1 dir2 同时创建两个目录<br>
mkdir -p /tmp/dir1/dir2 创建一个目录树<br>
rm -f file1 删除一个叫做 'file1' 的文件'<br>
rmdir dir1 删除一个叫做 'dir1' 的目录'<br>
rm -rf dir1 删除一个叫做 'dir1' 的目录并同时删除其内容<br>
rm -rf dir1 dir2 同时删除两个目录及它们的内容<br>
mv dir1 new_dir 重命名/移动 一个目录<br>
cp file1 file2 复制一个文件<br>
cp dir/* . 复制一个目录下的所有文件到当前工作目录<br>
cp -a /tmp/dir1 . 复制一个目录到当前工作目录<br>
cp -a dir1 dir2 复制一个目录<br>
ln -s file1 lnk1 创建一个指向文件或目录的软链接<br>
ln file1 lnk1 创建一个指向文件或目录的物理链接<br>
touch -t 0712250000 file1 修改一个文件或目录的时间戳 - (YYMMDDhhmm)<br>
file file1 outputs the mime type of the file as text<br>
iconv -l 列出已知的编码<br>
iconv -f fromEncoding -t toEncoding inputFile &gt; outputFile creates a new from the given input file by assuming it is encoded in fromEncoding and converting it to toEncoding.<br>
find . -maxdepth 1 -name *.jpg -print -exec convert &quot;{}&quot; -resize 80x60 &quot;thumbs/{}&quot; ; batch resize files in the current directory and send them to a thumbnails directory (requires convert from Imagemagick)</p>
<h2 id="文件搜索">文件搜索</h2>
<p>find / -name file1 从 '/' 开始进入根文件系统搜索文件和目录<br>
find / -user user1 搜索属于用户 'user1' 的文件和目录<br>
find /home/user1 -name *.bin 在目录 '/ home/user1' 中搜索带有'.bin' 结尾的文件<br>
find /usr/bin -type f -atime +100 搜索在过去100天内未被使用过的执行文件<br>
find /usr/bin -type f -mtime -10 搜索在10天内被创建或者修改过的文件<br>
find / -name *.rpm -exec chmod 755 '{}' ; 搜索以 '.rpm' 结尾的文件并定义其权限<br>
find / -xdev -name *.rpm 搜索以 '.rpm' 结尾的文件，忽略光驱、捷盘等可移动设备<br>
locate *.ps 寻找以 '.ps' 结尾的文件 - 先运行 'updatedb' 命令<br>
whereis halt 显示一个二进制文件、源码或man的位置<br>
which halt 显示一个二进制文件或可执行文件的完整路径</p>
<h2 id="挂载一个文件系统">挂载一个文件系统</h2>
<p>mount /dev/hda2 /mnt/hda2 挂载一个叫做hda2的盘 - 确定目录 '/ mnt/hda2' 已经存在<br>
umount /dev/hda2 卸载一个叫做hda2的盘 - 先从挂载点 '/ mnt/hda2' 退出<br>
fuser -km /mnt/hda2 当设备繁忙时强制卸载<br>
umount -n /mnt/hda2 运行卸载操作而不写入 /etc/mtab 文件- 当文件为只读或当磁盘写满时非常有用<br>
mount /dev/fd0 /mnt/floppy 挂载一个软盘<br>
mount /dev/cdrom /mnt/cdrom 挂载一个cdrom或dvdrom<br>
mount /dev/hdc /mnt/cdrecorder 挂载一个cdrw或dvdrom<br>
mount /dev/hdb /mnt/cdrecorder 挂载一个cdrw或dvdrom<br>
mount -o loop file.iso /mnt/cdrom 挂载一个文件或ISO镜像文件<br>
mount -t vfat /dev/hda5 /mnt/hda5 挂载一个Windows FAT32文件系统<br>
mount /dev/sda1 /mnt/usbdisk 挂载一个usb 捷盘或闪存设备<br>
mount -t smbfs -o username=user,password=pass //WinClient/share /mnt/share 挂载一个windows网络共享</p>
<h2 id="磁盘空间">磁盘空间</h2>
<p>df -h 显示已经挂载的分区列表<br>
ls -lSr |more 以尺寸大小排列文件和目录<br>
du -sh dir1 估算目录 'dir1' 已经使用的磁盘空间'<br>
du -sk * | sort -rn 以容量大小为依据依次显示文件和目录的大小<br>
rpm -q -a --qf '%10{SIZE}t%{NAME}n' | sort -k1,1n 以大小为依据依次显示已安装的rpm包所使用的空间 (fedora, redhat类系统)<br>
dpkg-query -W -f='<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mrow><mi>I</mi><mi>n</mi><mi>s</mi><mi>t</mi><mi>a</mi><mi>l</mi><mi>l</mi><mi>e</mi><mi>d</mi><mo>−</mo><mi>S</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo separator="true">;</mo><mn>10</mn></mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">{Installed-Size;10}t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mord mathdefault">n</span><span class="mord mathdefault">s</span><span class="mord mathdefault">t</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">e</span><span class="mord mathdefault">d</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault">i</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mord mathdefault">e</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">1</span><span class="mord">0</span></span><span class="mord mathdefault">t</span></span></span></span>{Package}n' | sort -k1,1n 以大小为依据显示已安装的deb包所使用的空间 (ubuntu, debian类系统)</p>
<h2 id="用户和群组">用户和群组</h2>
<p>groupadd group_name 创建一个新用户组<br>
groupdel group_name 删除一个用户组<br>
groupmod -n new_group_name old_group_name 重命名一个用户组<br>
useradd -c &quot;Name Surname &quot; -g admin -d /home/user1 -s /bin/bash user1 创建一个属于 &quot;admin&quot; 用户组的用户<br>
useradd user1 创建一个新用户<br>
userdel -r user1 删除一个用户 ( '-r' 排除主目录)<br>
usermod -c &quot;User FTP&quot; -g system -d /ftp/user1 -s /bin/nologin user1 修改用户属性<br>
passwd 修改口令<br>
passwd user1 修改一个用户的口令 (只允许root执行)<br>
chage -E 2005-12-31 user1 设置用户口令的失效期限<br>
pwck 检查 '/etc/passwd' 的文件格式和语法修正以及存在的用户<br>
grpck 检查 '/etc/passwd' 的文件格式和语法修正以及存在的群组<br>
newgrp group_name 登陆进一个新的群组以改变新创建文件的预设群组</p>
<h2 id="文件的权限-使用-设置权限使用-用于取消">文件的权限 - 使用 &quot;+&quot; 设置权限，使用 &quot;-&quot; 用于取消</h2>
<p>ls -lh 显示权限<br>
ls /tmp | pr -T5 -W$COLUMNS 将终端划分成5栏显示<br>
chmod ugo+rwx directory1 设置目录的所有人(u)、群组(g)以及其他人(o)以读（r ）、写(w)和执行(x)的权限<br>
chmod go-rwx directory1 删除群组(g)与其他人(o)对目录的读写执行权限<br>
chown user1 file1 改变一个文件的所有人属性<br>
chown -R user1 directory1 改变一个目录的所有人属性并同时改变改目录下所有文件的属性<br>
chgrp group1 file1 改变文件的群组<br>
chown user1:group1 file1 改变一个文件的所有人和群组属性<br>
find / -perm -u+s 罗列一个系统中所有使用了SUID控制的文件<br>
chmod u+s /bin/file1 设置一个二进制文件的 SUID 位 - 运行该文件的用户也被赋予和所有者同样的权限<br>
chmod u-s /bin/file1 禁用一个二进制文件的 SUID位<br>
chmod g+s /home/public 设置一个目录的SGID 位 - 类似SUID ，不过这是针对目录的<br>
chmod g-s /home/public 禁用一个目录的 SGID 位<br>
chmod o+t /home/public 设置一个文件的 STIKY 位 - 只允许合法所有人删除文件<br>
chmod o-t /home/public 禁用一个目录的 STIKY 位</p>
<h2 id="文件的特殊属性-使用-设置权限使用-用于取消">文件的特殊属性 - 使用 &quot;+&quot; 设置权限，使用 &quot;-&quot; 用于取消</h2>
<p>chattr +a file1 只允许以追加方式读写文件<br>
chattr +c file1 允许这个文件能被内核自动压缩/解压<br>
chattr +d file1 在进行文件系统备份时，dump程序将忽略这个文件<br>
chattr +i file1 设置成不可变的文件，不能被删除、修改、重命名或者链接<br>
chattr +s file1 允许一个文件被安全地删除<br>
chattr +S file1 一旦应用程序对这个文件执行了写操作，使系统立刻把修改的结果写到磁盘<br>
chattr +u file1 若文件被删除，系统会允许你在以后恢复这个被删除的文件<br>
lsattr 显示特殊的属性</p>
<h2 id="打包和压缩文件">打包和压缩文件</h2>
<p>bunzip2 file1.bz2 解压一个叫做 'file1.bz2'的文件<br>
bzip2 file1 压缩一个叫做 'file1' 的文件<br>
gunzip file1.gz 解压一个叫做 'file1.gz'的文件<br>
gzip file1 压缩一个叫做 'file1'的文件<br>
gzip -9 file1 最大程度压缩<br>
rar a file1.rar test_file 创建一个叫做 'file1.rar' 的包<br>
rar a file1.rar file1 file2 dir1 同时压缩 'file1', 'file2' 以及目录 'dir1'<br>
rar x file1.rar 解压rar包<br>
unrar x file1.rar 解压rar包<br>
tar -cvf archive.tar file1 创建一个非压缩的 tarball<br>
tar -cvf archive.tar file1 file2 dir1 创建一个包含了 'file1', 'file2' 以及 'dir1'的档案文件<br>
tar -tf archive.tar 显示一个包中的内容<br>
tar -xvf archive.tar 释放一个包<br>
tar -xvf archive.tar -C /tmp 将压缩包释放到 /tmp目录下<br>
tar -cvfj archive.tar.bz2 dir1 创建一个bzip2格式的压缩包<br>
tar -xvfj archive.tar.bz2 解压一个bzip2格式的压缩包<br>
tar -cvfz archive.tar.gz dir1 创建一个gzip格式的压缩包<br>
tar -xvfz archive.tar.gz 解压一个gzip格式的压缩包<br>
zip file1.zip file1 创建一个zip格式的压缩包<br>
zip -r file1.zip file1 file2 dir1 将几个文件和目录同时压缩成一个zip格式的压缩包<br>
unzip file1.zip 解压一个zip格式压缩包</p>
<h2 id="rpm-包-fedora-redhat及类似系统">RPM 包 - （Fedora, Redhat及类似系统）</h2>
<p>rpm -ivh package.rpm 安装一个rpm包<br>
rpm -ivh --nodeeps package.rpm 安装一个rpm包而忽略依赖关系警告<br>
rpm -U package.rpm 更新一个rpm包但不改变其配置文件<br>
rpm -F package.rpm 更新一个确定已经安装的rpm包<br>
rpm -e package_name.rpm 删除一个rpm包<br>
rpm -qa 显示系统中所有已经安装的rpm包<br>
rpm -qa | grep httpd 显示所有名称中包含 &quot;httpd&quot; 字样的rpm包<br>
rpm -qi package_name 获取一个已安装包的特殊信息<br>
rpm -qg &quot;System Environment/Daemons&quot; 显示一个组件的rpm包<br>
rpm -ql package_name 显示一个已经安装的rpm包提供的文件列表<br>
rpm -qc package_name 显示一个已经安装的rpm包提供的配置文件列表<br>
rpm -q package_name --whatrequires 显示与一个rpm包存在依赖关系的列表<br>
rpm -q package_name --whatprovides 显示一个rpm包所占的体积<br>
rpm -q package_name --scripts 显示在安装/删除期间所执行的脚本l<br>
rpm -q package_name --changelog 显示一个rpm包的修改历史<br>
rpm -qf /etc/httpd/conf/httpd.conf 确认所给的文件由哪个rpm包所提供<br>
rpm -qp package.rpm -l 显示由一个尚未安装的rpm包提供的文件列表<br>
rpm --import /media/cdrom/RPM-GPG-KEY 导入公钥数字证书<br>
rpm --checksig package.rpm 确认一个rpm包的完整性<br>
rpm -qa gpg-pubkey 确认已安装的所有rpm包的完整性<br>
rpm -V package_name 检查文件尺寸、 许可、类型、所有者、群组、MD5检查以及最后修改时间<br>
rpm -Va 检查系统中所有已安装的rpm包- 小心使用<br>
rpm -Vp package.rpm 确认一个rpm包还未安装<br>
rpm2cpio package.rpm | cpio --extract --make-directories <em>bin</em> 从一个rpm包运行可执行文件<br>
rpm -ivh /usr/src/redhat/RPMS/<code>arch</code>/package.rpm 从一个rpm源码安装一个构建好的包<br>
rpmbuild --rebuild package_name.src.rpm 从一个rpm源码构建一个 rpm 包</p>
<h2 id="yum-软件包升级器-fedora-redhat及类似系统">YUM 软件包升级器 - （Fedora, RedHat及类似系统）</h2>
<p>yum install package_name 下载并安装一个rpm包<br>
yum localinstall package_name.rpm 将安装一个rpm包，使用你自己的软件仓库为你解决所有依赖关系<br>
yum update package_name.rpm 更新当前系统中所有安装的rpm包<br>
yum update package_name 更新一个rpm包<br>
yum remove package_name 删除一个rpm包<br>
yum list 列出当前系统中安装的所有包<br>
yum search package_name 在rpm仓库中搜寻软件包<br>
yum clean packages 清理rpm缓存删除下载的包<br>
yum clean headers 删除所有头文件<br>
yum clean all 删除所有缓存的包和头文件</p>
<h2 id="deb-包-debian-ubuntu-以及类似系统">DEB 包 (Debian, Ubuntu 以及类似系统)</h2>
<p>dpkg -i package.deb 安装/更新一个 deb 包<br>
dpkg -r package_name 从系统删除一个 deb 包<br>
dpkg -l 显示系统中所有已经安装的 deb 包<br>
dpkg -l | grep httpd 显示所有名称中包含 &quot;httpd&quot; 字样的deb包<br>
dpkg -s package_name 获得已经安装在系统中一个特殊包的信息<br>
dpkg -L package_name 显示系统中已经安装的一个deb包所提供的文件列表<br>
dpkg --contents package.deb 显示尚未安装的一个包所提供的文件列表<br>
dpkg -S /bin/ping 确认所给的文件由哪个deb包提供</p>
<h2 id="apt-软件工具-debian-ubuntu-以及类似系统">APT 软件工具 (Debian, Ubuntu 以及类似系统)</h2>
<p>apt-get install package_name 安装/更新一个 deb 包<br>
apt-cdrom install package_name 从光盘安装/更新一个 deb 包<br>
apt-get update 升级列表中的软件包<br>
apt-get upgrade 升级所有已安装的软件<br>
apt-get remove package_name 从系统删除一个deb包<br>
apt-get check 确认依赖的软件仓库正确<br>
apt-get clean 从下载的软件包中清理缓存<br>
apt-cache search searched-package 返回包含所要搜索字符串的软件包名称</p>
<h2 id="查看文件内容">查看文件内容</h2>
<p>cat file1 从第一个字节开始正向查看文件的内容<br>
tac file1 从最后一行开始反向查看一个文件的内容<br>
more file1 查看一个长文件的内容<br>
less file1 类似于 'more' 命令，但是它允许在文件中和正向操作一样的反向操作<br>
head -2 file1 查看一个文件的前两行<br>
tail -2 file1 查看一个文件的最后两行<br>
tail -f /var/log/messages 实时查看被添加到一个文件中的内容</p>
<h2 id="文本处理">文本处理</h2>
<p>cat file1 file2 ... | command &lt;&gt; file1_in.txt_or_file1_out.txt general syntax for text manipulation using PIPE, STDIN and STDOUT<br>
cat file1 | command( sed, grep, awk, grep, etc...) &gt; result.txt 合并一个文件的详细说明文本，并将简介写入一个新文件中<br>
cat file1 | command( sed, grep, awk, grep, etc...) &gt;&gt; result.txt 合并一个文件的详细说明文本，并将简介写入一个已有的文件中<br>
grep Aug /var/log/messages 在文件 '/var/log/messages'中查找关键词&quot;Aug&quot;<br>
grep ^Aug /var/log/messages 在文件 '/var/log/messages'中查找以&quot;Aug&quot;开始的词汇<br>
grep [0-9] /var/log/messages 选择 '/var/log/messages' 文件中所有包含数字的行<br>
grep Aug -R /var/log/* 在目录 '/var/log' 及随后的目录中搜索字符串&quot;Aug&quot;<br>
sed 's/stringa1/stringa2/g' example.txt 将example.txt文件中的 &quot;string1&quot; 替换成 &quot;string2&quot;<br>
sed '/^<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;EOF&#039;, got &#039;#&#039; at position 49: …所有空白行 
sed &#039;/ *#̲/d; /^'>/d&#039; example.txt 从example.txt文件中删除所有空白行 
sed &#039;/ *#/d; /^</span>/d' example.txt 从example.txt文件中删除所有注释和空白行<br>
echo 'esempio' | tr '[:lower:]' '[:upper:]' 合并上下单元格内容<br>
sed -e '1d' result.txt 从文件example.txt 中排除第一行<br>
sed -n '/stringa1/p' 查看只包含词汇 &quot;string1&quot;的行<br>
sed -e 's/ <em>$//' example.txt 删除每一行最后的空白字符<br>
sed -e 's/stringa1//g' example.txt 从文档中只删除词汇 &quot;string1&quot; 并保留剩余全部<br>
sed -n '1,5p;5q' example.txt 查看从第一行到第5行内容<br>
sed -n '5p;5q' example.txt 查看第5行<br>
sed -e 's/00</em>/0/g' example.txt 用单个零替换多个零<br>
cat -n file1 标示文件的行数<br>
cat example.txt | awk 'NR%2==1' 删除example.txt文件中的所有偶数行<br>
echo a b c | awk '{print $1}' 查看一行第一栏<br>
echo a b c | awk '{print $1,$3}' 查看一行的第一和第三栏<br>
paste file1 file2 合并两个文件或两栏的内容<br>
paste -d '+' file1 file2 合并两个文件或两栏的内容，中间用&quot;+&quot;区分<br>
sort file1 file2 排序两个文件的内容<br>
sort file1 file2 | uniq 取出两个文件的并集(重复的行只保留一份)<br>
sort file1 file2 | uniq -u 删除交集，留下其他的行<br>
sort file1 file2 | uniq -d 取出两个文件的交集(只留下同时存在于两个文件中的文件)<br>
comm -1 file1 file2 比较两个文件的内容只删除 'file1' 所包含的内容<br>
comm -2 file1 file2 比较两个文件的内容只删除 'file2' 所包含的内容<br>
comm -3 file1 file2 比较两个文件的内容只删除两个文件共有的部分</p>
<h2 id="字符设置和文件格式转换">字符设置和文件格式转换</h2>
<p>dos2unix filedos.txt fileunix.txt 将一个文本文件的格式从MSDOS转换成UNIX<br>
unix2dos fileunix.txt filedos.txt 将一个文本文件的格式从UNIX转换成MSDOS<br>
recode ..HTML &lt; page.txt &gt; page.html 将一个文本文件转换成html<br>
recode -l | more 显示所有允许的转换格式</p>
<h2 id="文件系统分析">文件系统分析</h2>
<p>badblocks -v /dev/hda1 检查磁盘hda1上的坏磁块<br>
fsck /dev/hda1 修复/检查hda1磁盘上linux文件系统的完整性<br>
fsck.ext2 /dev/hda1 修复/检查hda1磁盘上ext2文件系统的完整性<br>
e2fsck /dev/hda1 修复/检查hda1磁盘上ext2文件系统的完整性<br>
e2fsck -j /dev/hda1 修复/检查hda1磁盘上ext3文件系统的完整性<br>
fsck.ext3 /dev/hda1 修复/检查hda1磁盘上ext3文件系统的完整性<br>
fsck.vfat /dev/hda1 修复/检查hda1磁盘上fat文件系统的完整性<br>
fsck.msdos /dev/hda1 修复/检查hda1磁盘上dos文件系统的完整性<br>
dosfsck /dev/hda1 修复/检查hda1磁盘上dos文件系统的完整性</p>
<h2 id="初始化一个文件系统">初始化一个文件系统</h2>
<p>mkfs /dev/hda1 在hda1分区创建一个文件系统<br>
mke2fs /dev/hda1 在hda1分区创建一个linux ext2的文件系统<br>
mke2fs -j /dev/hda1 在hda1分区创建一个linux ext3(日志型)的文件系统<br>
mkfs -t vfat 32 -F /dev/hda1 创建一个 FAT32 文件系统<br>
fdformat -n /dev/fd0 格式化一个软盘<br>
mkswap /dev/hda3 创建一个swap文件系统</p>
<h2 id="swap文件系统">SWAP文件系统</h2>
<p>mkswap /dev/hda3 创建一个swap文件系统<br>
swapon /dev/hda3 启用一个新的swap文件系统<br>
swapon /dev/hda2 /dev/hdb3 启用两个swap分区</p>
<h2 id="备份">备份</h2>
<p>dump -0aj -f /tmp/home0.bak /home 制作一个 '/home' 目录的完整备份<br>
dump -1aj -f /tmp/home0.bak /home 制作一个 '/home' 目录的交互式备份<br>
restore -if /tmp/home0.bak 还原一个交互式备份<br>
rsync -rogpav --delete /home /tmp 同步两边的目录<br>
rsync -rogpav -e ssh --delete /home ip_address:/tmp 通过SSH通道rsync<br>
rsync -az -e ssh --delete ip_addr:/home/public /home/local 通过ssh和压缩将一个远程目录同步到本地目录<br>
rsync -az -e ssh --delete /home/local ip_addr:/home/public 通过ssh和压缩将本地目录同步到远程目录<br>
dd bs=1M if=/dev/hda | gzip | ssh user@ip_addr 'dd of=hda.gz' 通过ssh在远程主机上执行一次备份本地磁盘的操作<br>
dd if=/dev/sda of=/tmp/file1 备份磁盘内容到一个文件<br>
tar -Puf backup.tar /home/user 执行一次对 '/home/user' 目录的交互式备份操作<br>
( cd /tmp/local/ &amp;&amp; tar c . ) | ssh -C user@ip_addr 'cd /home/share/ &amp;&amp; tar x -p' 通过ssh在远程目录中复制一个目录内容<br>
( tar c /home ) | ssh -C user@ip_addr 'cd /home/backup-home &amp;&amp; tar x -p' 通过ssh在远程目录中复制一个本地目录<br>
tar cf - . | (cd /tmp/backup ; tar xf - ) 本地将一个目录复制到另一个地方，保留原有权限及链接<br>
find /home/user1 -name '<em>.txt' | xargs cp -av --target-directory=/home/backup/ --parents 从一个目录查找并复制所有以 '.txt' 结尾的文件到另一个目录<br>
find /var/log -name '</em>.log' | tar cv --files-from=- | bzip2 &gt; log.tar.bz2 查找所有以 '.log' 结尾的文件并做成一个bzip包<br>
dd if=/dev/hda of=/dev/fd0 bs=512 count=1 做一个将 MBR (Master Boot Record)内容复制到软盘的动作<br>
dd if=/dev/fd0 of=/dev/hda bs=512 count=1 从已经保存到软盘的备份中恢复MBR内容</p>
<h2 id="光盘">光盘</h2>
<p>cdrecord -v gracetime=2 dev=/dev/cdrom -eject blank=fast -force 清空一个可复写的光盘内容<br>
mkisofs /dev/cdrom &gt; cd.iso 在磁盘上创建一个光盘的iso镜像文件<br>
mkisofs /dev/cdrom | gzip &gt; cd_iso.gz 在磁盘上创建一个压缩了的光盘iso镜像文件<br>
mkisofs -J -allow-leading-dots -R -V &quot;Label CD&quot; -iso-level 4 -o ./cd.iso data_cd 创建一个目录的iso镜像文件<br>
cdrecord -v dev=/dev/cdrom cd.iso 刻录一个ISO镜像文件<br>
gzip -dc cd_iso.gz | cdrecord dev=/dev/cdrom - 刻录一个压缩了的ISO镜像文件<br>
mount -o loop cd.iso /mnt/iso 挂载一个ISO镜像文件<br>
cd-paranoia -B 从一个CD光盘转录音轨到 wav 文件中<br>
cd-paranoia -- &quot;-3&quot; 从一个CD光盘转录音轨到 wav 文件中（参数-3）<br>
cdrecord --scanbus 扫描总线以识别scsi通道<br>
dd if=/dev/hdc | md5sum 校验一个设备的md5sum编码，例如一张 CD</p>
<h2 id="网络-以太网和wifi无线">网络 - （以太网和WIFI无线）</h2>
<p>ifconfig eth0 显示一个以太网卡的配置<br>
ifup eth0 启用一个 'eth0' 网络设备<br>
ifdown eth0 禁用一个 'eth0' 网络设备<br>
ifconfig eth0 192.168.1.1 netmask 255.255.255.0 控制IP地址<br>
ifconfig eth0 promisc 设置 'eth0' 成混杂模式以嗅探数据包 (sniffing)<br>
dhclient eth0 以dhcp模式启用 'eth0'<br>
route -n show routing table<br>
route add -net 0/0 gw IP_Gateway configura default gateway<br>
route add -net 192.168.0.0 netmask 255.255.0.0 gw 192.168.1.1 configure static route to reach network '192.168.0.0/16'<br>
route del 0/0 gw IP_gateway remove static route<br>
echo &quot;1&quot; &gt; /proc/sys/net/ipv4/ip_forward activate ip routing<br>
hostname show hostname of system<br>
host www.example.com lookup hostname to resolve name to ip address and viceversa(1)<br>
nslookup www.example.com lookup hostname to resolve name to ip address and viceversa(2)<br>
ip link show show link status of all interfaces<br>
mii-tool eth0 show link status of 'eth0'<br>
ethtool eth0 show statistics of network card 'eth0'<br>
netstat -tup show all active network connections and their PID<br>
netstat -tupl show all network services listening on the system and their PID<br>
tcpdump tcp port 80 show all HTTP traffic<br>
iwlist scan show wireless networks<br>
iwconfig eth1 show configuration of a wireless network card<br>
hostname show hostname<br>
host www.example.com lookup hostname to resolve name to ip address and viceversa<br>
nslookup www.example.com lookup hostname to resolve name to ip address and viceversa<br>
whois www.example.com lookup on Whois database</p>
<h2 id="go-top-index">GO TOP INDEX ^</h2>
<p>Microsoft Windows networks (SAMBA)<br>
nbtscan ip_addr netbios name resolution<br>
nmblookup -A ip_addr netbios name resolution<br>
smbclient -L ip_addr/hostname show remote shares of a windows host<br>
smbget -Rr smb://ip_addr/share like wget can download files from a host windows via smb<br>
mount -t smbfs -o username=user,password=pass //WinClient/share /mnt/share mount a windows network share</p>
<p>转发自：<a href="http://www.cnblogs.com/fnlingnzb-learner/p/5831284.html">原博客</a> 谢谢。</p>
]]></content>
    </entry>
</feed>